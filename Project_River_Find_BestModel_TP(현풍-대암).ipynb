{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMKHTsedaum7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import argparse\n",
    "from copy import deepcopy #Add Deepcopy for args\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(torch.__version__)\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1gRd7qVcEwI"
   },
   "source": [
    "# 1. Data loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KShxDU_Jcj3u"
   },
   "source": [
    "### 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f39evpcvc1KK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsungpark/Desktop/jupyter/Data_river/original02/HP_DA\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jinsungpark/Desktop/jupyter/Data_river/original02/HP_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTiRk82qctLD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DA_Down_data.xlsx       lstm[4].pt              modell_result_[2].csv\r\n",
      "DA_Down_log.xlsx        lstm[5].pt              modell_result_[3].csv\r\n",
      "HP_Up_data.xlsx         lstm[6].pt              modell_result_[4].csv\r\n",
      "HP_Up_log.xlsx          lstm[7].pt              modell_result_[5].csv\r\n",
      "lstm[10].pt             lstm[8].pt              modell_result_[6].csv\r\n",
      "lstm[11].pt             lstm[9].pt              modell_result_[7].csv\r\n",
      "lstm[12].pt             modell_result_[10].csv  modell_result_[8].csv\r\n",
      "lstm[1].pt              modell_result_[11].csv  modell_result_[9].csv\r\n",
      "lstm[2].pt              modell_result_[12].csv\r\n",
      "lstm[3].pt              modell_result_[1].csv\r\n"
     ]
    }
   ],
   "source": [
    "ls #현재경로에 있는 항목 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dln4LnKpc1CX"
   },
   "outputs": [],
   "source": [
    "UpStream_data = pd.read_excel('HP_Up_log.xlsx')\n",
    "DownStream_data = pd.read_excel('DA_Down_log.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GRAwoM_c068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'HP_DO', 'HP_BOD', 'HP_COD', 'HP_SS', 'HP_TN', 'HP_TP',\n",
      "       'HP_Chl_a', 'HP_Flow', 'ChaCh_DO', 'ChaCh_BOD', 'ChaCh_COD', 'ChaCh_SS',\n",
      "       'ChaCh_TN', 'ChaCh_TP', 'ChaCh_Chl_a', 'ChaCh_Flow', 'UiR_Rain',\n",
      "       'UiR_Solar', 'HP_Temp', 'ChaCh_Temp'],\n",
      "      dtype='object')\n",
      "Index(['Date', 'DA_DO', 'DA_BOD', 'DA_COD', 'DA_SS', 'DA_TN', 'DA_TP',\n",
      "       'DA_Chl_a'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(UpStream_data.columns)\n",
    "print(DownStream_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uneezLbLdGiC"
   },
   "outputs": [],
   "source": [
    "#날짜 인덱스화\n",
    "UpData = UpStream_data.set_index('Date')\n",
    "DownData = DownStream_data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 265 entries, 2013-01-08 to 2019-09-23\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   HP_DO        265 non-null    float64\n",
      " 1   HP_BOD       265 non-null    float64\n",
      " 2   HP_COD       265 non-null    float64\n",
      " 3   HP_SS        265 non-null    float64\n",
      " 4   HP_TN        265 non-null    float64\n",
      " 5   HP_TP        265 non-null    float64\n",
      " 6   HP_Chl_a     265 non-null    float64\n",
      " 7   HP_Flow      265 non-null    float64\n",
      " 8   ChaCh_DO     265 non-null    float64\n",
      " 9   ChaCh_BOD    265 non-null    float64\n",
      " 10  ChaCh_COD    265 non-null    float64\n",
      " 11  ChaCh_SS     265 non-null    float64\n",
      " 12  ChaCh_TN     265 non-null    float64\n",
      " 13  ChaCh_TP     265 non-null    float64\n",
      " 14  ChaCh_Chl_a  265 non-null    float64\n",
      " 15  ChaCh_Flow   265 non-null    float64\n",
      " 16  UiR_Rain     265 non-null    float64\n",
      " 17  UiR_Solar    265 non-null    float64\n",
      " 18  HP_Temp      265 non-null    float64\n",
      " 19  ChaCh_Temp   265 non-null    float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 43.5 KB\n"
     ]
    }
   ],
   "source": [
    "UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rSPrna-c0pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HP_DO', 'HP_COD', 'HP_SS', 'HP_TN', 'HP_TP', 'HP_Temp', 'HP_Flow',\n",
      "       'ChaCh_DO', 'ChaCh_COD', 'ChaCh_TN', 'ChaCh_TP', 'ChaCh_Temp',\n",
      "       'ChaCh_Flow', 'UiR_Rain'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#넣고싶은 상류 항목 컬럼 선택 - TP setting\n",
    "UpData = UpData.iloc[:,[0,2,3,4,5,18,7,8,10,12,13,19,15,16]]\n",
    "print(UpData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #넣고싶은 상류 항목 컬럼 선택 - TN setting\n",
    "# UpData = UpData.iloc[:,[0,4,5,18,7,8,10,12,13,19,15,16,17]]\n",
    "# UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 265 entries, 2013-01-08 to 2019-09-23\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DA_DO     265 non-null    float64\n",
      " 1   DA_BOD    265 non-null    float64\n",
      " 2   DA_COD    265 non-null    float64\n",
      " 3   DA_SS     265 non-null    float64\n",
      " 4   DA_TN     265 non-null    float64\n",
      " 5   DA_TP     265 non-null    float64\n",
      " 6   DA_Chl_a  265 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 16.6 KB\n"
     ]
    }
   ],
   "source": [
    "DownData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rSPrna-c0pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DA_TP\n"
     ]
    }
   ],
   "source": [
    "#알고싶은 하류 항목 컬럼 넘버 넣기('Date'항목이 인덱스화 돼서 컬럼 넘버가 -1씩 됨)\n",
    "Colum = 5\n",
    "print(DownData.columns[Colum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2Tp4o0Hc0ZL"
   },
   "source": [
    "### 1.2 Data Preprocessing(normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChKYCAtTdGpA"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "UpScaler = MinMaxScaler() #상류데이터용\n",
    "DownScaler = MinMaxScaler() #하류데이터용\n",
    "\n",
    "#나중에 결과를 DeNormalizing 하기 위해 나누어 사용 하였다.\n",
    "\n",
    "def DeNormalize(Y, Data_name, column_num, Scaler_Type):\n",
    "    \n",
    "    data = Data_name\n",
    "    Scaler = Scaler_Type\n",
    "    \n",
    "    _max = Scaler.data_max_[column_num] # 역정규화 하려는 데이터의 컬럼 번호\n",
    "    _min = Scaler.data_min_[column_num] \n",
    "    \n",
    "    X = Y*(_max-_min) + _min\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uneezLbLdGiC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP_DO         0\n",
      "HP_COD        0\n",
      "HP_SS         0\n",
      "HP_TN         0\n",
      "HP_TP         0\n",
      "HP_Temp       0\n",
      "HP_Flow       0\n",
      "ChaCh_DO      0\n",
      "ChaCh_COD     0\n",
      "ChaCh_TN      0\n",
      "ChaCh_TP      0\n",
      "ChaCh_Temp    0\n",
      "ChaCh_Flow    0\n",
      "UiR_Rain      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#데이터 정규화\n",
    "UpData = pd.DataFrame(UpScaler.fit_transform(UpData), columns=UpData.columns, index=UpData.index)\n",
    "DownData = pd.DataFrame(DownScaler.fit_transform(DownData), columns=DownData.columns, index=DownData.index)\n",
    "\n",
    "print(UpData.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDSVZGiUdGYz"
   },
   "source": [
    "#2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hxm2moSudGQD"
   },
   "outputs": [],
   "source": [
    "class RiverDataset(Dataset):\n",
    "    def __init__(self, UpData, DownData, x_frames, y_frames, start, end):\n",
    "        \n",
    "        self.x_frames = x_frames\n",
    "        self.y_frames = y_frames\n",
    "        \n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "        self.UpData = UpData[start:end]\n",
    "        self.DownData = DownData[start:end]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.UpData) - (self.x_frames + self.y_frames) + 1\n",
    "    #데이터를 전처리 할때 UpData와 DownData의 길이가 동일해짐(날짜를 동일한것만 추출해야 하므로), 따라서 전체길이는 둘중 하나를 사용\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.x_frames\n",
    "\n",
    "        X = self.UpData.iloc[idx-self.x_frames:idx].values\n",
    "        Y = self.DownData.iloc[idx:idx+self.y_frames].values\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fj80CahhdGG9"
   },
   "source": [
    "# 3. Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuBGEc51dF-V"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, batch_size, dropout, use_bn):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.use_bn = use_bn \n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers) #\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.regressor = self.make_regressor()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def make_regressor(self):\n",
    "        layers = []\n",
    "        if self.use_bn:\n",
    "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "        layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
    "        regressor = nn.Sequential(*layers)\n",
    "        return regressor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTpV_o6Wdglq"
   },
   "outputs": [],
   "source": [
    "# 정확도 : 예측확률을 100%로 봤을때 MAPE에 따른 오차비율을 빼줌 (100-MAPE) ##RMSE, MAPE 두개로 볼 수 있게\n",
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    R2_score = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "    return R2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GPb8H8-djwB"
   },
   "source": [
    "# 4. Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrT2W-pqdjh6"
   },
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, loss_fn, args):\n",
    "    trainloader = DataLoader(partition['train'],\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False, drop_last=True)\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    bat_siz = args.batch_size\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "\n",
    "        X = X.transpose(0, 1).float().to(args.device)#파이토치는 순서가 달라서 바꿔줌\n",
    "        y_true = y[:, :, Colum].float().to(args.device)\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred.append(y_pred)\n",
    "        true.append(y_true)\n",
    "\n",
    "    # ========================================================================== #\n",
    "    for i in range(len(trainloader)):\n",
    "        tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "        tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(bat_siz):\n",
    "            value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "            value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "            \n",
    "            pred_results.append(value1)\n",
    "            true_results.append(value2)\n",
    "    # ========================================================================== #   \n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc1 = RMSE(np.array(true_results), np.array(pred_results))\n",
    "    train_acc2 = R2(np.array(true_results), np.array(pred_results))\n",
    "#     train_acc3 = (100 - MAPE(np.array(true_results), np.array(pred_results)))\n",
    "\n",
    "    return model, train_loss, train_acc1[0], train_acc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JvAO-LVCdjgG"
   },
   "outputs": [],
   "source": [
    "def validate(model, partition, loss_fn, args):\n",
    "    valloader = DataLoader(partition['val'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    model.eval()\n",
    "\n",
    "    bat_siz = args.batch_size\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(valloader):\n",
    "\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y[:, :, Colum].float().to(args.device)\n",
    "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            pred.append(y_pred)\n",
    "            true.append(y_true)\n",
    "\n",
    "        # ========================================================================== #\n",
    "        for i in range(len(valloader)):\n",
    "            tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "            tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "\n",
    "            for j in range(bat_siz):\n",
    "                value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "                value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "\n",
    "                pred_results.append(value1)\n",
    "                true_results.append(value2)\n",
    "        # ========================================================================== #   \n",
    "\n",
    "    val_loss = val_loss / len(valloader)\n",
    "    val_acc1 = RMSE(np.array(true_results), np.array(pred_results))\n",
    "    val_acc2 = R2(np.array(true_results), np.array(pred_results))\n",
    "#     val_acc3 = (100 - MAPE(np.array(true_results), np.array(pred_results)))\n",
    "\n",
    "    \n",
    "    return val_loss, val_acc1[0], val_acc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHWmu5EtdjXu"
   },
   "outputs": [],
   "source": [
    "def test(model, partition, args):\n",
    "    testloader = DataLoader(partition['test'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    model.eval()\n",
    "\n",
    "    bat_siz = args.batch_size\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y[:, :, Colum].float().to(args.device)\n",
    "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            pred.append(y_pred)\n",
    "            true.append(y_true)\n",
    "\n",
    "    # =================== test 데이터 시각화를 위해 x,y데이터 저장 =================== #\n",
    "    for i in range(len(testloader)):\n",
    "        tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "        tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(bat_siz):\n",
    "            value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "            value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "            \n",
    "            pred_results.append(value1)\n",
    "            true_results.append(value2)\n",
    "    # ======================================================================== #   \n",
    "\n",
    "    test_acc1 =  RMSE(np.array( true_results), np.array(pred_results))\n",
    "    test_acc2 =  R2(np.array( true_results), np.array(pred_results))\n",
    "#     test_acc3 =  (100 - MAPE(np.array( true_results), np.array(pred_results)))\n",
    "    \n",
    "    return test_acc1[0], test_acc2[0], pred_results, true_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkkF0-qmeOMq"
   },
   "source": [
    "# 5. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EOe2j_udjNv"
   },
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "\n",
    "    model = LSTM(args.input_dim, args.hid_dim, args.y_frames, args.n_layers, args.batch_size, args.dropout, args.use_bn)\n",
    "    model.to(args.device)\n",
    "\n",
    "    if args.loss == 'MSELoss':\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        loss_fn = nn.MSELoss()\n",
    "    elif args.loss == 'L1Loss':\n",
    "        loss_fn = torch.nn.L1Loss()\n",
    "        loss_fn = nn.L1Loss()\n",
    "    elif args.loss == 'PoissonNLLLoss':\n",
    "        loss_fn = torch.nn.PoissonNLLLoss()\n",
    "        loss_fn = nn.PoissonNLLLoss()\n",
    "    elif args.loss == 'KLDivLoss':\n",
    "        loss_fn = torch.nn.KLDivLoss()\n",
    "        loss_fn = nn.KLDivLoss()\n",
    "    elif args.loss == 'BCELoss':\n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        loss_fn = nn.BCELoss()\n",
    "    elif args.loss == 'BCEWithLogitsLoss':\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        raise ValueError('In-valid LossFuction choice')\n",
    "    \n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "    \n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs_RMSE = []\n",
    "    train_accs_R2 = []\n",
    "    val_accs_RMSE = []\n",
    "    val_accs_R2 = []\n",
    "    result_info = pd.DataFrame()\n",
    "    result_data = pd.DataFrame()\n",
    "    \n",
    "    # ===================================== #\n",
    "    \n",
    "    ## model starting point ##    \n",
    "    ts = time.time()\n",
    "    model, train_loss, train_acc_RMSE, train_acc_R2 = train(model, partition, optimizer, loss_fn, args)\n",
    "    val_loss, val_acc_RMSE, val_acc_R2 = validate(model, partition, loss_fn, args)\n",
    "    te = time.time()\n",
    "\n",
    "    # ====== Add Epoch Data ====== #\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs_RMSE.append(train_acc_RMSE)\n",
    "    val_accs_RMSE.append(val_acc_RMSE)\n",
    "    train_accs_R2.append(train_acc_R2)\n",
    "    val_accs_R2.append(val_acc_R2)\n",
    "    # ============================ #\n",
    "\n",
    "\n",
    "#     print('Epoch {}, Acc_RMSE(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'\n",
    "#           .format(0, train_acc_RMSE, val_acc_RMSE, train_loss, val_loss, te-ts))\n",
    "    \n",
    "    for epoch in range(args.epoch-1):  # loop over the dataset multiple times\n",
    "        \n",
    "        ts = time.time()\n",
    "        model, train_loss, train_acc_RMSE, train_acc_R2 = train(model, partition, optimizer, loss_fn, args)\n",
    "        val_loss, val_acc_RMSE, val_acc_R2 = validate(model, partition, loss_fn, args)\n",
    "        te = time.time()\n",
    "\n",
    "        # ====== Add Epoch Data ====== #\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs_RMSE.append(train_acc_RMSE)\n",
    "        val_accs_RMSE.append(val_acc_RMSE)\n",
    "        train_accs_R2.append(train_acc_R2)\n",
    "        val_accs_R2.append(val_acc_R2)\n",
    "        # ============================ #\n",
    "        \n",
    "        \n",
    "        if epoch == epoch:\n",
    "            trash_01, trash_02, Pred_save, True_save = test(model, partition, args)\n",
    "            result_data['test_pred_epoch({})'.format(epoch)] = Pred_save\n",
    "            result_data['test_true_epoch({})'.format(epoch)] = True_save\n",
    "\n",
    "\n",
    "#         print('Epoch {}, Acc_RMSE(train/val): {:2.4f}/{:2.4f}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'\n",
    "#               .format(epoch+1, train_acc_RMSE, val_acc_RMSE, train_loss, val_loss, te-ts))\n",
    "        \n",
    "    test_acc_RMSE, test_acc_R2, Pred_data, True_data = test(model, partition, args)    \n",
    "    \n",
    "    # ======= Add Result  ======= #\n",
    "    result_info['train_losses'] = train_losses\n",
    "    result_info['val_losses'] = val_losses\n",
    "    \n",
    "    result_info['train_accs_RMSE'] = train_accs_RMSE\n",
    "    result_info['train_accs_R2'] = train_accs_R2\n",
    "    result_info['val_accs_RMSE'] = val_accs_RMSE\n",
    "    result_info['val_accs_R2'] = val_accs_R2\n",
    "    \n",
    "#     result_info['train_acc'] = train_acc\n",
    "#     result_info['val_acc'] = val_acc\n",
    "    result_info['test_RMSE'] = test_acc_RMSE\n",
    "    result_info['test_R2'] = test_acc_R2\n",
    "\n",
    "#     result_data['test_pred'] = Pred_data\n",
    "#     result_data['test_true'] = True_data\n",
    "    \n",
    "    return result_info, result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNi-f5HyeJYi"
   },
   "source": [
    "# 6. LSTM Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4Bu6kFUdizj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " size of trainset :211\n",
      " size of valset :44\n",
      " size of testset :44\n",
      " total_exp_num : 216\n"
     ]
    }
   ],
   "source": [
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ====== Data Loading ====== #\n",
    "args.batch_size = 8\n",
    "args.UpData = UpData\n",
    "args.DownData = DownData\n",
    "args.x_frames = 5\n",
    "args.y_frames = 1\n",
    "\n",
    "# ====== Model Capacity ===== #\n",
    "args.input_dim = len(UpData.columns)\n",
    "args.hid_dim = 16\n",
    "args.n_layers = 2\n",
    "\n",
    "# ====== Regularization ======= #\n",
    "args.l2 = 0.0001\n",
    "args.dropout = 0.1 \n",
    "args.use_bn = False\n",
    "\n",
    "# ====== Optimizer & Training ====== #\n",
    "args.optim = 'Adam'  #SGD, RMSprop, Adam...\n",
    "args.loss = 'MSELoss'#'MSELoss','L1Loss','PoissonNLLLoss','KLDivLoss','BCELoss','BCEWithLogitsLoss'\n",
    "args.lr = 0.01\n",
    "args.epoch = 3\n",
    "\n",
    "\n",
    "# ====== Experiment Variable ====== #\n",
    "name_var1 = 'x_frames'\n",
    "list_var1 = [4,2]\n",
    "\n",
    "name_var2 = 'loss'\n",
    "list_var2 = ['MSELoss']\n",
    "\n",
    "name_var3 = 'optim'\n",
    "list_var3 = ['Adam']\n",
    "\n",
    "name_var4 = 'use_bn'\n",
    "list_var4 = [False]\n",
    "\n",
    "name_var5 = 'dropout'\n",
    "list_var5 = [0.1]\n",
    "\n",
    "name_var6 = 'batch_size'\n",
    "list_var6 = [4, 8]\n",
    "\n",
    "name_var7 = 'hid_dim'\n",
    "list_var7 = [32, 16]\n",
    "\n",
    "name_var8 = 'n_layers'\n",
    "list_var8 = [4, 3, 2]\n",
    "\n",
    "name_var9 = 'lr'\n",
    "list_var9 = [0.01, 0.001, 0.0001]\n",
    "\n",
    "name_var10 = 'l2'\n",
    "list_var10 = [0.01, 0.001,0.0001]\n",
    "\n",
    "name_var11 = 'epoch'\n",
    "list_var11 = [200]\n",
    "\n",
    "trainset = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2013-01-01', '2018-06-30')\n",
    "valset = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2018-07-01', '2019-12-31')\n",
    "testset = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2018-07-01', '2019-12-31')\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}\n",
    "\n",
    "print(' size of trainset :{}\\n'.format(len(trainset)),\n",
    "      'size of valset :{}\\n'.format(len(valset)),\n",
    "      'size of testset :{}'.format(len(testset)))\n",
    "\n",
    "list_vars = [list_var1, list_var2, list_var3, list_var4, list_var5, list_var6, list_var7, list_var8, list_var9, list_var10, list_var11]\n",
    "i = 1\n",
    "for lenth in list_vars:\n",
    "    x = len(lenth)\n",
    "    i *= x\n",
    "total_exp_num = i\n",
    "\n",
    "print(' total_exp_num : {}'.format(total_exp_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jinsungpark/Desktop/jupyter/Data_river/original02/HP_DA'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsungpark/Desktop/jupyter/Data_river/exp_0418_01\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jinsungpark/Desktop/jupyter/Data_river/exp_0418_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Start #####\n",
      "experiment_1/216, took 178.4sec, 0.46% done\n",
      "experiment_2/216, took 186.0sec, 0.93% done\n",
      "experiment_3/216, took 172.5sec, 1.39% done\n",
      "experiment_4/216, took 197.4sec, 1.85% done\n",
      "experiment_5/216, took 171.2sec, 2.31% done\n",
      "experiment_6/216, took 130.6sec, 2.78% done\n",
      "experiment_7/216, took 161.7sec, 3.24% done\n",
      "experiment_8/216, took 130.6sec, 3.70% done\n",
      "experiment_9/216, took 130.4sec, 4.17% done\n",
      "experiment_10/216, took 142.9sec, 4.63% done\n",
      "experiment_11/216, took 141.7sec, 5.09% done\n",
      "experiment_12/216, took 132.7sec, 5.56% done\n",
      "experiment_13/216, took 159.7sec, 6.02% done\n",
      "experiment_14/216, took 109.6sec, 6.48% done\n",
      "experiment_15/216, took 109.3sec, 6.94% done\n",
      "experiment_16/216, took 126.2sec, 7.41% done\n",
      "experiment_17/216, took 109.4sec, 7.87% done\n",
      "experiment_18/216, took 109.2sec, 8.33% done\n",
      "experiment_19/216, took 106.8sec, 8.80% done\n",
      "experiment_20/216, took 104.6sec, 9.26% done\n",
      "experiment_21/216, took 97.2sec, 9.72% done\n",
      "experiment_22/216, took 115.0sec, 10.19% done\n",
      "experiment_23/216, took 87.7sec, 10.65% done\n",
      "experiment_24/216, took 87.5sec, 11.11% done\n",
      "experiment_25/216, took 88.4sec, 11.57% done\n",
      "experiment_26/216, took 87.5sec, 12.04% done\n",
      "experiment_27/216, took 87.5sec, 12.50% done\n",
      "experiment_28/216, took 143.9sec, 12.96% done\n",
      "experiment_29/216, took 144.8sec, 13.43% done\n",
      "experiment_30/216, took 142.4sec, 13.89% done\n",
      "experiment_31/216, took 149.6sec, 14.35% done\n",
      "experiment_32/216, took 142.9sec, 14.81% done\n",
      "experiment_33/216, took 129.3sec, 15.28% done\n",
      "experiment_34/216, took 134.5sec, 15.74% done\n",
      "experiment_35/216, took 130.1sec, 16.20% done\n",
      "experiment_36/216, took 128.3sec, 16.67% done\n",
      "experiment_37/216, took 118.2sec, 17.13% done\n",
      "experiment_38/216, took 119.4sec, 17.59% done\n",
      "experiment_39/216, took 116.3sec, 18.06% done\n",
      "experiment_40/216, took 123.8sec, 18.52% done\n",
      "experiment_41/216, took 120.1sec, 18.98% done\n",
      "experiment_42/216, took 107.8sec, 19.44% done\n",
      "experiment_43/216, took 112.0sec, 19.91% done\n",
      "experiment_44/216, took 107.3sec, 20.37% done\n",
      "experiment_45/216, took 107.4sec, 20.83% done\n",
      "experiment_46/216, took 94.7sec, 21.30% done\n",
      "experiment_47/216, took 94.1sec, 21.76% done\n",
      "experiment_48/216, took 87.8sec, 22.22% done\n",
      "experiment_49/216, took 94.3sec, 22.69% done\n",
      "experiment_50/216, took 86.7sec, 23.15% done\n",
      "experiment_51/216, took 86.7sec, 23.61% done\n",
      "experiment_52/216, took 87.9sec, 24.07% done\n",
      "experiment_53/216, took 88.0sec, 24.54% done\n",
      "experiment_54/216, took 89.1sec, 25.00% done\n",
      "experiment_55/216, took 139.1sec, 25.46% done\n",
      "experiment_56/216, took 132.4sec, 25.93% done\n",
      "experiment_57/216, took 121.7sec, 26.39% done\n",
      "experiment_58/216, took 136.6sec, 26.85% done\n",
      "experiment_59/216, took 98.5sec, 27.31% done\n",
      "experiment_60/216, took 98.6sec, 27.78% done\n",
      "experiment_61/216, took 100.8sec, 28.24% done\n",
      "experiment_62/216, took 97.6sec, 28.70% done\n",
      "experiment_63/216, took 97.9sec, 29.17% done\n",
      "experiment_64/216, took 117.3sec, 29.63% done\n",
      "experiment_65/216, took 109.4sec, 30.09% done\n",
      "experiment_66/216, took 102.5sec, 30.56% done\n",
      "experiment_67/216, took 111.3sec, 31.02% done\n",
      "experiment_68/216, took 84.0sec, 31.48% done\n",
      "experiment_69/216, took 84.9sec, 31.94% done\n",
      "experiment_70/216, took 84.6sec, 32.41% done\n",
      "experiment_71/216, took 83.6sec, 32.87% done\n",
      "experiment_72/216, took 83.7sec, 33.33% done\n",
      "experiment_73/216, took 89.9sec, 33.80% done\n",
      "experiment_74/216, took 72.7sec, 34.26% done\n",
      "experiment_75/216, took 72.6sec, 34.72% done\n",
      "experiment_76/216, took 87.9sec, 35.19% done\n",
      "experiment_77/216, took 71.5sec, 35.65% done\n",
      "experiment_78/216, took 70.3sec, 36.11% done\n",
      "experiment_79/216, took 72.8sec, 36.57% done\n",
      "experiment_80/216, took 71.0sec, 37.04% done\n",
      "experiment_81/216, took 70.4sec, 37.50% done\n",
      "experiment_82/216, took 96.2sec, 37.96% done\n",
      "experiment_83/216, took 91.0sec, 38.43% done\n",
      "experiment_84/216, took 87.2sec, 38.89% done\n",
      "experiment_85/216, took 89.4sec, 39.35% done\n",
      "experiment_86/216, took 86.5sec, 39.81% done\n",
      "experiment_87/216, took 77.0sec, 40.28% done\n",
      "experiment_88/216, took 77.2sec, 40.74% done\n",
      "experiment_89/216, took 77.4sec, 41.20% done\n",
      "experiment_90/216, took 77.3sec, 41.67% done\n",
      "experiment_91/216, took 78.4sec, 42.13% done\n",
      "experiment_92/216, took 76.9sec, 42.59% done\n",
      "experiment_93/216, took 66.9sec, 43.06% done\n",
      "experiment_94/216, took 76.1sec, 43.52% done\n",
      "experiment_95/216, took 74.6sec, 43.98% done\n",
      "experiment_96/216, took 67.9sec, 44.44% done\n",
      "experiment_97/216, took 67.0sec, 44.91% done\n",
      "experiment_98/216, took 66.9sec, 45.37% done\n",
      "experiment_99/216, took 67.0sec, 45.83% done\n",
      "experiment_100/216, took 64.2sec, 46.30% done\n",
      "experiment_101/216, took 63.5sec, 46.76% done\n",
      "experiment_102/216, took 60.7sec, 47.22% done\n",
      "experiment_103/216, took 62.7sec, 47.69% done\n",
      "experiment_104/216, took 56.5sec, 48.15% done\n",
      "experiment_105/216, took 56.6sec, 48.61% done\n",
      "experiment_106/216, took 56.5sec, 49.07% done\n",
      "experiment_107/216, took 56.8sec, 49.54% done\n",
      "experiment_108/216, took 56.6sec, 50.00% done\n",
      "experiment_109/216, took 178.2sec, 50.46% done\n",
      "experiment_110/216, took 187.5sec, 50.93% done\n",
      "experiment_111/216, took 169.3sec, 51.39% done\n",
      "experiment_112/216, took 200.0sec, 51.85% done\n",
      "experiment_113/216, took 188.7sec, 52.31% done\n",
      "experiment_114/216, took 132.9sec, 52.78% done\n",
      "experiment_115/216, took 151.9sec, 53.24% done\n",
      "experiment_116/216, took 133.3sec, 53.70% done\n",
      "experiment_117/216, took 131.4sec, 54.17% done\n",
      "experiment_118/216, took 141.0sec, 54.63% done\n",
      "experiment_119/216, took 145.6sec, 55.09% done\n",
      "experiment_120/216, took 138.1sec, 55.56% done\n",
      "experiment_121/216, took 155.3sec, 56.02% done\n",
      "experiment_122/216, took 110.1sec, 56.48% done\n",
      "experiment_123/216, took 110.0sec, 56.94% done\n",
      "experiment_124/216, took 129.3sec, 57.41% done\n",
      "experiment_125/216, took 109.7sec, 57.87% done\n",
      "experiment_126/216, took 109.9sec, 58.33% done\n",
      "experiment_127/216, took 113.2sec, 58.80% done\n",
      "experiment_128/216, took 108.9sec, 59.26% done\n",
      "experiment_129/216, took 99.1sec, 59.72% done\n",
      "experiment_130/216, took 126.9sec, 60.19% done\n",
      "experiment_131/216, took 87.9sec, 60.65% done\n",
      "experiment_132/216, took 87.9sec, 61.11% done\n",
      "experiment_133/216, took 87.6sec, 61.57% done\n",
      "experiment_134/216, took 87.5sec, 62.04% done\n",
      "experiment_135/216, took 87.3sec, 62.50% done\n",
      "experiment_136/216, took 144.3sec, 62.96% done\n",
      "experiment_137/216, took 145.4sec, 63.43% done\n",
      "experiment_138/216, took 141.3sec, 63.89% done\n",
      "experiment_139/216, took 149.7sec, 64.35% done\n",
      "experiment_140/216, took 140.3sec, 64.81% done\n",
      "experiment_141/216, took 127.8sec, 65.28% done\n",
      "experiment_142/216, took 135.0sec, 65.74% done\n",
      "experiment_143/216, took 127.6sec, 66.20% done\n",
      "experiment_144/216, took 127.7sec, 66.67% done\n",
      "experiment_145/216, took 118.4sec, 67.13% done\n",
      "experiment_146/216, took 120.1sec, 67.59% done\n",
      "experiment_147/216, took 116.7sec, 68.06% done\n",
      "experiment_148/216, took 119.5sec, 68.52% done\n",
      "experiment_149/216, took 118.3sec, 68.98% done\n",
      "experiment_150/216, took 107.2sec, 69.44% done\n",
      "experiment_151/216, took 109.8sec, 69.91% done\n",
      "experiment_152/216, took 107.1sec, 70.37% done\n",
      "experiment_153/216, took 107.1sec, 70.83% done\n",
      "experiment_154/216, took 93.9sec, 71.30% done\n",
      "experiment_155/216, took 93.5sec, 71.76% done\n",
      "experiment_156/216, took 86.1sec, 72.22% done\n",
      "experiment_157/216, took 97.0sec, 72.69% done\n",
      "experiment_158/216, took 86.1sec, 73.15% done\n",
      "experiment_159/216, took 86.2sec, 73.61% done\n",
      "experiment_160/216, took 86.0sec, 74.07% done\n",
      "experiment_161/216, took 86.0sec, 74.54% done\n",
      "experiment_162/216, took 86.4sec, 75.00% done\n",
      "experiment_163/216, took 136.7sec, 75.46% done\n",
      "experiment_164/216, took 130.4sec, 75.93% done\n",
      "experiment_165/216, took 124.6sec, 76.39% done\n",
      "experiment_166/216, took 131.8sec, 76.85% done\n",
      "experiment_167/216, took 98.9sec, 77.31% done\n",
      "experiment_168/216, took 100.0sec, 77.78% done\n",
      "experiment_169/216, took 101.8sec, 78.24% done\n",
      "experiment_170/216, took 100.1sec, 78.70% done\n",
      "experiment_171/216, took 100.2sec, 79.17% done\n",
      "experiment_172/216, took 116.5sec, 79.63% done\n",
      "experiment_173/216, took 112.6sec, 80.09% done\n",
      "experiment_174/216, took 86.1sec, 80.56% done\n",
      "experiment_175/216, took 114.1sec, 81.02% done\n",
      "experiment_176/216, took 86.8sec, 81.48% done\n",
      "experiment_177/216, took 88.8sec, 81.94% done\n",
      "experiment_178/216, took 85.3sec, 82.41% done\n",
      "experiment_179/216, took 85.8sec, 82.87% done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_180/216, took 84.2sec, 83.33% done\n",
      "experiment_181/216, took 92.3sec, 83.80% done\n",
      "experiment_182/216, took 71.5sec, 84.26% done\n",
      "experiment_183/216, took 70.8sec, 84.72% done\n",
      "experiment_184/216, took 71.3sec, 85.19% done\n",
      "experiment_185/216, took 71.6sec, 85.65% done\n",
      "experiment_186/216, took 72.1sec, 86.11% done\n",
      "experiment_187/216, took 71.5sec, 86.57% done\n",
      "experiment_188/216, took 71.5sec, 87.04% done\n",
      "experiment_189/216, took 71.9sec, 87.50% done\n",
      "experiment_190/216, took 92.0sec, 87.96% done\n",
      "experiment_191/216, took 91.1sec, 88.43% done\n",
      "experiment_192/216, took 89.3sec, 88.89% done\n",
      "experiment_193/216, took 88.9sec, 89.35% done\n",
      "experiment_194/216, took 85.4sec, 89.81% done\n",
      "experiment_195/216, took 76.8sec, 90.28% done\n",
      "experiment_196/216, took 76.9sec, 90.74% done\n",
      "experiment_197/216, took 76.8sec, 91.20% done\n",
      "experiment_198/216, took 77.0sec, 91.67% done\n",
      "experiment_199/216, took 77.2sec, 92.13% done\n",
      "experiment_200/216, took 74.5sec, 92.59% done\n",
      "experiment_201/216, took 67.1sec, 93.06% done\n",
      "experiment_202/216, took 75.6sec, 93.52% done\n",
      "experiment_203/216, took 66.5sec, 93.98% done\n",
      "experiment_204/216, took 66.8sec, 94.44% done\n",
      "experiment_205/216, took 66.5sec, 94.91% done\n",
      "experiment_206/216, took 59.9sec, 95.37% done\n",
      "experiment_207/216, took 35.9sec, 95.83% done\n",
      "experiment_208/216, took 33.3sec, 96.30% done\n",
      "experiment_209/216, took 29.8sec, 96.76% done\n",
      "experiment_210/216, took 29.8sec, 97.22% done\n",
      "experiment_211/216, took 30.0sec, 97.69% done\n",
      "experiment_212/216, took 29.7sec, 98.15% done\n",
      "experiment_213/216, took 30.6sec, 98.61% done\n",
      "experiment_214/216, took 30.8sec, 99.07% done\n",
      "experiment_215/216, took 30.3sec, 99.54% done\n",
      "experiment_216/216, took 30.3sec, 100.00% done\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print('##### Start #####')\n",
    "\n",
    "num = 0 #초기화\n",
    "\n",
    "for var1 in list_var1:\n",
    "    for var2 in list_var2:\n",
    "        for var3 in list_var3:\n",
    "            for var4 in list_var4:\n",
    "                for var5 in list_var5:\n",
    "                    for var6 in list_var6:\n",
    "                        for var7 in list_var7:\n",
    "                            for var8 in list_var8:\n",
    "                                for var9 in list_var9:\n",
    "                                    for var10 in list_var10:\n",
    "                                        for var11 in list_var11:\n",
    "                                            ts = time.time()\n",
    "                                            num += 1\n",
    "                                            setattr(args, name_var1, var1)\n",
    "                                            setattr(args, name_var2, var2)\n",
    "                                            setattr(args, name_var3, var3)\n",
    "                                            setattr(args, name_var4, var4)\n",
    "                                            setattr(args, name_var5, var5)\n",
    "                                            setattr(args, name_var6, var6)\n",
    "                                            setattr(args, name_var7, var7)\n",
    "                                            setattr(args, name_var8, var8)\n",
    "                                            setattr(args, name_var9, var9)\n",
    "                                            setattr(args, name_var10, var10)\n",
    "                                            setattr(args, name_var11, var11)\n",
    "\n",
    "#                                             print('experiment_{}/{} : x_frames = {}, loss={}, optim={}, use_bn={}, dropout={}, batch_size={}, hid_dim={}, n_layers={}, lr={}, l2={}, epoch={}'\n",
    "#                                                   .format(num,total_exp_num,args.x_frames,args.loss,args.optim,args.use_bn,args.dropout,args.batch_size,args.hid_dim,args.n_layers,args.lr,args.l2,args.epoch))\n",
    "                                            result_info, result_data = experiment(partition, deepcopy(args))\n",
    "    \n",
    "                                            min_RMSE = min(result_info['val_accs_RMSE'])\n",
    "                                            max_R2 = max(result_info['val_accs_R2'])\n",
    "#                                             RMSE_ = result_info['val_accs_RMSE']\n",
    "#                                             R2_ = result_info['val_accs_R2']\n",
    "                                            epoch = args.epoch\n",
    "                                            \n",
    "                                            result_info.to_csv('exp{:03d}_info_RMSE[{:2.4f}]_R2[{:2.4f}].csv'.format(num,min_RMSE,max_R2))\n",
    "                                            result_data.to_csv('exp{:03d}_data_RMSE[{:2.4f}]_R2[{:2.4f}].csv'.format(num,min_RMSE,max_R2))\n",
    "                \n",
    "                                            file=open('exp_index.txt','a')\n",
    "                                            file.write('experiment {:03d}/{} : x_frames = {}, loss={}, optim={}, use_bn={}, dropout={}, batch_size={}, hid_dim={}, n_layers={}, lr={}, l2={}, epoch={}\\n'\n",
    "                                                       .format(num,total_exp_num,args.x_frames,args.loss,args.optim,args.use_bn,args.dropout,args.batch_size,args.hid_dim,args.n_layers,args.lr,args.l2,args.epoch))\n",
    "                                            file.close()\n",
    "\n",
    "                                            te = time.time()\n",
    "                                \n",
    "                                            print('experiment_{}/{}, took {:2.1f}sec, {:2.2f}% done'\n",
    "                                                  .format(num,total_exp_num,te-ts,(num/total_exp_num)*100))\n",
    "                                    \n",
    "#                                             network = LSTM(args.input_dim, args.hid_dim, args.y_frames, args.n_layers, args.batch_size, args.dropout, args.use_bn)\n",
    "#                                             torch.save(network.state_dict(),'lstm1.pt')\n",
    "                            \n",
    "                                       \n",
    "#                                             print('train_acc = {:2.2f}%, val_acc = {:2.2f}%, test_acc = {:2.2f}%'\n",
    "#                                                   .format(result['train_acc'],result['val_acc'],result['test_acc']))\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
