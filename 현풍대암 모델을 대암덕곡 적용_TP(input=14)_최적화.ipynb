{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMKHTsedaum7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import visdom\n",
    "vis = visdom.Visdom()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(torch.__version__)\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1gRd7qVcEwI"
   },
   "source": [
    "# 1. Data loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KShxDU_Jcj3u"
   },
   "source": [
    "### 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f39evpcvc1KK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsungpark/Desktop/jupyter/Data_river/original02/DA_DG\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jinsungpark/Desktop/jupyter/Data_river/original02/DA_DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTiRk82qctLD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DA_Up_data.xlsx\r\n",
      "DA_Up_log.xlsx\r\n",
      "DG_Down_data.xlsx\r\n",
      "DG_Down_log.xlsx\r\n",
      "현풍대암모델-대암덕곡적용_TP(input=10).csv\r\n",
      "현풍대암모델-대암덕곡적용_TP(input=14).csv\r\n",
      "현풍대암모델-대암덕곡적용_TP(input=14)_보개방이전.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls #현재경로에 있는 항목 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dln4LnKpc1CX"
   },
   "outputs": [],
   "source": [
    "UpStream_data = pd.read_excel('DA_Up_log.xlsx')\n",
    "DownStream_data = pd.read_excel('DG_Down_log.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GRAwoM_c068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'DA_DO', 'DA_BOD', 'DA_COD', 'DA_SS', 'DA_TN', 'DA_TP',\n",
      "       'DA_Chl_a', 'DA_Flow', 'HCh__DO', 'HCh__BOD', 'HCh__COD', 'HCh__SS',\n",
      "       'HCh__TN', 'HCh__TP', 'HCh__Chl_a', 'HCh__Flow', 'UiR_Rain',\n",
      "       'UiR_Solar', 'DA_Temp', 'HCh__Temp'],\n",
      "      dtype='object')\n",
      "Index(['Date', 'DG_DO', 'DG_BOD', 'DG_COD', 'DG_SS', 'DG_TN', 'DG_TP',\n",
      "       'DG_Chl_a'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(UpStream_data.columns)\n",
    "print(DownStream_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uneezLbLdGiC"
   },
   "outputs": [],
   "source": [
    "#날짜 인덱스화\n",
    "UpData = UpStream_data.set_index('Date')\n",
    "DownData = DownStream_data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 265 entries, 2013-01-07 to 2019-09-24\n",
      "Data columns (total 20 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   DA_DO       265 non-null    float64\n",
      " 1   DA_BOD      265 non-null    float64\n",
      " 2   DA_COD      265 non-null    float64\n",
      " 3   DA_SS       265 non-null    float64\n",
      " 4   DA_TN       265 non-null    float64\n",
      " 5   DA_TP       265 non-null    float64\n",
      " 6   DA_Chl_a    265 non-null    float64\n",
      " 7   DA_Flow     265 non-null    float64\n",
      " 8   HCh__DO     265 non-null    float64\n",
      " 9   HCh__BOD    265 non-null    float64\n",
      " 10  HCh__COD    265 non-null    float64\n",
      " 11  HCh__SS     265 non-null    float64\n",
      " 12  HCh__TN     265 non-null    float64\n",
      " 13  HCh__TP     265 non-null    float64\n",
      " 14  HCh__Chl_a  265 non-null    float64\n",
      " 15  HCh__Flow   265 non-null    float64\n",
      " 16  UiR_Rain    265 non-null    float64\n",
      " 17  UiR_Solar   265 non-null    float64\n",
      " 18  DA_Temp     265 non-null    float64\n",
      " 19  HCh__Temp   265 non-null    float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 43.5 KB\n"
     ]
    }
   ],
   "source": [
    "UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rSPrna-c0pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 265 entries, 2013-01-07 to 2019-09-24\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   DA_DO      265 non-null    float64\n",
      " 1   DA_COD     265 non-null    float64\n",
      " 2   DA_SS      265 non-null    float64\n",
      " 3   DA_TN      265 non-null    float64\n",
      " 4   DA_TP      265 non-null    float64\n",
      " 5   DA_Temp    265 non-null    float64\n",
      " 6   DA_Flow    265 non-null    float64\n",
      " 7   HCh__DO    265 non-null    float64\n",
      " 8   HCh__COD   265 non-null    float64\n",
      " 9   HCh__TN    265 non-null    float64\n",
      " 10  HCh__TP    265 non-null    float64\n",
      " 11  HCh__Temp  265 non-null    float64\n",
      " 12  HCh__Flow  265 non-null    float64\n",
      " 13  UiR_Rain   265 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 31.1 KB\n"
     ]
    }
   ],
   "source": [
    "#넣고싶은 상류 항목 컬럼 선택 - TP setting(input:14)\n",
    "UpData = UpData.iloc[:,[0,2,3,4,5,18,7,8,10,12,13,19,15,16]]\n",
    "UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #넣고싶은 상류 항목 컬럼 선택 - TP setting(input:10)\n",
    "# UpData = UpData.iloc[:,[0,2,3,4,5,18,12,13,15,16]]\n",
    "# print(UpData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #넣고싶은 상류 항목 컬럼 선택 - TN setting\n",
    "# UpData = UpData.iloc[:,[0,4,5,18,7,8,10,12,13,19,15,16,17]]\n",
    "# UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 265 entries, 2013-01-07 to 2019-09-24\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DG_DO     265 non-null    float64\n",
      " 1   DG_BOD    265 non-null    float64\n",
      " 2   DG_COD    265 non-null    float64\n",
      " 3   DG_SS     265 non-null    float64\n",
      " 4   DG_TN     265 non-null    float64\n",
      " 5   DG_TP     265 non-null    float64\n",
      " 6   DG_Chl_a  265 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 16.6 KB\n"
     ]
    }
   ],
   "source": [
    "DownData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rSPrna-c0pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DG_TP\n"
     ]
    }
   ],
   "source": [
    "#알고싶은 하류 항목 컬럼 넘버 넣기('Date'항목이 인덱스화 돼서 컬럼 넘버가 -1씩 됨)\n",
    "Colum = 5\n",
    "print(DownData.columns[Colum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KShxDU_Jcj3u"
   },
   "source": [
    "### 1.1 Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2Tp4o0Hc0ZL"
   },
   "source": [
    "### 1.2 Data Preprocessing(normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChKYCAtTdGpA"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "UpScaler = MinMaxScaler() #상류데이터용\n",
    "DownScaler = MinMaxScaler() #하류데이터용\n",
    "\n",
    "#나중에 결과를 DeNormalizing 하기 위해 나누어 사용 하였다.\n",
    "\n",
    "def DeNormalize(Y, Data_name, column_num, Scaler_Type):\n",
    "    \n",
    "    data = Data_name\n",
    "    Scaler = Scaler_Type\n",
    "    \n",
    "    _max = Scaler.data_max_[column_num] # 역정규화 하려는 데이터의 컬럼 번호\n",
    "    _min = Scaler.data_min_[column_num] \n",
    "    \n",
    "    X = Y*(_max-_min) + _min\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uneezLbLdGiC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DA_DO        0\n",
      "DA_COD       0\n",
      "DA_SS        0\n",
      "DA_TN        0\n",
      "DA_TP        0\n",
      "DA_Temp      0\n",
      "DA_Flow      0\n",
      "HCh__DO      0\n",
      "HCh__COD     0\n",
      "HCh__TN      0\n",
      "HCh__TP      0\n",
      "HCh__Temp    0\n",
      "HCh__Flow    0\n",
      "UiR_Rain     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#데이터 정규화\n",
    "UpData = pd.DataFrame(UpScaler.fit_transform(UpData), columns=UpData.columns, index=UpData.index)\n",
    "DownData = pd.DataFrame(DownScaler.fit_transform(DownData), columns=DownData.columns, index=DownData.index)\n",
    "\n",
    "print(UpData.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDSVZGiUdGYz"
   },
   "source": [
    "#2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hxm2moSudGQD"
   },
   "outputs": [],
   "source": [
    "class RiverDataset(Dataset):\n",
    "    def __init__(self, UpData, DownData, x_frames, y_frames, start, end):\n",
    "        \n",
    "        self.x_frames = x_frames\n",
    "        self.y_frames = y_frames\n",
    "        \n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "        self.UpData = UpData[start:end]\n",
    "        self.DownData = DownData[start:end]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.UpData) - (self.x_frames + self.y_frames) + 1\n",
    "    #데이터를 전처리 할때 UpData와 DownData의 길이가 동일해짐(날짜를 동일한것만 추출해야 하므로), 따라서 전체길이는 둘중 하나를 사용\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.x_frames\n",
    "\n",
    "        X = self.UpData.iloc[idx-self.x_frames:idx].values\n",
    "        Y = self.DownData.iloc[idx:idx+self.y_frames].values\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fj80CahhdGG9"
   },
   "source": [
    "# 3. Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_edit(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_edit, self).__init__()\n",
    "        self.input_dim = 14\n",
    "        self.hidden_dim = 32\n",
    "        self.output_dim = 1\n",
    "        self.num_layers = 3\n",
    "\n",
    "        self.batch_size = 8\n",
    "        self.dropout = 0.1\n",
    "        self.use_bn = False\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers) #\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.regressor = self.make_regressor()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def make_regressor(self):\n",
    "        layers = []\n",
    "        if self.use_bn:\n",
    "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "        layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
    "        regressor = nn.Sequential(*layers)\n",
    "        return regressor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #input=10\n",
    "# class LSTM_edit(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(LSTM_edit, self).__init__()\n",
    "#         self.input_dim = 10\n",
    "#         self.hidden_dim = 32\n",
    "#         self.output_dim = 1\n",
    "#         self.num_layers = 3\n",
    "\n",
    "#         self.batch_size = 8\n",
    "#         self.dropout = 0.1\n",
    "#         self.use_bn = False\n",
    "        \n",
    "#         self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers) #\n",
    "#         self.hidden = self.init_hidden()\n",
    "#         self.regressor = self.make_regressor()\n",
    "        \n",
    "#     def init_hidden(self):\n",
    "#         return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "#                 torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "#     def make_regressor(self):\n",
    "#         layers = []\n",
    "#         if self.use_bn:\n",
    "#             layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "#         layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "#         layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
    "#         layers.append(nn.ReLU())\n",
    "#         layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
    "#         regressor = nn.Sequential(*layers)\n",
    "#         return regressor\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "#         y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
    "#         return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTpV_o6Wdglq"
   },
   "outputs": [],
   "source": [
    "# 정확도 : 예측확률을 100%로 봤을때 MAPE에 따른 오차비율을 빼줌 (100-MAPE) ##RMSE, MAPE 두개로 볼 수 있게\n",
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    R2_score = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "    return R2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GPb8H8-djwB"
   },
   "source": [
    "# 4. Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_edit(model):\n",
    "    testloader = DataLoader(testset,\n",
    "                           batch_size=8,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    print('start')\n",
    "    model.eval()\n",
    "\n",
    "    bat_siz = 8\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X = X.transpose(0, 1).float()\n",
    "            y_true = y[:, :, Colum].float()\n",
    "            model.hidden = [hidden for hidden in model.init_hidden()]\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            pred.append(y_pred)\n",
    "            true.append(y_true)\n",
    "\n",
    "    # ==== test 데이터 시각화를 위해 x,y데이터 저장 ==== #\n",
    "    for i in range(len(testloader)):\n",
    "        tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "        tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(bat_siz):\n",
    "            value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "            value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "            \n",
    "            pred_results.append(value1)\n",
    "            true_results.append(value2)\n",
    "    # ========================================== #   \n",
    "\n",
    "    test_acc1 =  RMSE(np.array( true_results), np.array(pred_results))\n",
    "    test_acc2 =  R2(np.array( true_results), np.array(pred_results))\n",
    "#     test_acc3 =  (100 - MAPE(np.array( true_results), np.array(pred_results)))\n",
    "    print('end')\n",
    "    \n",
    "    return test_acc1[0], test_acc2[0], pred_results, true_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkkF0-qmeOMq"
   },
   "source": [
    "# 5. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNi-f5HyeJYi"
   },
   "source": [
    "# 6. LSTM Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Current CPU random seed:',torch.initial_seed())\n",
    "# print('Current CUDA random seed:',torch.cuda.initial_seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.text('loseFunc = {}, optim={}, x_frames={}, n_layers={}, batch_size={}, hid_dim={}, epoch={}, lr={}, l2={}, dropout={}, use_bn={}'\n",
    "#                              .format(args.loss,args.optim,args.x_frames,args.n_layers,args.batch_size,args.hid_dim,args.epoch,args.lr,args.l2,args.dropout,args.use_bn),\n",
    "#                              opts=dict(title='exp_{}_text'.format(num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 666\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "\n",
    "# network = LSTM(14, 32, 1, 3, 4, 0.1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = RiverDataset(UpData, DownData, 4, 1, '2013-01-01', '2019-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "for number in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    modell = LSTM_edit()\n",
    "    modell.load_state_dict(torch.load('/Users/jinsungpark/Desktop/result/lstm[{}].pt'.format(number)))\n",
    "    RMSE_1, R2_1, Pred_1, True_1 = test_edit(modell)\n",
    "\n",
    "    test_data = pd.DataFrame()\n",
    "    test_data['test_pred'] = Pred_1\n",
    "    test_data['test_true'] = True_1\n",
    "\n",
    "    acc1 = RMSE(np.array(True_1), np.array(Pred_1))[0]\n",
    "    acc2 = R2(np.array(True_1), np.array(Pred_1))[0]\n",
    "\n",
    "    result = test_data\n",
    "\n",
    "    predict = torch.Tensor(result['test_pred']).view(-1,1)\n",
    "    truth = torch.Tensor(result['test_true']).view(-1,1)\n",
    "    axis = torch.Tensor(range(len(result['test_pred']))).view(-1,1)\n",
    "\n",
    "    Y_axis = torch.cat((predict, truth), -1)\n",
    "    X_axis = torch.cat((axis, axis), -1)\n",
    "\n",
    "    vis.line(Y = Y_axis, X = X_axis, opts=dict(title='Result_{},RMSE[{:2.3f}],R2[{:2.3f}]'\n",
    "                                               .format(number,acc1,acc2),\n",
    "                                               legend=['predict','true'],\n",
    "                                               showlegend=True,\n",
    "                                               layoutopts = {'plotly': {'legend': {'x':0, 'y':0}}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "modell = LSTM_edit()\n",
    "modell.load_state_dict(torch.load('lstm[12].pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "RMSE_1, R2_1, Pred_1, True_1 = test_edit(modell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame()\n",
    "test_data['test_pred'] = Pred_1\n",
    "test_data['test_true'] = True_1\n",
    "\n",
    "acc1 = RMSE(np.array(True_1), np.array(Pred_1))[0]\n",
    "acc2 = R2(np.array(True_1), np.array(Pred_1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_data\n",
    "\n",
    "predict = torch.Tensor(result['test_pred']).view(-1,1)\n",
    "truth = torch.Tensor(result['test_true']).view(-1,1)\n",
    "axis = torch.Tensor(range(len(result['test_pred']))).view(-1,1)\n",
    "\n",
    "Y_axis = torch.cat((predict, truth), -1)\n",
    "X_axis = torch.cat((axis, axis), -1)\n",
    "\n",
    "vis.line(Y = Y_axis, X = X_axis, opts=dict(title='Result,RMSE[{:2.3f}],R2[{:2.3f}]'\n",
    "                                           .format(acc1,acc2),\n",
    "                                           legend=['predict','true'],\n",
    "                                           showlegend=True,\n",
    "                                           layoutopts = {'plotly': {'legend': {'x':0, 'y':0}}}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
