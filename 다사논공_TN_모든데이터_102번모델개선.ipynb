{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMKHTsedaum7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import argparse\n",
    "from copy import deepcopy #Add Deepcopy for args\n",
    "import visdom\n",
    "vis = visdom.Visdom()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(torch.__version__)\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1gRd7qVcEwI"
   },
   "source": [
    "# 1. Data loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KShxDU_Jcj3u"
   },
   "source": [
    "### 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f39evpcvc1KK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsungpark/Desktop/jupyter/Data_river/data04\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jinsungpark/Desktop/jupyter/Data_river/data04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTiRk82qctLD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS_Data_edit.xlsx      NG_Data_edit.xlsx      lstm02.pt\r\n",
      "DS_Data_edit_log.xlsx  NG_Data_edit_log.xlsx  \u001b[34mmodel_save\u001b[m\u001b[m/\r\n",
      "DS_data.xlsx           NG_data.xlsx           \u001b[34mresults\u001b[m\u001b[m/\r\n",
      "DS_to_NG.xlsx          UpData.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls #현재경로에 있는 항목 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dln4LnKpc1CX"
   },
   "outputs": [],
   "source": [
    "UpStream_data = pd.read_excel('DS_Data_edit_log.xlsx')\n",
    "DownStream_data = pd.read_excel('NG_Data_edit_log.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GRAwoM_c068"
   },
   "outputs": [],
   "source": [
    "# print(UpStream_data.columns)\n",
    "# print(DownStream_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uneezLbLdGiC"
   },
   "outputs": [],
   "source": [
    "#날짜 인덱스화\n",
    "UpData = UpStream_data.set_index('Date')\n",
    "DownData = DownStream_data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 349 entries, 2013-01-07 to 2019-09-30\n",
      "Data columns (total 43 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   DS_DO              349 non-null    float64\n",
      " 1   DS_BOD             349 non-null    float64\n",
      " 2   DS_COD             349 non-null    float64\n",
      " 3   DS_SS              349 non-null    float64\n",
      " 4   DS_TN              349 non-null    float64\n",
      " 5   DS_TP              349 non-null    float64\n",
      " 6   DS_Chl_a           349 non-null    float64\n",
      " 7   DS_Cells           349 non-null    float64\n",
      " 8   GJ_Deep            349 non-null    float64\n",
      " 9   GJ_Level           349 non-null    float64\n",
      " 10  GJ_Outflow         349 non-null    float64\n",
      " 11  DaeGu_Rain         349 non-null    float64\n",
      " 12  DaeGu_Solar        349 non-null    float64\n",
      " 13  SeoBu_COD          349 non-null    float64\n",
      " 14  SeoBu_SS           349 non-null    float64\n",
      " 15  SeoBu_TN           349 non-null    float64\n",
      " 16  SeoBu_TP           349 non-null    float64\n",
      " 17  SeoBu_Flow_mean    349 non-null    float64\n",
      " 18  SeoBu_Flow_day     349 non-null    float64\n",
      " 19  SeoBu_COD_load     349 non-null    float64\n",
      " 20  SeoBu_SS_load      349 non-null    float64\n",
      " 21  SeoBu_TN_load      349 non-null    float64\n",
      " 22  SeoBu_TP_load      349 non-null    float64\n",
      " 23  SungSeo_COD        349 non-null    float64\n",
      " 24  SungSeo_SS         349 non-null    float64\n",
      " 25  SungSeo_TN         349 non-null    float64\n",
      " 26  SungSeo_TP         349 non-null    float64\n",
      " 27  SungSeo_Flow_mean  349 non-null    float64\n",
      " 28  SungSeo_Flow_day   349 non-null    float64\n",
      " 29  SungSeo_COD_load   349 non-null    float64\n",
      " 30  SungSeo_SS_load    349 non-null    float64\n",
      " 31  SungSeo_TN_load    349 non-null    float64\n",
      " 32  SungSeo_TP_load    349 non-null    float64\n",
      " 33  GumHo_DO           349 non-null    float64\n",
      " 34  GumHo_BOD          349 non-null    float64\n",
      " 35  GumHo_COD          349 non-null    float64\n",
      " 36  GumHo_SS           349 non-null    float64\n",
      " 37  GumHo_TN           349 non-null    float64\n",
      " 38  GumHo_TP           349 non-null    float64\n",
      " 39  GumHo_Chl_a        349 non-null    float64\n",
      " 40  GumHo_Flow         349 non-null    float64\n",
      " 41  DS_Temp            349 non-null    float64\n",
      " 42  GumHo_Temp         349 non-null    float64\n",
      "dtypes: float64(43)\n",
      "memory usage: 120.0+ KB\n"
     ]
    }
   ],
   "source": [
    "UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rSPrna-c0pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 349 entries, 2013-01-07 to 2019-09-30\n",
      "Data columns (total 33 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   DS_DO              349 non-null    float64\n",
      " 1   DS_BOD             349 non-null    float64\n",
      " 2   DS_COD             349 non-null    float64\n",
      " 3   DS_SS              349 non-null    float64\n",
      " 4   DS_TN              349 non-null    float64\n",
      " 5   DS_TP              349 non-null    float64\n",
      " 6   DS_Chl_a           349 non-null    float64\n",
      " 7   DS_Cells           349 non-null    float64\n",
      " 8   GJ_Deep            349 non-null    float64\n",
      " 9   GJ_Level           349 non-null    float64\n",
      " 10  GJ_Outflow         349 non-null    float64\n",
      " 11  DaeGu_Rain         349 non-null    float64\n",
      " 12  DaeGu_Solar        349 non-null    float64\n",
      " 13  SeoBu_COD          349 non-null    float64\n",
      " 14  SeoBu_SS           349 non-null    float64\n",
      " 15  SeoBu_TN           349 non-null    float64\n",
      " 16  SeoBu_TP           349 non-null    float64\n",
      " 17  SeoBu_Flow_mean    349 non-null    float64\n",
      " 18  SungSeo_COD        349 non-null    float64\n",
      " 19  SungSeo_SS         349 non-null    float64\n",
      " 20  SungSeo_TN         349 non-null    float64\n",
      " 21  SungSeo_TP         349 non-null    float64\n",
      " 22  SungSeo_Flow_mean  349 non-null    float64\n",
      " 23  GumHo_DO           349 non-null    float64\n",
      " 24  GumHo_BOD          349 non-null    float64\n",
      " 25  GumHo_COD          349 non-null    float64\n",
      " 26  GumHo_SS           349 non-null    float64\n",
      " 27  GumHo_TN           349 non-null    float64\n",
      " 28  GumHo_TP           349 non-null    float64\n",
      " 29  GumHo_Chl_a        349 non-null    float64\n",
      " 30  GumHo_Flow         349 non-null    float64\n",
      " 31  DS_Temp            349 non-null    float64\n",
      " 32  GumHo_Temp         349 non-null    float64\n",
      "dtypes: float64(33)\n",
      "memory usage: 92.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#넣고싶은 상류 항목 컬럼 선택 - TP=TN all setting\n",
    "UpData = UpData.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,23,24,25,26,27,33,34,35,36,37,38,39,40,41,42]]\n",
    "UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #넣고싶은 상류 항목 컬럼 선택 - TN setting\n",
    "# UpData = UpData.iloc[:,[0,4,5,18,7,8,10,12,13,19,15,16,17]]\n",
    "# UpData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 349 entries, 2013-01-07 to 2019-09-30\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   NG_DO     349 non-null    float64\n",
      " 1   NG_BOD    349 non-null    float64\n",
      " 2   NG_COD    349 non-null    float64\n",
      " 3   NG_SS     349 non-null    float64\n",
      " 4   NG_TN     349 non-null    float64\n",
      " 5   NG_TP     349 non-null    float64\n",
      " 6   NG_Chl_a  349 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 21.8+ KB\n"
     ]
    }
   ],
   "source": [
    "DownData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rSPrna-c0pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NG_TN\n"
     ]
    }
   ],
   "source": [
    "#알고싶은 하류 항목 컬럼 넘버 넣기('Date'항목이 인덱스화 돼서 컬럼 넘버가 -1씩 됨)\n",
    "Colum = 4\n",
    "print(DownData.columns[Colum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2Tp4o0Hc0ZL"
   },
   "source": [
    "### 1.2 Data Preprocessing(normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChKYCAtTdGpA"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "UpScaler = MinMaxScaler() #상류데이터용\n",
    "DownScaler = MinMaxScaler() #하류데이터용\n",
    "\n",
    "#나중에 결과를 DeNormalizing 하기 위해 나누어 사용 하였다.\n",
    "\n",
    "def DeNormalize(Y, Data_name, column_num, Scaler_Type):\n",
    "    \n",
    "    data = Data_name\n",
    "    Scaler = Scaler_Type\n",
    "    \n",
    "    _max = Scaler.data_max_[column_num] # 역정규화 하려는 데이터의 컬럼 번호\n",
    "    _min = Scaler.data_min_[column_num] \n",
    "    \n",
    "    X = Y*(_max-_min) + _min\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uneezLbLdGiC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS_DO                0\n",
      "DS_BOD               0\n",
      "DS_COD               0\n",
      "DS_SS                0\n",
      "DS_TN                0\n",
      "DS_TP                0\n",
      "DS_Chl_a             0\n",
      "DS_Cells             0\n",
      "GJ_Deep              0\n",
      "GJ_Level             0\n",
      "GJ_Outflow           0\n",
      "DaeGu_Rain           0\n",
      "DaeGu_Solar          0\n",
      "SeoBu_COD            0\n",
      "SeoBu_SS             0\n",
      "SeoBu_TN             0\n",
      "SeoBu_TP             0\n",
      "SeoBu_Flow_mean      0\n",
      "SungSeo_COD          0\n",
      "SungSeo_SS           0\n",
      "SungSeo_TN           0\n",
      "SungSeo_TP           0\n",
      "SungSeo_Flow_mean    0\n",
      "GumHo_DO             0\n",
      "GumHo_BOD            0\n",
      "GumHo_COD            0\n",
      "GumHo_SS             0\n",
      "GumHo_TN             0\n",
      "GumHo_TP             0\n",
      "GumHo_Chl_a          0\n",
      "GumHo_Flow           0\n",
      "DS_Temp              0\n",
      "GumHo_Temp           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#데이터 정규화\n",
    "UpData = pd.DataFrame(UpScaler.fit_transform(UpData), columns=UpData.columns, index=UpData.index)\n",
    "DownData = pd.DataFrame(DownScaler.fit_transform(DownData), columns=DownData.columns, index=DownData.index)\n",
    "\n",
    "print(UpData.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDSVZGiUdGYz"
   },
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hxm2moSudGQD"
   },
   "outputs": [],
   "source": [
    "class RiverDataset(Dataset):\n",
    "    def __init__(self, UpData, DownData, x_frames, y_frames, start, end):\n",
    "        \n",
    "        self.x_frames = x_frames\n",
    "        self.y_frames = y_frames\n",
    "        \n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "        self.UpData = UpData[start:end]\n",
    "        self.DownData = DownData[start:end]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.UpData) - (self.x_frames + self.y_frames) + 1\n",
    "    #데이터를 전처리 할때 UpData와 DownData의 길이가 동일해짐(날짜를 동일한것만 추출해야 하므로), 따라서 전체길이는 둘중 하나를 사용\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.x_frames\n",
    "\n",
    "        X = self.UpData.iloc[idx-self.x_frames:idx].values\n",
    "        Y = self.DownData.iloc[idx:idx+self.y_frames].values\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fj80CahhdGG9"
   },
   "source": [
    "# 3. Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuBGEc51dF-V"
   },
   "outputs": [],
   "source": [
    "# class LSTM(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_layers, batch_size, dropout, use_bn):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.input_dim = input_dim \n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_dim = output_dim\n",
    "#         self.num_layers = num_layers\n",
    "\n",
    "#         self.batch_size = batch_size\n",
    "#         self.dropout = dropout\n",
    "#         self.use_bn = use_bn \n",
    "        \n",
    "#         self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers) #\n",
    "#         self.hidden = self.init_hidden()\n",
    "#         self.regressor = self.make_regressor()\n",
    "        \n",
    "#     def init_hidden(self):\n",
    "#         return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "#                 torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "#     def make_regressor(self):\n",
    "#         layers = []\n",
    "#         if self.use_bn:\n",
    "#             layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "#         layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "#         layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
    "#         layers.append(nn.ReLU())\n",
    "#         layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
    "#         regressor = nn.Sequential(*layers)\n",
    "#         return regressor\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "#         y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
    "#         return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_edit(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_edit, self).__init__()\n",
    "        self.input_dim = 33\n",
    "        self.hidden_dim = 64\n",
    "        self.output_dim = 1\n",
    "        self.num_layers = 2\n",
    "\n",
    "        self.batch_size = 8\n",
    "        self.dropout = 0.1\n",
    "        self.use_bn = False\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers) #\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.regressor = self.make_regressor()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def make_regressor(self):\n",
    "        layers = []\n",
    "        if self.use_bn:\n",
    "            layers.append(nn.BatchNorm1d(self.hidden_dim))\n",
    "        layers.append(nn.Dropout(self.dropout))\n",
    "        \n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim // 2))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim // 2, self.output_dim))\n",
    "        regressor = nn.Sequential(*layers)\n",
    "        return regressor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y_pred = self.regressor(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTpV_o6Wdglq"
   },
   "outputs": [],
   "source": [
    "# 정확도 : 예측확률을 100%로 봤을때 MAPE에 따른 오차비율을 빼줌 (100-MAPE) ##RMSE, MAPE 두개로 볼 수 있게\n",
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    R2_score = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "    return R2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GPb8H8-djwB"
   },
   "source": [
    "# 4. Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrT2W-pqdjh6"
   },
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, loss_fn, args):\n",
    "    trainloader = DataLoader(trainset,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False, drop_last=True)\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    bat_siz = args.batch_size\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "\n",
    "        X = X.transpose(0, 1).float().to(args.device)#파이토치는 순서가 달라서 바꿔줌\n",
    "        y_true = y[:, :, Colum].float().to(args.device)\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred.append(y_pred)\n",
    "        true.append(y_true)\n",
    "\n",
    "    # ========================================================================== #\n",
    "    for i in range(len(trainloader)):\n",
    "        tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "        tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(bat_siz):\n",
    "            value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "            value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "            \n",
    "            pred_results.append(value1)\n",
    "            true_results.append(value2)\n",
    "    # ========================================================================== #   \n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc1 = RMSE(np.array(true_results), np.array(pred_results))\n",
    "    train_acc2 = R2(np.array(true_results), np.array(pred_results))\n",
    "#     train_acc3 = (100 - MAPE(np.array(true_results), np.array(pred_results)))\n",
    "\n",
    "    return model, train_loss, train_acc1[0], train_acc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JvAO-LVCdjgG"
   },
   "outputs": [],
   "source": [
    "def validate(model, partition, loss_fn, args):\n",
    "    valloader = DataLoader(valset,\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    model.eval()\n",
    "\n",
    "    bat_siz = args.batch_size\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(valloader):\n",
    "\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y[:, :, Colum].float().to(args.device)\n",
    "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred.view(-1), y_true.view(-1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            pred.append(y_pred)\n",
    "            true.append(y_true)\n",
    "\n",
    "        # ========================================================================== #\n",
    "        for i in range(len(valloader)):\n",
    "            tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "            tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "\n",
    "            for j in range(bat_siz):\n",
    "                value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "                value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "\n",
    "                pred_results.append(value1)\n",
    "                true_results.append(value2)\n",
    "        # ========================================================================== #   \n",
    "\n",
    "    val_loss = val_loss / len(valloader)\n",
    "    val_acc1 = RMSE(np.array(true_results), np.array(pred_results))\n",
    "    val_acc2 = R2(np.array(true_results), np.array(pred_results))\n",
    "#     val_acc3 = (100 - MAPE(np.array(true_results), np.array(pred_results)))\n",
    "\n",
    "    \n",
    "    return val_loss, val_acc1[0], val_acc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHWmu5EtdjXu"
   },
   "outputs": [],
   "source": [
    "def test(model, partition, args):\n",
    "    testloader = DataLoader(partition['test'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    model.eval()\n",
    "\n",
    "    bat_siz = args.batch_size\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y[:, :, Colum].float().to(args.device)\n",
    "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            pred.append(y_pred)\n",
    "            true.append(y_true)\n",
    "\n",
    "    # =================== test 데이터 시각화를 위해 x,y데이터 저장 =================== #\n",
    "    for i in range(len(testloader)):\n",
    "        tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "        tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(bat_siz):\n",
    "            value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "            value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "            \n",
    "            pred_results.append(value1)\n",
    "            true_results.append(value2)\n",
    "    # ======================================================================== #   \n",
    "\n",
    "    test_acc1 =  RMSE(np.array( true_results), np.array(pred_results))\n",
    "    test_acc2 =  R2(np.array( true_results), np.array(pred_results))\n",
    "#     test_acc3 =  (100 - MAPE(np.array( true_results), np.array(pred_results)))\n",
    "    \n",
    "    return test_acc1[0], test_acc2[0], pred_results, true_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_edit(model):\n",
    "    testloader = DataLoader(testset,\n",
    "                           batch_size=8,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    print('start')\n",
    "    model.eval()\n",
    "\n",
    "    bat_siz = 8\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y[:, :, Colum].float().to(args.device)\n",
    "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            pred.append(y_pred)\n",
    "            true.append(y_true)\n",
    "\n",
    "    # ==== test 데이터 시각화를 위해 x,y데이터 저장 ==== #\n",
    "    for i in range(len(testloader)):\n",
    "        tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "        tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(bat_siz):\n",
    "            value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "            value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "            \n",
    "            pred_results.append(value1)\n",
    "            true_results.append(value2)\n",
    "    # ========================================== #   \n",
    "\n",
    "    test_acc1 =  RMSE(np.array( true_results), np.array(pred_results))\n",
    "    test_acc2 =  R2(np.array( true_results), np.array(pred_results))\n",
    "#     test_acc3 =  (100 - MAPE(np.array( true_results), np.array(pred_results)))\n",
    "    print('end')\n",
    "    \n",
    "    return test_acc1[0], test_acc2[0], pred_results, true_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_edit_all(model):\n",
    "    testloader = DataLoader(testall,\n",
    "                           batch_size=8,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    print('start')\n",
    "    model.eval()\n",
    "\n",
    "    bat_siz = 8\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X = X.transpose(0, 1).float().to(args.device)\n",
    "            y_true = y[:, :, Colum].float().to(args.device)\n",
    "            model.hidden = [hidden.to(args.device) for hidden in model.init_hidden()]\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            pred.append(y_pred)\n",
    "            true.append(y_true)\n",
    "\n",
    "    # ==== test 데이터 시각화를 위해 x,y데이터 저장 ==== #\n",
    "    for i in range(len(testloader)):\n",
    "        tems1 = pred[i].view(bat_siz).cpu().detach().numpy()\n",
    "        tems2 = true[i].view(bat_siz).cpu().detach().numpy()\n",
    "        \n",
    "        for j in range(bat_siz):\n",
    "            value1 = np.exp(DeNormalize(tems1[j], DownData, Colum, DownScaler))\n",
    "            value2 = np.exp(DeNormalize(tems2[j], DownData, Colum, DownScaler))\n",
    "            \n",
    "            pred_results.append(value1)\n",
    "            true_results.append(value2)\n",
    "    # ========================================== #   \n",
    "\n",
    "    test_acc1 =  RMSE(np.array( true_results), np.array(pred_results))\n",
    "    test_acc2 =  R2(np.array( true_results), np.array(pred_results))\n",
    "#     test_acc3 =  (100 - MAPE(np.array( true_results), np.array(pred_results)))\n",
    "    print('end')\n",
    "    \n",
    "    return test_acc1[0], test_acc2[0], pred_results, true_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkkF0-qmeOMq"
   },
   "source": [
    "# 5. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EOe2j_udjNv"
   },
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "\n",
    "#     model = LSTM(args.input_dim, args.hid_dim, args.y_frames, args.n_layers, args.batch_size, args.dropout, args.use_bn)\n",
    "    model = LSTM_edit()\n",
    "    model.to(args.device)\n",
    "#     loss_fn = torch.nn.MSELoss() ##loss는 mse를 사용\n",
    "#     loss_fn = nn.MSELoss()\n",
    "    \n",
    "    if args.loss == 'MSELoss':\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        loss_fn = nn.MSELoss()\n",
    "    elif args.loss == 'L1Loss':\n",
    "        loss_fn = torch.nn.L1Loss()\n",
    "        loss_fn = nn.L1Loss()\n",
    "    elif args.loss == 'PoissonNLLLoss':\n",
    "        loss_fn = torch.nn.PoissonNLLLoss()\n",
    "        loss_fn = nn.PoissonNLLLoss()\n",
    "    elif args.loss == 'KLDivLoss':\n",
    "        loss_fn = torch.nn.KLDivLoss()\n",
    "        loss_fn = nn.KLDivLoss()\n",
    "    elif args.loss == 'BCELoss':\n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        loss_fn = nn.BCELoss()\n",
    "    elif args.loss == 'BCEWithLogitsLoss':\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        raise ValueError('In-valid LossFuction choice')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "    \n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs_RMSE = []\n",
    "    train_accs_R2 = []\n",
    "    val_accs_RMSE = []\n",
    "    val_accs_R2 = []\n",
    "    axis = []\n",
    "    # ===================================== #\n",
    "    \n",
    "    ## model starting point ##    \n",
    "    ts = time.time()\n",
    "    model, train_loss, train_acc_RMSE, train_acc_R2 = train(model, partition, optimizer, loss_fn, args)\n",
    "    val_loss, val_acc_RMSE, val_acc_R2 = validate(model, partition, loss_fn, args)\n",
    "    te = time.time()\n",
    "\n",
    "    # ====== Add Epoch Data ====== #\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs_RMSE.append(train_acc_RMSE)\n",
    "    val_accs_RMSE.append(val_acc_RMSE)\n",
    "    train_accs_R2.append(train_acc_R2)\n",
    "    val_accs_R2.append(val_acc_R2)\n",
    "    # ============================ #\n",
    "\n",
    "    # # ===== Visdom visualizing ================================================================================== #\n",
    "    axis.append(0)\n",
    "    \n",
    "    plot1 = vis.line(Y=torch.cat((torch.Tensor(train_losses).view(-1,1), torch.Tensor(val_losses).view(-1,1)), -1),\n",
    "                     X=torch.cat((torch.Tensor(axis).view(-1,1), torch.Tensor(axis).view(-1,1)), -1),\n",
    "                     opts=dict(title='exp_{}_loss'.format(num), legend=['train_loss','val_loss'], showlegend=True))\n",
    "    \n",
    "    plot2 = vis.line(Y=torch.cat((torch.Tensor(train_accs_RMSE).view(-1,1), torch.Tensor(val_accs_RMSE).view(-1,1)), -1),\n",
    "                     X=torch.cat((torch.Tensor(axis).view(-1,1), torch.Tensor(axis).view(-1,1)), -1),\n",
    "                     opts=dict(title='exp_{}_acc_RMSE'.format(num), legend=['train_acc','val_acc'], showlegend=True))\n",
    "    \n",
    "    plot3 = vis.line(Y=torch.cat((torch.Tensor(train_accs_R2).view(-1,1), torch.Tensor(val_accs_R2).view(-1,1)), -1),\n",
    "                     X=torch.cat((torch.Tensor(axis).view(-1,1), torch.Tensor(axis).view(-1,1)), -1),\n",
    "                     opts=dict(title='exp_{}_acc_R2'.format(num), legend=['train_acc','val_acc'], showlegend=True))    \n",
    "    # # =========================================================================================================== #\n",
    "    \n",
    "    print('Epoch {}, Acc_RMSE(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'\n",
    "          .format(0, train_acc_RMSE, val_acc_RMSE, train_loss, val_loss, te-ts))\n",
    "    \n",
    "    for epoch in range(args.epoch-1):  # loop over the dataset multiple times\n",
    "        \n",
    "        ts = time.time()\n",
    "        model, train_loss, train_acc_RMSE, train_acc_R2 = train(model, partition, optimizer, loss_fn, args)\n",
    "        val_loss, val_acc_RMSE, val_acc_R2 = validate(model, partition, loss_fn, args)\n",
    "        te = time.time()\n",
    "\n",
    "        # ====== Add Epoch Data ====== #\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs_RMSE.append(train_acc_RMSE)\n",
    "        val_accs_RMSE.append(val_acc_RMSE)\n",
    "        train_accs_R2.append(train_acc_R2)\n",
    "        val_accs_R2.append(val_acc_R2)\n",
    "        # ============================ #\n",
    "\n",
    "        # # ===== Visdom visualizing ============================================================================== #\n",
    "        axis.append(epoch+1)\n",
    "        \n",
    "        vis.line(Y=torch.cat((torch.Tensor(train_losses).view(-1,1), torch.Tensor(val_losses).view(-1,1)), -1),\n",
    "                 X=torch.cat((torch.Tensor(axis).view(-1,1), torch.Tensor(axis).view(-1,1)), -1),\n",
    "                 win=plot1, update='replace')\n",
    "        \n",
    "        vis.line(Y=torch.cat((torch.Tensor(train_accs_RMSE).view(-1,1), torch.Tensor(val_accs_RMSE).view(-1,1)), -1),\n",
    "                 X=torch.cat((torch.Tensor(axis).view(-1,1), torch.Tensor(axis).view(-1,1)), -1),\n",
    "                 win=plot2, update='replace')\n",
    "        \n",
    "        vis.line(Y=torch.cat((torch.Tensor(train_accs_R2).view(-1,1), torch.Tensor(val_accs_R2).view(-1,1)), -1),\n",
    "                 X=torch.cat((torch.Tensor(axis).view(-1,1), torch.Tensor(axis).view(-1,1)), -1),\n",
    "                 win=plot3, update='replace')\n",
    "        # # ====================================================================================================== #\n",
    "        \n",
    "        print('Epoch {}, Acc_RMSE(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'\n",
    "              .format(epoch+1, train_acc_RMSE, val_acc_RMSE, train_loss, val_loss, te-ts))\n",
    "        \n",
    "    test_acc_RMSE, test_acc_R2, Pred_data, True_data = test_edit(model)\n",
    "    test_acc_RMSE_all, test_acc_R2_all, Pred_data_all, True_data_all = test_edit_all(model)\n",
    "    \n",
    "    # ======= Add Result to Dictionary ======= #\n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    \n",
    "    result['train_accs_RMSE'] = train_accs_RMSE\n",
    "    result['train_accs_R2'] = train_accs_R2\n",
    "    result['val_accs_RMSE'] = val_accs_RMSE\n",
    "    result['val_accs_R2'] = val_accs_R2\n",
    "#     result['train_acc'] = train_acc\n",
    "#     result['val_acc'] = val_acc\n",
    "    result['test_RMSE'] = test_acc_RMSE\n",
    "    result['test_R2'] = test_acc_R2\n",
    "    result['test_pred'] = Pred_data\n",
    "    result['test_true'] = True_data\n",
    "    result['test_RMSE_all'] = test_acc_RMSE_all\n",
    "    result['test_R2_all'] = test_acc_R2_all\n",
    "    result['test_pred_all'] = Pred_data_all\n",
    "    result['test_true_all'] = True_data_all\n",
    "    \n",
    "    network = model\n",
    "    torch.save(network.state_dict(),'lstm[{}].pt'.format(num))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNi-f5HyeJYi"
   },
   "source": [
    "# 6. LSTM Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4Bu6kFUdizj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " size of trainset :181\n",
      " size of valset :38\n",
      " size of testset :38\n",
      " total_exp_num : 24\n"
     ]
    }
   ],
   "source": [
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ====== Data Loading ====== #\n",
    "args.batch_size = 8\n",
    "args.UpData = UpData\n",
    "args.DownData = DownData\n",
    "args.x_frames = 4\n",
    "args.y_frames = 1\n",
    "\n",
    "# ====== Model Capacity ===== #\n",
    "args.input_dim = len(UpData.columns)\n",
    "args.hid_dim = 64\n",
    "args.n_layers = 2\n",
    "\n",
    "# ====== Regularization ======= #\n",
    "args.l2 = 0.0001\n",
    "args.dropout = 0.1 \n",
    "args.use_bn = False\n",
    "\n",
    "# ====== Optimizer & Training ====== #\n",
    "args.optim = 'Adam'  #SGD, RMSprop, Adam...\n",
    "args.loss = 'MSELoss'#'MSELoss','L1Loss','PoissonNLLLoss','KLDivLoss','BCELoss','BCEWithLogitsLoss'\n",
    "args.lr = 0.01\n",
    "args.epoch = 1000\n",
    "\n",
    "\n",
    "# ====== Experiment Variable ====== #\n",
    "name_var1 = 'x_frames'\n",
    "list_var1 = [4]\n",
    "\n",
    "name_var2 = 'loss'\n",
    "list_var2 = ['MSELoss']\n",
    "\n",
    "name_var3 = 'optim'\n",
    "list_var3 = ['Adam']\n",
    "\n",
    "name_var4 = 'use_bn'\n",
    "list_var4 = [False]\n",
    "\n",
    "name_var5 = 'dropout'\n",
    "list_var5 = [0.1]\n",
    "\n",
    "name_var6 = 'batch_size'\n",
    "list_var6 = [8]\n",
    "\n",
    "name_var7 = 'hid_dim'\n",
    "list_var7 = [64]\n",
    "\n",
    "name_var8 = 'n_layers'\n",
    "list_var8 = [2]\n",
    "\n",
    "name_var9 = 'lr'\n",
    "list_var9 = [0.01]\n",
    "\n",
    "name_var10 = 'l2'\n",
    "list_var10 = [0.0001]\n",
    "\n",
    "name_var11 = 'epoch'\n",
    "list_var11 = [65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,200]\n",
    "\n",
    "trainset = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2013-01-01', '2016-07-31')\n",
    "valset = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2016-08-01', '2017-05-19')\n",
    "testset = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2016-08-01', '2017-05-19')\n",
    "testall = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2013-01-01', '2016-07-31')\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}\n",
    "\n",
    "print(' size of trainset :{}\\n'.format(len(trainset)),\n",
    "      'size of valset :{}\\n'.format(len(valset)),\n",
    "      'size of testset :{}'.format(len(testset)))\n",
    "\n",
    "list_vars = [list_var1, list_var2, list_var3, list_var4, list_var5, list_var6, list_var7, list_var8, list_var9, list_var10, list_var11]\n",
    "i = 1\n",
    "for lenth in list_vars:\n",
    "    x = len(lenth)\n",
    "    i *= x\n",
    "total_exp_num = i\n",
    "\n",
    "print(' total_exp_num : {}'.format(total_exp_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jinsungpark/Desktop/jupyter/Data_river/data04'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsungpark/Desktop/Real_Last/DS_NG_TN\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jinsungpark/Desktop/Real_Last/DS_NG_TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Start #####\n",
      "\n",
      " exp_1\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.65/0.78, Loss(train/val) 0.10494/0.02132. Took 0.16 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.13/0.44, Loss(train/val) 0.03847/0.00602. Took 0.16 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.88/1.18, Loss(train/val) 0.02229/0.03082. Took 0.15 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.12/0.59, Loss(train/val) 0.03251/0.01285. Took 0.16 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.80/0.30, Loss(train/val) 0.01717/0.00286. Took 0.15 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.67/0.33, Loss(train/val) 0.01305/0.00412. Took 0.16 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.83/0.28, Loss(train/val) 0.01745/0.00274. Took 0.15 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.72/0.30, Loss(train/val) 0.01393/0.00326. Took 0.16 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.73/0.29, Loss(train/val) 0.01412/0.00306. Took 0.15 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.81/0.29, Loss(train/val) 0.01632/0.00294. Took 0.15 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.80/0.28, Loss(train/val) 0.01649/0.00279. Took 0.16 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.66/0.33, Loss(train/val) 0.01223/0.00436. Took 0.15 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.61/0.41, Loss(train/val) 0.01003/0.00638. Took 0.15 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.65/0.39, Loss(train/val) 0.01146/0.00578. Took 0.15 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.60/0.50, Loss(train/val) 0.01033/0.00936. Took 0.14 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.52/0.51, Loss(train/val) 0.00847/0.01043. Took 0.16 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.78/0.55, Loss(train/val) 0.01539/0.01040. Took 0.15 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.56/0.55, Loss(train/val) 0.00928/0.01165. Took 0.15 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.86/0.55, Loss(train/val) 0.01801/0.01053. Took 0.15 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.55/0.39, Loss(train/val) 0.00893/0.00552. Took 0.16 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.64/0.70, Loss(train/val) 0.01186/0.01906. Took 0.16 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.62/0.69, Loss(train/val) 0.01176/0.01802. Took 0.15 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.77/0.89, Loss(train/val) 0.01779/0.03105. Took 0.14 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.75/0.57, Loss(train/val) 0.01577/0.01167. Took 0.16 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.73/0.86, Loss(train/val) 0.01457/0.02905. Took 0.15 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.92/0.58, Loss(train/val) 0.02566/0.01344. Took 0.15 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.78/0.60, Loss(train/val) 0.01685/0.01323. Took 0.15 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.77/0.48, Loss(train/val) 0.01642/0.00948. Took 0.15 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.85/0.29, Loss(train/val) 0.02199/0.00274. Took 0.14 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.86/0.40, Loss(train/val) 0.02071/0.00514. Took 0.16 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.71/0.41, Loss(train/val) 0.01433/0.00505. Took 0.15 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.70/0.32, Loss(train/val) 0.01378/0.00359. Took 0.15 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.65/0.32, Loss(train/val) 0.01277/0.00345. Took 0.15 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.68/0.39, Loss(train/val) 0.01277/0.00479. Took 0.15 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.68/0.42, Loss(train/val) 0.01319/0.00530. Took 0.14 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.62/0.42, Loss(train/val) 0.01114/0.00533. Took 0.16 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.59/0.43, Loss(train/val) 0.01005/0.00553. Took 0.15 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.59/0.43, Loss(train/val) 0.01030/0.00547. Took 0.15 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.58/0.41, Loss(train/val) 0.00979/0.00526. Took 0.15 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.58/0.37, Loss(train/val) 0.00967/0.00441. Took 0.16 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.59/0.36, Loss(train/val) 0.00971/0.00426. Took 0.14 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.56/0.37, Loss(train/val) 0.00901/0.00442. Took 0.16 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00921/0.00368. Took 0.15 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.57/0.34, Loss(train/val) 0.00914/0.00381. Took 0.16 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.55/0.35, Loss(train/val) 0.00870/0.00396. Took 0.15 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.56/0.35, Loss(train/val) 0.00897/0.00413. Took 0.15 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.53/0.32, Loss(train/val) 0.00826/0.00360. Took 0.16 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.53/0.38, Loss(train/val) 0.00808/0.00460. Took 0.15 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.51/0.40, Loss(train/val) 0.00800/0.00511. Took 0.15 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.50/0.32, Loss(train/val) 0.00787/0.00353. Took 0.16 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.51/0.49, Loss(train/val) 0.00768/0.00692. Took 0.15 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.51/0.44, Loss(train/val) 0.00818/0.00588. Took 0.15 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.49/0.47, Loss(train/val) 0.00760/0.00656. Took 0.15 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.51/0.45, Loss(train/val) 0.00831/0.00616. Took 0.15 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.48/0.40, Loss(train/val) 0.00715/0.00507. Took 0.14 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.49/0.47, Loss(train/val) 0.00756/0.00656. Took 0.16 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.48/0.38, Loss(train/val) 0.00721/0.00473. Took 0.15 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.46/0.52, Loss(train/val) 0.00684/0.00786. Took 0.15 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.50/0.46, Loss(train/val) 0.00778/0.00643. Took 0.15 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.46/0.51, Loss(train/val) 0.00678/0.00765. Took 0.15 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.50/0.53, Loss(train/val) 0.00784/0.00809. Took 0.15 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.48/0.55, Loss(train/val) 0.00714/0.00867. Took 0.16 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.50/0.46, Loss(train/val) 0.00780/0.00656. Took 0.15 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.44/0.46, Loss(train/val) 0.00623/0.00647. Took 0.15 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.48/0.37, Loss(train/val) 0.00758/0.00458. Took 0.15 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_2\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.51/0.49, Loss(train/val) 0.07618/0.00783. Took 0.15 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 0.99/0.38, Loss(train/val) 0.02825/0.00456. Took 0.16 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.98/0.57, Loss(train/val) 0.02493/0.01085. Took 0.15 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.86/0.32, Loss(train/val) 0.02043/0.00338. Took 0.15 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.72/0.35, Loss(train/val) 0.01431/0.00483. Took 0.15 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.83/0.51, Loss(train/val) 0.01692/0.00874. Took 0.16 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.84/0.35, Loss(train/val) 0.01735/0.00443. Took 0.15 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.75/0.36, Loss(train/val) 0.01390/0.00496. Took 0.16 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.82/0.48, Loss(train/val) 0.01623/0.00866. Took 0.15 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.81/0.51, Loss(train/val) 0.01695/0.01023. Took 0.16 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.85/0.42, Loss(train/val) 0.01929/0.00705. Took 0.14 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.89/0.34, Loss(train/val) 0.02180/0.00402. Took 0.16 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.87/0.31, Loss(train/val) 0.01984/0.00366. Took 0.15 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.78/0.31, Loss(train/val) 0.01664/0.00340. Took 0.16 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.73/0.35, Loss(train/val) 0.01478/0.00393. Took 0.14 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.69/0.41, Loss(train/val) 0.01296/0.00517. Took 0.16 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.73/0.28, Loss(train/val) 0.01433/0.00302. Took 0.15 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.74/0.27, Loss(train/val) 0.01432/0.00268. Took 0.16 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.68/0.28, Loss(train/val) 0.01194/0.00276. Took 0.14 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.60/0.31, Loss(train/val) 0.01017/0.00317. Took 0.16 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.65/0.29, Loss(train/val) 0.01114/0.00324. Took 0.15 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.65/0.29, Loss(train/val) 0.01094/0.00291. Took 0.16 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.66/0.29, Loss(train/val) 0.01103/0.00295. Took 0.15 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.58/0.26, Loss(train/val) 0.00912/0.00239. Took 0.16 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.56/0.31, Loss(train/val) 0.00869/0.00354. Took 0.15 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Acc_RMSE(train/val): 0.62/0.36, Loss(train/val) 0.01062/0.00483. Took 0.16 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.65/0.35, Loss(train/val) 0.01106/0.00478. Took 0.15 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.56/0.31, Loss(train/val) 0.00900/0.00349. Took 0.16 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.56/0.32, Loss(train/val) 0.00866/0.00360. Took 0.15 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00898/0.00398. Took 0.16 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.59/0.46, Loss(train/val) 0.00956/0.00803. Took 0.15 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.58/0.44, Loss(train/val) 0.00943/0.00691. Took 0.16 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.58/0.53, Loss(train/val) 0.00872/0.01011. Took 0.15 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.60/0.49, Loss(train/val) 0.00977/0.00967. Took 0.16 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.70/0.56, Loss(train/val) 0.01348/0.01196. Took 0.15 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.59/0.25, Loss(train/val) 0.01001/0.00226. Took 0.15 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.72/0.30, Loss(train/val) 0.01335/0.00284. Took 0.15 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.77/0.34, Loss(train/val) 0.01555/0.00349. Took 0.16 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.64/0.55, Loss(train/val) 0.01152/0.00832. Took 0.14 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.71/0.35, Loss(train/val) 0.01412/0.00366. Took 0.16 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.64/0.55, Loss(train/val) 0.01116/0.00777. Took 0.16 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.71/0.44, Loss(train/val) 0.01367/0.00558. Took 0.16 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.56/0.49, Loss(train/val) 0.00927/0.00643. Took 0.15 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.63/0.47, Loss(train/val) 0.01074/0.00642. Took 0.17 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.54/0.53, Loss(train/val) 0.00896/0.00724. Took 0.17 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.60/0.46, Loss(train/val) 0.00996/0.00591. Took 0.23 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.53/0.50, Loss(train/val) 0.00840/0.00669. Took 0.23 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.58/0.47, Loss(train/val) 0.00917/0.00598. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.52/0.37, Loss(train/val) 0.00837/0.00423. Took 0.26 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.49/0.41, Loss(train/val) 0.00763/0.00501. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.53/0.39, Loss(train/val) 0.00814/0.00458. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.50/0.33, Loss(train/val) 0.00772/0.00368. Took 0.25 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.55/0.45, Loss(train/val) 0.00805/0.00571. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.50/0.37, Loss(train/val) 0.00780/0.00415. Took 0.25 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.48/0.52, Loss(train/val) 0.00683/0.00737. Took 0.23 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.50/0.42, Loss(train/val) 0.00744/0.00520. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.46/0.37, Loss(train/val) 0.00669/0.00417. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.45/0.29, Loss(train/val) 0.00660/0.00303. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.51/0.56, Loss(train/val) 0.00751/0.00858. Took 0.23 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.55/0.29, Loss(train/val) 0.00907/0.00312. Took 0.25 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.43/0.62, Loss(train/val) 0.00604/0.01012. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.57/0.59, Loss(train/val) 0.00932/0.00954. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.45/0.39, Loss(train/val) 0.00624/0.00471. Took 0.23 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.45/0.35, Loss(train/val) 0.00634/0.00394. Took 0.25 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.48/0.81, Loss(train/val) 0.00750/0.01587. Took 0.25 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_3\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.54/0.60, Loss(train/val) 0.07890/0.01179. Took 0.23 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.07/0.42, Loss(train/val) 0.03375/0.00566. Took 0.25 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.87/0.66, Loss(train/val) 0.02158/0.01365. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.95/0.33, Loss(train/val) 0.02553/0.00442. Took 0.24 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.73/0.25, Loss(train/val) 0.01369/0.00223. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.74/0.27, Loss(train/val) 0.01430/0.00253. Took 0.25 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.78/0.26, Loss(train/val) 0.01556/0.00242. Took 0.25 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.69/0.33, Loss(train/val) 0.01272/0.00374. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.72/0.32, Loss(train/val) 0.01318/0.00365. Took 0.26 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.66/0.30, Loss(train/val) 0.01151/0.00314. Took 0.25 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.63/0.29, Loss(train/val) 0.01070/0.00315. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.65/0.31, Loss(train/val) 0.01095/0.00349. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.66/0.27, Loss(train/val) 0.01131/0.00272. Took 0.25 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.68/0.32, Loss(train/val) 0.01199/0.00354. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.63/0.27, Loss(train/val) 0.01055/0.00263. Took 0.26 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.59/0.37, Loss(train/val) 0.00994/0.00484. Took 0.25 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.60/0.36, Loss(train/val) 0.01012/0.00494. Took 0.25 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.68/0.62, Loss(train/val) 0.01326/0.01483. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.77/0.34, Loss(train/val) 0.01662/0.00434. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.72/0.40, Loss(train/val) 0.01285/0.00536. Took 0.27 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.70/0.28, Loss(train/val) 0.01216/0.00270. Took 0.23 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.71/0.33, Loss(train/val) 0.01233/0.00396. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.58/0.26, Loss(train/val) 0.00925/0.00249. Took 0.23 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.65/0.46, Loss(train/val) 0.01135/0.00874. Took 0.23 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.56/0.40, Loss(train/val) 0.00896/0.00672. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.64/0.66, Loss(train/val) 0.01198/0.01743. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.56/0.37, Loss(train/val) 0.00932/0.00551. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.67/0.55, Loss(train/val) 0.01263/0.01098. Took 0.23 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.61/0.35, Loss(train/val) 0.01029/0.00414. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.62/0.46, Loss(train/val) 0.01001/0.00738. Took 0.23 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.57/0.48, Loss(train/val) 0.00908/0.00791. Took 0.25 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.71/0.72, Loss(train/val) 0.01369/0.02000. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.74/0.44, Loss(train/val) 0.01532/0.00753. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.75/0.51, Loss(train/val) 0.01567/0.00972. Took 0.23 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.81/0.43, Loss(train/val) 0.01794/0.00536. Took 0.23 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.82/0.37, Loss(train/val) 0.01845/0.00403. Took 0.23 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.74/0.53, Loss(train/val) 0.01537/0.00768. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.71/0.50, Loss(train/val) 0.01393/0.00701. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.64/0.45, Loss(train/val) 0.01176/0.00592. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.60/0.46, Loss(train/val) 0.01022/0.00582. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.61/0.44, Loss(train/val) 0.01046/0.00557. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.01015/0.00406. Took 0.24 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.01002/0.00420. Took 0.26 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.59/0.36, Loss(train/val) 0.00955/0.00407. Took 0.27 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.60/0.40, Loss(train/val) 0.00978/0.00466. Took 0.25 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.59/0.36, Loss(train/val) 0.00950/0.00402. Took 0.26 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.56/0.31, Loss(train/val) 0.00875/0.00328. Took 0.25 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.54/0.33, Loss(train/val) 0.00813/0.00373. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.53/0.36, Loss(train/val) 0.00811/0.00403. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.54/0.40, Loss(train/val) 0.00859/0.00475. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.50/0.37, Loss(train/val) 0.00807/0.00430. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Acc_RMSE(train/val): 0.49/0.38, Loss(train/val) 0.00757/0.00455. Took 0.26 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.50/0.41, Loss(train/val) 0.00788/0.00497. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.52/0.32, Loss(train/val) 0.00825/0.00345. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.54/0.27, Loss(train/val) 0.00805/0.00257. Took 0.24 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.55/0.38, Loss(train/val) 0.00833/0.00460. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.54/0.26, Loss(train/val) 0.00791/0.00265. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.52/0.50, Loss(train/val) 0.00757/0.00695. Took 0.23 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.56/0.49, Loss(train/val) 0.00867/0.00692. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.50/0.45, Loss(train/val) 0.00726/0.00598. Took 0.23 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.53/0.54, Loss(train/val) 0.00855/0.00813. Took 0.25 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.51/0.50, Loss(train/val) 0.00788/0.00689. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.46/0.53, Loss(train/val) 0.00651/0.00770. Took 0.25 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.51/0.61, Loss(train/val) 0.00752/0.00994. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.46/0.45, Loss(train/val) 0.00638/0.00595. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_4\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.50/0.73, Loss(train/val) 0.08018/0.01814. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.15/0.72, Loss(train/val) 0.03943/0.01786. Took 0.25 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.10/0.44, Loss(train/val) 0.03540/0.00597. Took 0.23 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.86/1.16, Loss(train/val) 0.02132/0.02848. Took 0.24 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 1.02/0.44, Loss(train/val) 0.02686/0.00680. Took 0.25 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.89/0.40, Loss(train/val) 0.01943/0.00539. Took 0.23 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.71/0.30, Loss(train/val) 0.01363/0.00320. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.68/0.32, Loss(train/val) 0.01185/0.00383. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.83/0.35, Loss(train/val) 0.01656/0.00395. Took 0.25 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.75/0.27, Loss(train/val) 0.01492/0.00258. Took 0.23 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.67/0.37, Loss(train/val) 0.01200/0.00552. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.61/0.31, Loss(train/val) 0.00998/0.00384. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.63/0.37, Loss(train/val) 0.01055/0.00518. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.59/0.35, Loss(train/val) 0.00952/0.00458. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.60/0.43, Loss(train/val) 0.00989/0.00696. Took 0.23 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.53/0.51, Loss(train/val) 0.00846/0.00967. Took 0.23 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.83/0.34, Loss(train/val) 0.01770/0.00432. Took 0.23 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.57/0.52, Loss(train/val) 0.00985/0.01067. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.65/0.53, Loss(train/val) 0.01243/0.00973. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.56/0.57, Loss(train/val) 0.01040/0.01145. Took 0.25 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.86/0.52, Loss(train/val) 0.01856/0.00862. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.82/0.51, Loss(train/val) 0.01509/0.00840. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.66/0.70, Loss(train/val) 0.01262/0.01884. Took 0.23 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.91/0.38, Loss(train/val) 0.02371/0.00523. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.66/0.28, Loss(train/val) 0.01335/0.00295. Took 0.25 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.87/0.40, Loss(train/val) 0.02092/0.00478. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.83/0.41, Loss(train/val) 0.01854/0.00506. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.71/0.47, Loss(train/val) 0.01364/0.00704. Took 0.23 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.68/0.33, Loss(train/val) 0.01305/0.00371. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.65/0.29, Loss(train/val) 0.01189/0.00303. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.72/0.44, Loss(train/val) 0.01390/0.00579. Took 0.23 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.61/0.34, Loss(train/val) 0.01084/0.00374. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.58/0.43, Loss(train/val) 0.00985/0.00552. Took 0.25 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.80/0.30, Loss(train/val) 0.01340/0.00305. Took 0.23 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.78/0.31, Loss(train/val) 0.01568/0.00341. Took 0.23 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.50/0.29, Loss(train/val) 0.00771/0.00316. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.64/0.34, Loss(train/val) 0.01102/0.00420. Took 0.25 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.52/0.28, Loss(train/val) 0.00860/0.00277. Took 0.23 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.59/0.39, Loss(train/val) 0.00969/0.00478. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.62/0.45, Loss(train/val) 0.01060/0.00595. Took 0.23 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.58/0.42, Loss(train/val) 0.00962/0.00523. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.58/0.46, Loss(train/val) 0.00981/0.00611. Took 0.23 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.58/0.43, Loss(train/val) 0.00950/0.00560. Took 0.23 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.56/0.45, Loss(train/val) 0.00915/0.00593. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.55/0.42, Loss(train/val) 0.00891/0.00552. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.57/0.39, Loss(train/val) 0.00916/0.00469. Took 0.23 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.54/0.42, Loss(train/val) 0.00816/0.00542. Took 0.24 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.52/0.44, Loss(train/val) 0.00798/0.00581. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.54/0.40, Loss(train/val) 0.00829/0.00504. Took 0.23 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.51/0.40, Loss(train/val) 0.00769/0.00502. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.49/0.39, Loss(train/val) 0.00735/0.00496. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.48/0.42, Loss(train/val) 0.00723/0.00554. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.49/0.35, Loss(train/val) 0.00722/0.00419. Took 0.23 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.48/0.39, Loss(train/val) 0.00690/0.00491. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.49/0.50, Loss(train/val) 0.00728/0.00743. Took 0.23 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.48/0.40, Loss(train/val) 0.00698/0.00548. Took 0.23 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.49/0.45, Loss(train/val) 0.00700/0.00608. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.49/0.44, Loss(train/val) 0.00731/0.00600. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.44/0.40, Loss(train/val) 0.00634/0.00494. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.44/0.35, Loss(train/val) 0.00648/0.00420. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.41/0.40, Loss(train/val) 0.00560/0.00507. Took 0.23 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.41/0.45, Loss(train/val) 0.00567/0.00620. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.44/0.38, Loss(train/val) 0.00626/0.00514. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.40/0.47, Loss(train/val) 0.00519/0.00677. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.51/0.61, Loss(train/val) 0.00781/0.01050. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_5\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 2.07/0.87, Loss(train/val) 0.15266/0.02715. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.21/0.83, Loss(train/val) 0.04380/0.02427. Took 0.25 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.20/0.72, Loss(train/val) 0.04387/0.01763. Took 0.23 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.11/0.65, Loss(train/val) 0.03703/0.01414. Took 0.23 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 1.07/0.31, Loss(train/val) 0.03349/0.00354. Took 0.23 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.86/0.79, Loss(train/val) 0.02211/0.01525. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 1.04/0.43, Loss(train/val) 0.02747/0.00604. Took 0.23 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.71/0.48, Loss(train/val) 0.01403/0.00676. Took 0.23 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.85/0.37, Loss(train/val) 0.01914/0.00508. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.60/0.35, Loss(train/val) 0.00997/0.00383. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Acc_RMSE(train/val): 0.80/0.27, Loss(train/val) 0.01591/0.00253. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.66/0.36, Loss(train/val) 0.01197/0.00472. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.64/0.33, Loss(train/val) 0.01069/0.00416. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.65/0.33, Loss(train/val) 0.01103/0.00432. Took 0.23 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.61/0.29, Loss(train/val) 0.01002/0.00319. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.68/0.28, Loss(train/val) 0.01199/0.00284. Took 0.23 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.71/0.34, Loss(train/val) 0.01321/0.00410. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.57/0.28, Loss(train/val) 0.00904/0.00286. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.61/0.25, Loss(train/val) 0.01014/0.00223. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.70/0.31, Loss(train/val) 0.01255/0.00361. Took 0.23 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.55/0.55, Loss(train/val) 0.00940/0.01236. Took 0.25 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.53/0.56, Loss(train/val) 0.00902/0.01334. Took 0.23 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.62/0.37, Loss(train/val) 0.01126/0.00526. Took 0.25 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.50/0.67, Loss(train/val) 0.00787/0.01728. Took 0.23 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.49/0.46, Loss(train/val) 0.00791/0.00907. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.60/0.44, Loss(train/val) 0.01007/0.00699. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.52/0.66, Loss(train/val) 0.00895/0.01704. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.66/0.33, Loss(train/val) 0.01210/0.00370. Took 0.27 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.52/0.53, Loss(train/val) 0.00875/0.01069. Took 0.29 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.90/0.47, Loss(train/val) 0.01957/0.00705. Took 0.27 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.84/0.54, Loss(train/val) 0.01691/0.00951. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.68/0.57, Loss(train/val) 0.01193/0.01118. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.77/0.51, Loss(train/val) 0.01625/0.01240. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.65/0.50, Loss(train/val) 0.01173/0.01138. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.67/0.52, Loss(train/val) 0.01278/0.01117. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.62/0.40, Loss(train/val) 0.01043/0.00559. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.62/0.52, Loss(train/val) 0.01028/0.01003. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.62/0.36, Loss(train/val) 0.01014/0.00469. Took 0.23 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.66/0.75, Loss(train/val) 0.01209/0.02106. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.75/0.60, Loss(train/val) 0.01401/0.01382. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.77/0.69, Loss(train/val) 0.01666/0.02351. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.67/0.48, Loss(train/val) 0.01317/0.00980. Took 0.24 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.67/0.57, Loss(train/val) 0.01268/0.01430. Took 0.23 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.72/0.43, Loss(train/val) 0.01480/0.00661. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.72/0.45, Loss(train/val) 0.01464/0.00784. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.79/0.38, Loss(train/val) 0.01833/0.00440. Took 0.23 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.76/0.44, Loss(train/val) 0.01633/0.00544. Took 0.24 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.80/0.59, Loss(train/val) 0.01781/0.00961. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.77/0.63, Loss(train/val) 0.01665/0.01027. Took 0.23 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.73/0.59, Loss(train/val) 0.01484/0.00898. Took 0.23 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.65/0.55, Loss(train/val) 0.01212/0.00809. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.61/0.50, Loss(train/val) 0.01096/0.00661. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.58/0.48, Loss(train/val) 0.00995/0.00623. Took 0.25 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.56/0.42, Loss(train/val) 0.00951/0.00498. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.55/0.45, Loss(train/val) 0.00883/0.00556. Took 0.24 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.58/0.32, Loss(train/val) 0.00951/0.00322. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.55/0.33, Loss(train/val) 0.00864/0.00341. Took 0.27 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.57/0.30, Loss(train/val) 0.00876/0.00298. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.56/0.34, Loss(train/val) 0.00863/0.00363. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.56/0.36, Loss(train/val) 0.00884/0.00386. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.54/0.33, Loss(train/val) 0.00829/0.00340. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.53/0.38, Loss(train/val) 0.00861/0.00430. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.51/0.35, Loss(train/val) 0.00785/0.00371. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.51/0.36, Loss(train/val) 0.00778/0.00393. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.48/0.31, Loss(train/val) 0.00727/0.00306. Took 0.25 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_6\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.58/0.65, Loss(train/val) 0.08616/0.01398. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.09/0.61, Loss(train/val) 0.03538/0.01217. Took 0.23 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.82/0.55, Loss(train/val) 0.01995/0.00909. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.04/0.37, Loss(train/val) 0.02992/0.00456. Took 0.23 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.81/0.26, Loss(train/val) 0.01720/0.00230. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.72/0.50, Loss(train/val) 0.01449/0.00673. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.78/0.36, Loss(train/val) 0.01546/0.00489. Took 0.23 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.72/0.34, Loss(train/val) 0.01337/0.00425. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.63/0.33, Loss(train/val) 0.01121/0.00355. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.76/0.43, Loss(train/val) 0.01489/0.00650. Took 0.23 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.66/0.34, Loss(train/val) 0.01186/0.00402. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.70/0.26, Loss(train/val) 0.01303/0.00243. Took 0.25 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.92/0.48, Loss(train/val) 0.02068/0.00746. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.95/0.43, Loss(train/val) 0.02302/0.00594. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.73/0.44, Loss(train/val) 0.01482/0.00759. Took 0.23 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.65/0.52, Loss(train/val) 0.01151/0.01008. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.73/0.49, Loss(train/val) 0.01387/0.00889. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.72/0.56, Loss(train/val) 0.01402/0.01179. Took 0.23 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.81/0.46, Loss(train/val) 0.01769/0.00723. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.80/0.38, Loss(train/val) 0.01644/0.00513. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.71/0.34, Loss(train/val) 0.01404/0.00414. Took 0.23 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.76/0.30, Loss(train/val) 0.01631/0.00327. Took 0.23 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.79/0.49, Loss(train/val) 0.01763/0.00653. Took 0.23 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.76/0.46, Loss(train/val) 0.01585/0.00583. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.63/0.43, Loss(train/val) 0.01137/0.00529. Took 0.25 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.68/0.44, Loss(train/val) 0.01248/0.00544. Took 0.23 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.63/0.42, Loss(train/val) 0.01127/0.00499. Took 0.23 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.63/0.38, Loss(train/val) 0.01119/0.00434. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.63/0.40, Loss(train/val) 0.01085/0.00470. Took 0.25 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.64/0.43, Loss(train/val) 0.01116/0.00525. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.61/0.35, Loss(train/val) 0.01038/0.00387. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.56/0.35, Loss(train/val) 0.00878/0.00394. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.59/0.36, Loss(train/val) 0.00969/0.00413. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.59/0.36, Loss(train/val) 0.00960/0.00386. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.56/0.32, Loss(train/val) 0.00903/0.00322. Took 0.24 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.60/0.30, Loss(train/val) 0.00968/0.00314. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Acc_RMSE(train/val): 0.53/0.29, Loss(train/val) 0.00817/0.00278. Took 0.27 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.52/0.27, Loss(train/val) 0.00762/0.00260. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.49/0.27, Loss(train/val) 0.00712/0.00265. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.51/0.33, Loss(train/val) 0.00740/0.00411. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.49/0.27, Loss(train/val) 0.00678/0.00266. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.50/0.36, Loss(train/val) 0.00786/0.00471. Took 0.23 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.46/0.31, Loss(train/val) 0.00692/0.00352. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.48/0.27, Loss(train/val) 0.00708/0.00261. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.51/0.24, Loss(train/val) 0.00760/0.00211. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.54/0.24, Loss(train/val) 0.00819/0.00210. Took 0.24 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.59/0.34, Loss(train/val) 0.00878/0.00431. Took 0.23 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.57/0.31, Loss(train/val) 0.00838/0.00364. Took 0.23 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00828/0.00396. Took 0.24 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.53/0.30, Loss(train/val) 0.00706/0.00331. Took 0.29 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.52/0.47, Loss(train/val) 0.00791/0.00874. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.55/0.37, Loss(train/val) 0.00955/0.00478. Took 0.23 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.53/0.34, Loss(train/val) 0.00855/0.00352. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.63/0.29, Loss(train/val) 0.01083/0.00283. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.60/0.29, Loss(train/val) 0.00954/0.00272. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.57/0.35, Loss(train/val) 0.00901/0.00372. Took 0.26 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.59/0.30, Loss(train/val) 0.00945/0.00287. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.58/0.25, Loss(train/val) 0.00915/0.00227. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.51/0.32, Loss(train/val) 0.00731/0.00330. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.57/0.30, Loss(train/val) 0.00920/0.00329. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.49/0.33, Loss(train/val) 0.00703/0.00344. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.49/0.29, Loss(train/val) 0.00771/0.00285. Took 0.23 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.54/0.28, Loss(train/val) 0.00829/0.00279. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.51/0.27, Loss(train/val) 0.00737/0.00247. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.50/0.41, Loss(train/val) 0.00739/0.00499. Took 0.26 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_7\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.90/0.87, Loss(train/val) 0.13134/0.02727. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.18/0.80, Loss(train/val) 0.04134/0.02270. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.14/0.72, Loss(train/val) 0.03915/0.01771. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.01/0.44, Loss(train/val) 0.03022/0.00703. Took 0.26 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.95/0.34, Loss(train/val) 0.02529/0.00464. Took 0.30 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.76/0.27, Loss(train/val) 0.01552/0.00271. Took 0.25 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.72/0.40, Loss(train/val) 0.01487/0.00535. Took 0.25 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.73/0.28, Loss(train/val) 0.01384/0.00289. Took 0.25 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.62/0.41, Loss(train/val) 0.01087/0.00523. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.78/0.32, Loss(train/val) 0.01549/0.00362. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.58/0.41, Loss(train/val) 0.00989/0.00485. Took 0.25 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.87/0.38, Loss(train/val) 0.01860/0.00488. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.64/0.33, Loss(train/val) 0.01131/0.00391. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.59/0.43, Loss(train/val) 0.00956/0.00788. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.53/0.41, Loss(train/val) 0.00845/0.00697. Took 0.25 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.52/0.39, Loss(train/val) 0.00791/0.00650. Took 0.27 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.50/0.34, Loss(train/val) 0.00767/0.00459. Took 0.25 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.59/0.27, Loss(train/val) 0.00927/0.00273. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.62/0.27, Loss(train/val) 0.00995/0.00251. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.63/0.29, Loss(train/val) 0.01092/0.00302. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.61/0.46, Loss(train/val) 0.01042/0.00874. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.59/0.51, Loss(train/val) 0.00979/0.01087. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.56/0.53, Loss(train/val) 0.00930/0.01105. Took 0.23 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.50/0.71, Loss(train/val) 0.00812/0.02065. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.67/0.44, Loss(train/val) 0.01304/0.00795. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.57/0.47, Loss(train/val) 0.00933/0.00800. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.53/0.61, Loss(train/val) 0.00846/0.01415. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.51/0.63, Loss(train/val) 0.00828/0.01532. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.57/0.56, Loss(train/val) 0.00943/0.01190. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.53/0.63, Loss(train/val) 0.00832/0.01451. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.56/0.69, Loss(train/val) 0.00861/0.01736. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.68/0.60, Loss(train/val) 0.01214/0.01348. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.64/0.82, Loss(train/val) 0.00994/0.02512. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.69/0.73, Loss(train/val) 0.01314/0.02239. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.74/1.02, Loss(train/val) 0.01578/0.04642. Took 0.23 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.60/0.58, Loss(train/val) 0.01088/0.01425. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.70/0.70, Loss(train/val) 0.01290/0.01969. Took 0.25 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.89/0.69, Loss(train/val) 0.01686/0.01638. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.88/0.38, Loss(train/val) 0.02226/0.00597. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.66/0.29, Loss(train/val) 0.01363/0.00310. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.75/0.32, Loss(train/val) 0.01717/0.00331. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.81/0.53, Loss(train/val) 0.01885/0.00791. Took 0.26 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.79/0.52, Loss(train/val) 0.01762/0.00753. Took 0.24 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.71/0.51, Loss(train/val) 0.01490/0.00750. Took 0.25 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.67/0.51, Loss(train/val) 0.01359/0.00719. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.64/0.46, Loss(train/val) 0.01215/0.00598. Took 0.28 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.59/0.46, Loss(train/val) 0.01062/0.00589. Took 0.24 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.59/0.40, Loss(train/val) 0.01051/0.00460. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.54/0.39, Loss(train/val) 0.00897/0.00430. Took 0.24 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.56/0.38, Loss(train/val) 0.00935/0.00418. Took 0.25 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.53/0.27, Loss(train/val) 0.00864/0.00250. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.49/0.34, Loss(train/val) 0.00796/0.00351. Took 0.26 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.52/0.33, Loss(train/val) 0.00837/0.00335. Took 0.25 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.52/0.30, Loss(train/val) 0.00822/0.00286. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.50/0.29, Loss(train/val) 0.00766/0.00270. Took 0.26 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.51/0.30, Loss(train/val) 0.00840/0.00288. Took 0.26 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.54/0.28, Loss(train/val) 0.00811/0.00263. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.49/0.41, Loss(train/val) 0.00804/0.00482. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.53/0.31, Loss(train/val) 0.00842/0.00301. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.49/0.40, Loss(train/val) 0.00793/0.00468. Took 0.26 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.50/0.37, Loss(train/val) 0.00772/0.00398. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.48/0.35, Loss(train/val) 0.00749/0.00373. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Acc_RMSE(train/val): 0.48/0.39, Loss(train/val) 0.00722/0.00446. Took 0.25 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.48/0.27, Loss(train/val) 0.00722/0.00263. Took 0.25 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.43/0.51, Loss(train/val) 0.00601/0.00690. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_8\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.71/0.67, Loss(train/val) 0.10864/0.01482. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.10/0.39, Loss(train/val) 0.03576/0.00473. Took 0.26 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.92/0.52, Loss(train/val) 0.02401/0.00941. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.93/0.30, Loss(train/val) 0.02478/0.00311. Took 0.25 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.83/0.31, Loss(train/val) 0.01854/0.00326. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.77/0.47, Loss(train/val) 0.01718/0.00649. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.74/0.29, Loss(train/val) 0.01462/0.00299. Took 0.26 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.67/0.42, Loss(train/val) 0.01266/0.00531. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.65/0.38, Loss(train/val) 0.01174/0.00448. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.67/0.34, Loss(train/val) 0.01193/0.00384. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.64/0.44, Loss(train/val) 0.01101/0.00543. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.67/0.34, Loss(train/val) 0.01189/0.00400. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.56/0.37, Loss(train/val) 0.00908/0.00475. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.55/0.33, Loss(train/val) 0.00852/0.00365. Took 0.27 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.66/0.32, Loss(train/val) 0.01132/0.00317. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.71/0.27, Loss(train/val) 0.01343/0.00255. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.65/0.29, Loss(train/val) 0.01170/0.00311. Took 0.25 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.53/0.55, Loss(train/val) 0.00908/0.01286. Took 0.23 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.51/0.44, Loss(train/val) 0.00825/0.00857. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.53/0.38, Loss(train/val) 0.00841/0.00604. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.59/0.37, Loss(train/val) 0.00969/0.00498. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.50/0.48, Loss(train/val) 0.00760/0.00976. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.49/0.37, Loss(train/val) 0.00736/0.00556. Took 0.25 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.54/0.28, Loss(train/val) 0.00824/0.00298. Took 0.23 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.52/0.28, Loss(train/val) 0.00750/0.00281. Took 0.23 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.65/0.26, Loss(train/val) 0.01107/0.00251. Took 0.25 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.76/0.26, Loss(train/val) 0.01506/0.00247. Took 0.25 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.75/0.43, Loss(train/val) 0.01402/0.00590. Took 0.25 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.59/0.77, Loss(train/val) 0.00996/0.02268. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.68/0.78, Loss(train/val) 0.01407/0.02577. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.56/0.69, Loss(train/val) 0.01045/0.01953. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.81/0.63, Loss(train/val) 0.01771/0.01381. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.64/0.50, Loss(train/val) 0.01114/0.00879. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.63/0.74, Loss(train/val) 0.01083/0.02096. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.76/0.78, Loss(train/val) 0.01680/0.02544. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.64/0.55, Loss(train/val) 0.01294/0.01184. Took 0.25 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.73/0.56, Loss(train/val) 0.01556/0.01240. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.73/0.58, Loss(train/val) 0.01461/0.01263. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.85/0.60, Loss(train/val) 0.01968/0.01466. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.76/0.55, Loss(train/val) 0.01551/0.01295. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.78/0.47, Loss(train/val) 0.01707/0.00888. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.79/0.31, Loss(train/val) 0.01803/0.00329. Took 0.24 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.77/0.45, Loss(train/val) 0.01761/0.00615. Took 0.23 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.78/0.46, Loss(train/val) 0.01722/0.00662. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.66/0.42, Loss(train/val) 0.01325/0.00521. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.64/0.42, Loss(train/val) 0.01199/0.00526. Took 0.24 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.62/0.39, Loss(train/val) 0.01123/0.00453. Took 0.24 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.62/0.37, Loss(train/val) 0.01108/0.00414. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.63/0.44, Loss(train/val) 0.01071/0.00520. Took 0.24 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.65/0.41, Loss(train/val) 0.01126/0.00472. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.61/0.47, Loss(train/val) 0.01049/0.00600. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.62/0.36, Loss(train/val) 0.01051/0.00386. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.56/0.39, Loss(train/val) 0.00887/0.00428. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.58/0.34, Loss(train/val) 0.00927/0.00355. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.54/0.35, Loss(train/val) 0.00813/0.00379. Took 0.24 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.53/0.32, Loss(train/val) 0.00817/0.00323. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.52/0.37, Loss(train/val) 0.00765/0.00397. Took 0.27 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.54/0.34, Loss(train/val) 0.00843/0.00355. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.51/0.34, Loss(train/val) 0.00770/0.00367. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.49/0.35, Loss(train/val) 0.00702/0.00370. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.50/0.29, Loss(train/val) 0.00728/0.00306. Took 0.25 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.44/0.33, Loss(train/val) 0.00596/0.00344. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.47/0.33, Loss(train/val) 0.00687/0.00344. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.48/0.35, Loss(train/val) 0.00689/0.00376. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.47/0.28, Loss(train/val) 0.00691/0.00295. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_9\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.47/0.71, Loss(train/val) 0.07438/0.01699. Took 0.25 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.08/0.41, Loss(train/val) 0.03411/0.00533. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.83/0.64, Loss(train/val) 0.01982/0.01203. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.92/0.44, Loss(train/val) 0.02290/0.00654. Took 0.25 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.74/0.32, Loss(train/val) 0.01446/0.00332. Took 0.25 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.80/0.27, Loss(train/val) 0.01652/0.00261. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.67/0.32, Loss(train/val) 0.01218/0.00360. Took 0.25 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.67/0.37, Loss(train/val) 0.01189/0.00497. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.72/0.28, Loss(train/val) 0.01304/0.00276. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.72/0.30, Loss(train/val) 0.01294/0.00313. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.73/0.35, Loss(train/val) 0.01337/0.00428. Took 0.23 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.72/0.32, Loss(train/val) 0.01342/0.00354. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.58/0.30, Loss(train/val) 0.00983/0.00341. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.65/0.33, Loss(train/val) 0.01112/0.00430. Took 0.23 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.61/0.32, Loss(train/val) 0.00993/0.00370. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.59/0.41, Loss(train/val) 0.00950/0.00609. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.58/0.37, Loss(train/val) 0.00925/0.00546. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.57/0.42, Loss(train/val) 0.00933/0.00744. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.61/0.47, Loss(train/val) 0.01012/0.00893. Took 0.25 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.69/0.41, Loss(train/val) 0.01327/0.00690. Took 0.23 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.64/0.43, Loss(train/val) 0.01084/0.00650. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Acc_RMSE(train/val): 0.68/0.49, Loss(train/val) 0.01200/0.00868. Took 0.25 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.57/0.37, Loss(train/val) 0.00895/0.00484. Took 0.24 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.70/0.53, Loss(train/val) 0.01218/0.00991. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.54/0.47, Loss(train/val) 0.00839/0.00780. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.67/0.59, Loss(train/val) 0.01184/0.01366. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.68/0.43, Loss(train/val) 0.01265/0.00698. Took 0.23 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.71/0.51, Loss(train/val) 0.01310/0.00959. Took 0.25 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.70/0.39, Loss(train/val) 0.01238/0.00529. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.66/0.52, Loss(train/val) 0.01201/0.00973. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.72/0.57, Loss(train/val) 0.01479/0.01201. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.78/0.55, Loss(train/val) 0.01588/0.01085. Took 0.23 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.66/0.42, Loss(train/val) 0.01199/0.00585. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.79/0.42, Loss(train/val) 0.01749/0.00517. Took 0.23 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.76/0.55, Loss(train/val) 0.01596/0.00798. Took 0.24 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.73/0.55, Loss(train/val) 0.01498/0.00821. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.69/0.55, Loss(train/val) 0.01322/0.00809. Took 0.23 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.67/0.54, Loss(train/val) 0.01248/0.00769. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.64/0.52, Loss(train/val) 0.01153/0.00726. Took 0.23 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.64/0.50, Loss(train/val) 0.01121/0.00693. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.65/0.51, Loss(train/val) 0.01125/0.00697. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.63/0.50, Loss(train/val) 0.01093/0.00685. Took 0.25 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.64/0.43, Loss(train/val) 0.01093/0.00526. Took 0.24 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.61/0.35, Loss(train/val) 0.01014/0.00393. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.66/0.30, Loss(train/val) 0.01175/0.00328. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.61/0.37, Loss(train/val) 0.00995/0.00514. Took 0.24 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.61/0.37, Loss(train/val) 0.00987/0.00512. Took 0.25 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.58/0.41, Loss(train/val) 0.00965/0.00663. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.61/0.36, Loss(train/val) 0.01061/0.00443. Took 0.23 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.65/0.47, Loss(train/val) 0.01135/0.00594. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.66/0.47, Loss(train/val) 0.01172/0.00601. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.63/0.41, Loss(train/val) 0.01067/0.00489. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.79/0.41, Loss(train/val) 0.01776/0.00469. Took 0.25 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.87/0.58, Loss(train/val) 0.01836/0.00835. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.67/0.39, Loss(train/val) 0.01213/0.00433. Took 0.24 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.53/0.42, Loss(train/val) 0.00863/0.00524. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.62/0.39, Loss(train/val) 0.01053/0.00456. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.64/0.43, Loss(train/val) 0.01079/0.00534. Took 0.23 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.58/0.46, Loss(train/val) 0.00942/0.00586. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.61/0.42, Loss(train/val) 0.00995/0.00526. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.58/0.34, Loss(train/val) 0.00984/0.00358. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.59/0.44, Loss(train/val) 0.00959/0.00559. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.63/0.37, Loss(train/val) 0.01055/0.00415. Took 0.25 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.59/0.50, Loss(train/val) 0.00924/0.00666. Took 0.23 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.62/0.45, Loss(train/val) 0.01042/0.00567. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_10\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.58/0.73, Loss(train/val) 0.09334/0.01816. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.08/0.40, Loss(train/val) 0.03466/0.00491. Took 0.23 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.85/0.51, Loss(train/val) 0.02012/0.00837. Took 0.23 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.89/0.36, Loss(train/val) 0.02195/0.00516. Took 0.24 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.64/0.31, Loss(train/val) 0.01116/0.00315. Took 0.23 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.76/0.29, Loss(train/val) 0.01515/0.00303. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.65/0.51, Loss(train/val) 0.01194/0.00690. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.87/0.49, Loss(train/val) 0.01894/0.00820. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.64/0.32, Loss(train/val) 0.01135/0.00353. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.64/0.36, Loss(train/val) 0.01111/0.00489. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.62/0.31, Loss(train/val) 0.01037/0.00351. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.64/0.31, Loss(train/val) 0.01084/0.00333. Took 0.25 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.66/0.30, Loss(train/val) 0.01144/0.00303. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.71/0.32, Loss(train/val) 0.01326/0.00351. Took 0.25 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.61/0.39, Loss(train/val) 0.01043/0.00544. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.60/0.61, Loss(train/val) 0.01042/0.01409. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.60/0.52, Loss(train/val) 0.01069/0.01211. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.71/0.55, Loss(train/val) 0.01374/0.01252. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.51/0.45, Loss(train/val) 0.00804/0.00853. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.71/0.59, Loss(train/val) 0.01349/0.01351. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.51/0.48, Loss(train/val) 0.00809/0.00906. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.69/0.69, Loss(train/val) 0.01314/0.01926. Took 0.25 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.58/0.51, Loss(train/val) 0.01000/0.01009. Took 0.25 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.66/0.66, Loss(train/val) 0.01214/0.01691. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.63/0.72, Loss(train/val) 0.01151/0.01999. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.71/0.70, Loss(train/val) 0.01462/0.02098. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.63/0.53, Loss(train/val) 0.01162/0.01123. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.72/0.76, Loss(train/val) 0.01517/0.02242. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.71/0.43, Loss(train/val) 0.01526/0.00721. Took 0.25 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.79/0.40, Loss(train/val) 0.01760/0.00629. Took 0.25 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.81/0.38, Loss(train/val) 0.01900/0.00570. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.79/0.32, Loss(train/val) 0.01728/0.00341. Took 0.25 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.78/0.47, Loss(train/val) 0.01670/0.00611. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.73/0.49, Loss(train/val) 0.01519/0.00710. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.68/0.47, Loss(train/val) 0.01343/0.00610. Took 0.23 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.66/0.37, Loss(train/val) 0.01380/0.00432. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.80/0.28, Loss(train/val) 0.01346/0.00259. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.68/0.30, Loss(train/val) 0.01224/0.00292. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.71/0.25, Loss(train/val) 0.01371/0.00229. Took 0.23 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.93/0.31, Loss(train/val) 0.02385/0.00340. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.51/0.27, Loss(train/val) 0.00890/0.00259. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.54/0.46, Loss(train/val) 0.00917/0.00600. Took 0.25 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.65/0.28, Loss(train/val) 0.01173/0.00299. Took 0.24 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.53/0.43, Loss(train/val) 0.00835/0.00525. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.62/0.49, Loss(train/val) 0.01097/0.00650. Took 0.27 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.01065/0.00407. Took 0.25 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.52/0.47, Loss(train/val) 0.00821/0.00606. Took 0.25 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Acc_RMSE(train/val): 0.55/0.51, Loss(train/val) 0.00928/0.00702. Took 0.25 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.53/0.44, Loss(train/val) 0.00875/0.00530. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.49/0.42, Loss(train/val) 0.00749/0.00509. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.51/0.54, Loss(train/val) 0.00797/0.00771. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.52/0.42, Loss(train/val) 0.00865/0.00505. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.47/0.46, Loss(train/val) 0.00700/0.00595. Took 0.25 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.55/0.43, Loss(train/val) 0.00886/0.00532. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.54/0.58, Loss(train/val) 0.00893/0.00881. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.51/0.36, Loss(train/val) 0.00798/0.00384. Took 0.23 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.54/0.27, Loss(train/val) 0.00843/0.00255. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.54/0.33, Loss(train/val) 0.00858/0.00345. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.52/0.28, Loss(train/val) 0.00815/0.00282. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.53/0.25, Loss(train/val) 0.00823/0.00224. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.52/0.25, Loss(train/val) 0.00805/0.00231. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.51/0.25, Loss(train/val) 0.00792/0.00234. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.50/0.37, Loss(train/val) 0.00747/0.00425. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.51/0.24, Loss(train/val) 0.00762/0.00214. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.43/0.42, Loss(train/val) 0.00619/0.00531. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_11\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.50/0.59, Loss(train/val) 0.07819/0.01132. Took 0.26 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 0.99/0.34, Loss(train/val) 0.02838/0.00381. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.92/0.46, Loss(train/val) 0.02210/0.00680. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.78/0.41, Loss(train/val) 0.01671/0.00482. Took 0.26 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.70/0.35, Loss(train/val) 0.01336/0.00439. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.80/0.42, Loss(train/val) 0.01582/0.00626. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.79/0.31, Loss(train/val) 0.01577/0.00325. Took 0.26 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.83/0.40, Loss(train/val) 0.01691/0.00560. Took 0.23 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.77/0.38, Loss(train/val) 0.01504/0.00571. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.68/0.44, Loss(train/val) 0.01219/0.00812. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.67/0.40, Loss(train/val) 0.01209/0.00652. Took 0.23 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.67/0.37, Loss(train/val) 0.01170/0.00543. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.74/0.44, Loss(train/val) 0.01373/0.00775. Took 0.25 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.70/0.35, Loss(train/val) 0.01233/0.00489. Took 0.23 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.70/0.42, Loss(train/val) 0.01194/0.00682. Took 0.23 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.61/0.29, Loss(train/val) 0.00996/0.00309. Took 0.23 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.68/0.46, Loss(train/val) 0.01221/0.00945. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.57/0.34, Loss(train/val) 0.00902/0.00461. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.70/0.60, Loss(train/val) 0.01371/0.01515. Took 0.25 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.77/0.43, Loss(train/val) 0.01564/0.00614. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.87/0.43, Loss(train/val) 0.01644/0.00592. Took 0.25 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.69/0.26, Loss(train/val) 0.01192/0.00245. Took 0.25 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.64/0.50, Loss(train/val) 0.01175/0.00974. Took 0.24 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.72/0.47, Loss(train/val) 0.01404/0.00801. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.74/0.45, Loss(train/val) 0.01428/0.00678. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.78/0.40, Loss(train/val) 0.01467/0.00509. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.63/0.40, Loss(train/val) 0.01100/0.00598. Took 0.23 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.74/0.50, Loss(train/val) 0.01639/0.00945. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.79/0.32, Loss(train/val) 0.01889/0.00381. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.81/0.30, Loss(train/val) 0.01653/0.00294. Took 0.25 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.85/0.33, Loss(train/val) 0.01935/0.00349. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.68/0.48, Loss(train/val) 0.01308/0.00614. Took 0.25 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.78/0.39, Loss(train/val) 0.01636/0.00458. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.61/0.47, Loss(train/val) 0.01141/0.00622. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.68/0.50, Loss(train/val) 0.01270/0.00675. Took 0.23 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.64/0.55, Loss(train/val) 0.01169/0.00803. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.63/0.47, Loss(train/val) 0.01115/0.00610. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.59/0.53, Loss(train/val) 0.01002/0.00745. Took 0.25 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.64/0.42, Loss(train/val) 0.01121/0.00495. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.59/0.50, Loss(train/val) 0.00953/0.00654. Took 0.27 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.58/0.49, Loss(train/val) 0.00979/0.00649. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.59/0.43, Loss(train/val) 0.00976/0.00516. Took 0.27 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.55/0.45, Loss(train/val) 0.00874/0.00555. Took 0.24 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.59/0.40, Loss(train/val) 0.00951/0.00475. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.55/0.40, Loss(train/val) 0.00854/0.00464. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.55/0.37, Loss(train/val) 0.00859/0.00407. Took 0.25 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.52/0.36, Loss(train/val) 0.00799/0.00402. Took 0.23 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.53/0.31, Loss(train/val) 0.00806/0.00326. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.48/0.30, Loss(train/val) 0.00702/0.00325. Took 0.24 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.47/0.33, Loss(train/val) 0.00676/0.00360. Took 0.26 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.48/0.31, Loss(train/val) 0.00725/0.00340. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.47/0.32, Loss(train/val) 0.00677/0.00341. Took 0.23 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.45/0.33, Loss(train/val) 0.00628/0.00352. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.46/0.30, Loss(train/val) 0.00665/0.00305. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.44/0.30, Loss(train/val) 0.00625/0.00305. Took 0.23 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.45/0.35, Loss(train/val) 0.00664/0.00415. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.44/0.32, Loss(train/val) 0.00608/0.00320. Took 0.25 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.48/0.29, Loss(train/val) 0.00720/0.00315. Took 0.23 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.52/0.36, Loss(train/val) 0.00768/0.00385. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.49/0.34, Loss(train/val) 0.00760/0.00400. Took 0.25 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.46/0.42, Loss(train/val) 0.00652/0.00509. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.50/0.29, Loss(train/val) 0.00790/0.00277. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.44/0.28, Loss(train/val) 0.00644/0.00275. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.48/0.29, Loss(train/val) 0.00709/0.00300. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.51/0.34, Loss(train/val) 0.00820/0.00364. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_12\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.71/0.85, Loss(train/val) 0.11932/0.02573. Took 0.25 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.21/0.76, Loss(train/val) 0.04393/0.02017. Took 0.25 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.13/0.46, Loss(train/val) 0.03842/0.00658. Took 0.25 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.83/0.70, Loss(train/val) 0.02074/0.01143. Took 0.24 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 1.21/0.56, Loss(train/val) 0.04132/0.01030. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.80/0.50, Loss(train/val) 0.01835/0.00701. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Acc_RMSE(train/val): 0.80/0.31, Loss(train/val) 0.01727/0.00376. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.68/0.29, Loss(train/val) 0.01281/0.00296. Took 0.25 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.84/0.27, Loss(train/val) 0.01801/0.00268. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.77/0.35, Loss(train/val) 0.01554/0.00434. Took 0.25 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.66/0.32, Loss(train/val) 0.01191/0.00422. Took 0.25 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.70/0.28, Loss(train/val) 0.01270/0.00282. Took 0.25 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.71/0.33, Loss(train/val) 0.01315/0.00436. Took 0.25 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.56/0.31, Loss(train/val) 0.00896/0.00396. Took 0.25 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.66/0.34, Loss(train/val) 0.01150/0.00450. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.59/0.42, Loss(train/val) 0.00993/0.00682. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.54/0.49, Loss(train/val) 0.00877/0.01011. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.01047/0.00556. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.58/0.44, Loss(train/val) 0.00954/0.00750. Took 0.25 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.49/0.58, Loss(train/val) 0.00788/0.01324. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.53/0.54, Loss(train/val) 0.00948/0.01154. Took 0.25 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.65/0.39, Loss(train/val) 0.01210/0.00544. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.57/0.47, Loss(train/val) 0.00953/0.00825. Took 0.24 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.56/0.58, Loss(train/val) 0.00992/0.01177. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.59/0.39, Loss(train/val) 0.01071/0.00597. Took 0.25 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.87/0.32, Loss(train/val) 0.01800/0.00320. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 1.02/0.36, Loss(train/val) 0.02269/0.00442. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.81/0.42, Loss(train/val) 0.01818/0.00797. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.78/0.35, Loss(train/val) 0.01545/0.00436. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.70/0.33, Loss(train/val) 0.01217/0.00362. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.83/0.39, Loss(train/val) 0.01579/0.00478. Took 0.26 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.67/0.51, Loss(train/val) 0.01281/0.01174. Took 0.26 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.73/0.58, Loss(train/val) 0.01503/0.01218. Took 0.25 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.74/0.39, Loss(train/val) 0.01441/0.00561. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.60/0.50, Loss(train/val) 0.01026/0.00947. Took 0.24 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.77/0.57, Loss(train/val) 0.01638/0.01175. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.77/0.44, Loss(train/val) 0.01679/0.00684. Took 0.25 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.73/0.31, Loss(train/val) 0.01508/0.00350. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.83/0.33, Loss(train/val) 0.01778/0.00411. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.88/0.44, Loss(train/val) 0.02162/0.00558. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.74/0.40, Loss(train/val) 0.01531/0.00473. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.77/0.45, Loss(train/val) 0.01622/0.00590. Took 0.25 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.73/0.52, Loss(train/val) 0.01536/0.00789. Took 0.23 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.73/0.59, Loss(train/val) 0.01484/0.00942. Took 0.23 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.73/0.55, Loss(train/val) 0.01423/0.00815. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.65/0.51, Loss(train/val) 0.01191/0.00724. Took 0.24 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.64/0.48, Loss(train/val) 0.01148/0.00622. Took 0.23 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.63/0.47, Loss(train/val) 0.01085/0.00618. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.63/0.49, Loss(train/val) 0.01084/0.00656. Took 0.26 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.61/0.38, Loss(train/val) 0.01047/0.00431. Took 0.25 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.59/0.36, Loss(train/val) 0.00917/0.00390. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.58/0.33, Loss(train/val) 0.00917/0.00334. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.57/0.31, Loss(train/val) 0.00901/0.00312. Took 0.25 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.58/0.31, Loss(train/val) 0.00903/0.00313. Took 0.26 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.58/0.38, Loss(train/val) 0.00921/0.00415. Took 0.23 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.61/0.40, Loss(train/val) 0.01005/0.00453. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.62/0.44, Loss(train/val) 0.01035/0.00537. Took 0.25 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.65/0.46, Loss(train/val) 0.01125/0.00581. Took 0.23 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.65/0.47, Loss(train/val) 0.01148/0.00610. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.64/0.41, Loss(train/val) 0.01096/0.00486. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.59/0.47, Loss(train/val) 0.00945/0.00605. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.59/0.41, Loss(train/val) 0.00978/0.00483. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.56/0.42, Loss(train/val) 0.00872/0.00494. Took 0.25 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.56/0.47, Loss(train/val) 0.00896/0.00615. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00881/0.00335. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_13\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.66/0.50, Loss(train/val) 0.11695/0.00822. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.17/0.61, Loss(train/val) 0.04150/0.01229. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.14/0.58, Loss(train/val) 0.03969/0.01091. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.14/0.45, Loss(train/val) 0.03957/0.00652. Took 0.24 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 1.03/0.53, Loss(train/val) 0.03093/0.00903. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.99/0.32, Loss(train/val) 0.02785/0.00340. Took 0.23 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.83/0.60, Loss(train/val) 0.01915/0.00959. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.79/0.38, Loss(train/val) 0.01650/0.00474. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.74/0.46, Loss(train/val) 0.01485/0.00588. Took 0.26 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.79/0.49, Loss(train/val) 0.01674/0.00680. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.74/0.58, Loss(train/val) 0.01470/0.00863. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.65/0.41, Loss(train/val) 0.01141/0.00518. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.65/0.42, Loss(train/val) 0.01128/0.00537. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.62/0.56, Loss(train/val) 0.01083/0.00811. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.76/0.68, Loss(train/val) 0.01572/0.01133. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.79/0.44, Loss(train/val) 0.01632/0.00596. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.61/0.40, Loss(train/val) 0.01011/0.00569. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.58/0.38, Loss(train/val) 0.00951/0.00520. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.52/0.47, Loss(train/val) 0.00842/0.00672. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.56/0.43, Loss(train/val) 0.00897/0.00540. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.72/0.76, Loss(train/val) 0.01476/0.01370. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.84/0.47, Loss(train/val) 0.01785/0.00601. Took 0.25 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.74/0.33, Loss(train/val) 0.01444/0.00404. Took 0.24 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.57/0.43, Loss(train/val) 0.00986/0.00746. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.58/0.35, Loss(train/val) 0.00956/0.00515. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.55/0.49, Loss(train/val) 0.00841/0.00663. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.67/0.36, Loss(train/val) 0.01214/0.00449. Took 0.25 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.56/0.38, Loss(train/val) 0.00927/0.00586. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.55/0.35, Loss(train/val) 0.00849/0.00488. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.53/0.33, Loss(train/val) 0.00820/0.00395. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.51/0.38, Loss(train/val) 0.00775/0.00596. Took 0.25 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.54/0.47, Loss(train/val) 0.00898/0.00944. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Acc_RMSE(train/val): 0.51/0.56, Loss(train/val) 0.00804/0.00865. Took 0.25 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.79/0.46, Loss(train/val) 0.01618/0.00590. Took 0.25 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.86/0.31, Loss(train/val) 0.01782/0.00349. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.64/0.26, Loss(train/val) 0.01142/0.00247. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.66/0.48, Loss(train/val) 0.01149/0.00861. Took 0.25 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.53/0.47, Loss(train/val) 0.00810/0.00882. Took 0.25 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.48/0.44, Loss(train/val) 0.00712/0.00808. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.52/0.42, Loss(train/val) 0.00799/0.00666. Took 0.25 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.56/0.40, Loss(train/val) 0.00840/0.00573. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.52/0.49, Loss(train/val) 0.00819/0.00858. Took 0.23 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.48/0.37, Loss(train/val) 0.00694/0.00523. Took 0.24 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.74/0.24, Loss(train/val) 0.01332/0.00211. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.75/0.37, Loss(train/val) 0.01345/0.00452. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.59/0.60, Loss(train/val) 0.00978/0.01304. Took 0.24 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.57/0.43, Loss(train/val) 0.00937/0.00624. Took 0.24 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.77/0.75, Loss(train/val) 0.01567/0.02171. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.58/0.37, Loss(train/val) 0.01022/0.00563. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.74/0.69, Loss(train/val) 0.01601/0.01786. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.80/0.38, Loss(train/val) 0.01639/0.00579. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.82/0.28, Loss(train/val) 0.01905/0.00278. Took 0.26 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.77/0.40, Loss(train/val) 0.01703/0.00464. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.79/0.50, Loss(train/val) 0.01700/0.00689. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.75/0.55, Loss(train/val) 0.01543/0.00823. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.69/0.55, Loss(train/val) 0.01305/0.00816. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.68/0.55, Loss(train/val) 0.01287/0.00814. Took 0.23 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.64/0.49, Loss(train/val) 0.01134/0.00668. Took 0.26 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.61/0.52, Loss(train/val) 0.01069/0.00733. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.65/0.49, Loss(train/val) 0.01148/0.00658. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.62/0.50, Loss(train/val) 0.01048/0.00692. Took 0.25 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.63/0.38, Loss(train/val) 0.01059/0.00425. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.58/0.36, Loss(train/val) 0.00909/0.00399. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.59/0.39, Loss(train/val) 0.00940/0.00450. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.62/0.36, Loss(train/val) 0.01007/0.00395. Took 0.26 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_14\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.58/0.59, Loss(train/val) 0.11446/0.01197. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.16/0.57, Loss(train/val) 0.03951/0.01049. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.17/0.76, Loss(train/val) 0.04091/0.02020. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.15/0.62, Loss(train/val) 0.03997/0.01276. Took 0.25 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 1.05/0.47, Loss(train/val) 0.03333/0.00676. Took 0.25 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 1.09/0.35, Loss(train/val) 0.03286/0.00417. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.74/0.50, Loss(train/val) 0.01609/0.00687. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.79/0.34, Loss(train/val) 0.01614/0.00412. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.70/0.37, Loss(train/val) 0.01309/0.00428. Took 0.23 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.67/0.37, Loss(train/val) 0.01215/0.00498. Took 0.25 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.59/0.67, Loss(train/val) 0.01016/0.01123. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.84/0.34, Loss(train/val) 0.01801/0.00387. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.73/0.33, Loss(train/val) 0.01432/0.00357. Took 0.23 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.78/0.34, Loss(train/val) 0.01577/0.00439. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.67/0.51, Loss(train/val) 0.01207/0.00723. Took 0.23 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.72/0.39, Loss(train/val) 0.01341/0.00557. Took 0.23 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.64/0.40, Loss(train/val) 0.01093/0.00536. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.66/0.33, Loss(train/val) 0.01136/0.00411. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.60/0.35, Loss(train/val) 0.01010/0.00516. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.59/0.33, Loss(train/val) 0.00986/0.00447. Took 0.23 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.61/0.32, Loss(train/val) 0.00988/0.00391. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.70/0.43, Loss(train/val) 0.01275/0.00546. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.83/0.28, Loss(train/val) 0.01675/0.00305. Took 0.25 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.63/0.48, Loss(train/val) 0.01144/0.00870. Took 0.23 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.68/0.33, Loss(train/val) 0.01219/0.00386. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.60/0.62, Loss(train/val) 0.01042/0.01502. Took 0.23 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.64/0.40, Loss(train/val) 0.01166/0.00684. Took 0.23 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.74/0.51, Loss(train/val) 0.01426/0.00941. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.52/0.57, Loss(train/val) 0.00825/0.01209. Took 0.25 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.86/0.46, Loss(train/val) 0.01786/0.00793. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.48/0.47, Loss(train/val) 0.00764/0.00912. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 1.06/0.63, Loss(train/val) 0.02547/0.01328. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.97/0.47, Loss(train/val) 0.02222/0.00712. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.79/0.53, Loss(train/val) 0.01898/0.01269. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.83/0.38, Loss(train/val) 0.01724/0.00539. Took 0.24 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.86/0.45, Loss(train/val) 0.01719/0.00713. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.78/0.49, Loss(train/val) 0.01605/0.01017. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.81/0.42, Loss(train/val) 0.01986/0.00598. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.80/0.42, Loss(train/val) 0.01777/0.00514. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.81/0.64, Loss(train/val) 0.01796/0.01001. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.78/0.43, Loss(train/val) 0.01661/0.00535. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.61/0.38, Loss(train/val) 0.01080/0.00453. Took 0.26 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.65/0.40, Loss(train/val) 0.01179/0.00491. Took 0.26 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.67/0.37, Loss(train/val) 0.01245/0.00441. Took 0.26 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.64/0.37, Loss(train/val) 0.01146/0.00431. Took 0.25 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.65/0.40, Loss(train/val) 0.01189/0.00501. Took 0.25 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.62/0.41, Loss(train/val) 0.01105/0.00516. Took 0.25 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.65/0.42, Loss(train/val) 0.01177/0.00523. Took 0.26 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.63/0.47, Loss(train/val) 0.01095/0.00632. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.62/0.39, Loss(train/val) 0.01064/0.00476. Took 0.25 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.58/0.38, Loss(train/val) 0.00975/0.00444. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.56/0.38, Loss(train/val) 0.00913/0.00460. Took 0.25 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00920/0.00372. Took 0.27 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.00988/0.00440. Took 0.25 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.65/0.35, Loss(train/val) 0.01108/0.00418. Took 0.26 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.00991/0.00446. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.55/0.37, Loss(train/val) 0.00880/0.00433. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.50/0.39, Loss(train/val) 0.00770/0.00467. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Acc_RMSE(train/val): 0.47/0.36, Loss(train/val) 0.00732/0.00424. Took 0.26 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.48/0.43, Loss(train/val) 0.00753/0.00557. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.49/0.41, Loss(train/val) 0.00774/0.00528. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.48/0.43, Loss(train/val) 0.00734/0.00551. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.48/0.40, Loss(train/val) 0.00747/0.00516. Took 0.23 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.47/0.40, Loss(train/val) 0.00694/0.00506. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.47/0.35, Loss(train/val) 0.00700/0.00406. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_15\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.77/0.61, Loss(train/val) 0.11042/0.01230. Took 0.25 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.12/0.48, Loss(train/val) 0.03756/0.00715. Took 0.23 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.97/0.56, Loss(train/val) 0.02583/0.01088. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.00/0.39, Loss(train/val) 0.02882/0.00538. Took 0.23 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.85/0.29, Loss(train/val) 0.01831/0.00308. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.75/0.45, Loss(train/val) 0.01623/0.00595. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.83/0.28, Loss(train/val) 0.01726/0.00275. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.62/0.44, Loss(train/val) 0.01127/0.00574. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.64/0.33, Loss(train/val) 0.01107/0.00378. Took 0.23 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.64/0.31, Loss(train/val) 0.01097/0.00339. Took 0.25 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.61/0.32, Loss(train/val) 0.01011/0.00338. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.67/0.30, Loss(train/val) 0.01214/0.00289. Took 0.25 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.68/0.28, Loss(train/val) 0.01250/0.00286. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.64/0.29, Loss(train/val) 0.01152/0.00318. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.55/0.49, Loss(train/val) 0.00922/0.01011. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.50/0.48, Loss(train/val) 0.00810/0.01032. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.50/0.38, Loss(train/val) 0.00784/0.00598. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.60/0.28, Loss(train/val) 0.00972/0.00301. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.63/0.24, Loss(train/val) 0.01025/0.00202. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.69/0.27, Loss(train/val) 0.01233/0.00248. Took 0.23 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.64/0.28, Loss(train/val) 0.01113/0.00272. Took 0.23 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.56/0.46, Loss(train/val) 0.00906/0.00762. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.60/0.78, Loss(train/val) 0.01093/0.02608. Took 0.23 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.58/0.52, Loss(train/val) 0.01079/0.01211. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.58/0.55, Loss(train/val) 0.00981/0.01212. Took 0.23 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.52/0.65, Loss(train/val) 0.00835/0.01713. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.57/0.52, Loss(train/val) 0.00958/0.01052. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.50/0.51, Loss(train/val) 0.00752/0.01037. Took 0.23 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.59/0.67, Loss(train/val) 0.00886/0.01680. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.70/0.34, Loss(train/val) 0.01339/0.00433. Took 0.24 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.67/0.55, Loss(train/val) 0.01155/0.01146. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.71/0.91, Loss(train/val) 0.01393/0.03164. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.77/0.45, Loss(train/val) 0.01557/0.00831. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.75/0.62, Loss(train/val) 0.01560/0.01767. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.68/0.52, Loss(train/val) 0.01344/0.01072. Took 0.24 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.62/0.58, Loss(train/val) 0.01204/0.01300. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.66/0.40, Loss(train/val) 0.01465/0.00572. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.77/0.38, Loss(train/val) 0.01575/0.00523. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.78/0.37, Loss(train/val) 0.01748/0.00446. Took 0.23 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.76/0.39, Loss(train/val) 0.01570/0.00431. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.78/0.50, Loss(train/val) 0.01706/0.00677. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.79/0.55, Loss(train/val) 0.01782/0.00901. Took 0.24 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.69/0.56, Loss(train/val) 0.01415/0.00822. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.73/0.47, Loss(train/val) 0.01465/0.00616. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.60/0.47, Loss(train/val) 0.01093/0.00620. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.58/0.47, Loss(train/val) 0.01044/0.00601. Took 0.23 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.56/0.41, Loss(train/val) 0.00942/0.00478. Took 0.24 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.53/0.41, Loss(train/val) 0.00874/0.00475. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.53/0.31, Loss(train/val) 0.00852/0.00311. Took 0.24 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.49/0.40, Loss(train/val) 0.00747/0.00462. Took 0.23 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.50/0.32, Loss(train/val) 0.00780/0.00323. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.47/0.35, Loss(train/val) 0.00704/0.00364. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.49/0.24, Loss(train/val) 0.00794/0.00214. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.43/0.41, Loss(train/val) 0.00633/0.00473. Took 0.23 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.52/0.37, Loss(train/val) 0.00832/0.00401. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.49/0.26, Loss(train/val) 0.00756/0.00236. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.45/0.40, Loss(train/val) 0.00677/0.00474. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.50/0.38, Loss(train/val) 0.00759/0.00419. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.47/0.30, Loss(train/val) 0.00697/0.00302. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.45/0.32, Loss(train/val) 0.00678/0.00336. Took 0.25 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.43/0.31, Loss(train/val) 0.00628/0.00325. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.47/0.59, Loss(train/val) 0.00673/0.00930. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.50/0.24, Loss(train/val) 0.00730/0.00218. Took 0.25 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.44/0.36, Loss(train/val) 0.00650/0.00397. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.46/0.57, Loss(train/val) 0.00651/0.00856. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_16\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.57/0.62, Loss(train/val) 0.08553/0.01267. Took 0.27 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.00/0.39, Loss(train/val) 0.02954/0.00476. Took 0.26 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.89/0.26, Loss(train/val) 0.02185/0.00232. Took 0.26 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.76/0.44, Loss(train/val) 0.01611/0.00567. Took 0.26 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.66/0.36, Loss(train/val) 0.01218/0.00452. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.77/0.33, Loss(train/val) 0.01522/0.00376. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.63/0.48, Loss(train/val) 0.01185/0.00629. Took 0.25 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.78/0.41, Loss(train/val) 0.01580/0.00607. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.62/0.39, Loss(train/val) 0.01078/0.00512. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.70/0.41, Loss(train/val) 0.01301/0.00595. Took 0.27 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.67/0.30, Loss(train/val) 0.01254/0.00306. Took 0.26 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.79/0.34, Loss(train/val) 0.01589/0.00390. Took 0.26 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.67/0.30, Loss(train/val) 0.01226/0.00326. Took 0.26 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.62/0.36, Loss(train/val) 0.01052/0.00513. Took 0.25 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.62/0.44, Loss(train/val) 0.01050/0.00732. Took 0.26 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.01012/0.00557. Took 0.25 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.62/0.35, Loss(train/val) 0.01042/0.00453. Took 0.26 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Acc_RMSE(train/val): 0.66/0.38, Loss(train/val) 0.01089/0.00487. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.58/0.32, Loss(train/val) 0.00937/0.00349. Took 0.26 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.71/0.25, Loss(train/val) 0.01237/0.00213. Took 0.27 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.62/0.25, Loss(train/val) 0.01058/0.00227. Took 0.28 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.67/0.54, Loss(train/val) 0.01137/0.01054. Took 0.34 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.60/0.40, Loss(train/val) 0.01029/0.00629. Took 0.27 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.61/0.61, Loss(train/val) 0.01028/0.01462. Took 0.25 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.60/0.61, Loss(train/val) 0.01086/0.01492. Took 0.27 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.78/0.63, Loss(train/val) 0.01748/0.01423. Took 0.27 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.58/0.37, Loss(train/val) 0.01010/0.00476. Took 0.26 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.74/0.50, Loss(train/val) 0.01495/0.00947. Took 0.26 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.71/0.35, Loss(train/val) 0.01408/0.00414. Took 0.26 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.65/0.32, Loss(train/val) 0.01177/0.00344. Took 0.27 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.80/0.33, Loss(train/val) 0.01743/0.00420. Took 0.25 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.77/0.33, Loss(train/val) 0.01694/0.00376. Took 0.26 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.77/0.32, Loss(train/val) 0.01639/0.00339. Took 0.25 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.81/0.38, Loss(train/val) 0.01754/0.00423. Took 0.25 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.76/0.46, Loss(train/val) 0.01599/0.00615. Took 0.27 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.68/0.49, Loss(train/val) 0.01292/0.00677. Took 0.26 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.65/0.49, Loss(train/val) 0.01190/0.00642. Took 0.25 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.62/0.39, Loss(train/val) 0.01101/0.00454. Took 0.25 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.59/0.38, Loss(train/val) 0.00987/0.00423. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.63/0.34, Loss(train/val) 0.01056/0.00376. Took 0.27 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.56/0.39, Loss(train/val) 0.00890/0.00444. Took 0.26 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.59/0.36, Loss(train/val) 0.00993/0.00389. Took 0.27 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.55/0.36, Loss(train/val) 0.00889/0.00389. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.62/0.35, Loss(train/val) 0.01051/0.00372. Took 0.26 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.60/0.39, Loss(train/val) 0.01000/0.00460. Took 0.30 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.59/0.38, Loss(train/val) 0.00962/0.00418. Took 0.28 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.58/0.35, Loss(train/val) 0.00921/0.00382. Took 0.28 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.56/0.34, Loss(train/val) 0.00897/0.00350. Took 0.26 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.55/0.35, Loss(train/val) 0.00871/0.00381. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.55/0.33, Loss(train/val) 0.00848/0.00339. Took 0.26 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.51/0.39, Loss(train/val) 0.00805/0.00441. Took 0.26 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.60/0.37, Loss(train/val) 0.00986/0.00395. Took 0.26 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.55/0.34, Loss(train/val) 0.00870/0.00366. Took 0.29 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.53/0.31, Loss(train/val) 0.00814/0.00300. Took 0.26 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.49/0.34, Loss(train/val) 0.00718/0.00376. Took 0.27 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.51/0.27, Loss(train/val) 0.00761/0.00272. Took 0.26 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.44/0.35, Loss(train/val) 0.00608/0.00395. Took 0.26 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.49/0.36, Loss(train/val) 0.00724/0.00404. Took 0.26 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.49/0.40, Loss(train/val) 0.00711/0.00485. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.49/0.43, Loss(train/val) 0.00710/0.00530. Took 0.26 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.48/0.29, Loss(train/val) 0.00715/0.00313. Took 0.25 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.44/0.48, Loss(train/val) 0.00626/0.00635. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.51/0.35, Loss(train/val) 0.00816/0.00383. Took 0.26 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.46/0.53, Loss(train/val) 0.00679/0.00760. Took 0.26 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.52/0.36, Loss(train/val) 0.00794/0.00400. Took 0.25 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_17\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.45/0.68, Loss(train/val) 0.07220/0.01542. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.10/0.69, Loss(train/val) 0.03619/0.01602. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.01/0.36, Loss(train/val) 0.02923/0.00490. Took 0.25 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.87/0.43, Loss(train/val) 0.02194/0.00549. Took 0.25 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.90/0.54, Loss(train/val) 0.02055/0.00961. Took 0.25 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.83/0.28, Loss(train/val) 0.01853/0.00275. Took 0.25 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.70/0.30, Loss(train/val) 0.01334/0.00336. Took 0.25 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.72/0.39, Loss(train/val) 0.01309/0.00534. Took 0.25 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.71/0.35, Loss(train/val) 0.01267/0.00458. Took 0.25 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.69/0.37, Loss(train/val) 0.01250/0.00523. Took 0.25 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.67/0.36, Loss(train/val) 0.01154/0.00475. Took 0.25 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.75/0.39, Loss(train/val) 0.01338/0.00555. Took 0.26 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.78/0.35, Loss(train/val) 0.01429/0.00394. Took 0.25 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.74/0.30, Loss(train/val) 0.01346/0.00326. Took 0.25 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.69/0.43, Loss(train/val) 0.01211/0.00714. Took 0.25 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.67/0.55, Loss(train/val) 0.01241/0.01271. Took 0.26 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.62/0.51, Loss(train/val) 0.01134/0.00937. Took 0.25 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.90/0.53, Loss(train/val) 0.02069/0.00955. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 1.19/0.55, Loss(train/val) 0.02766/0.00963. Took 0.26 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.95/0.43, Loss(train/val) 0.02252/0.00615. Took 0.26 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.76/0.51, Loss(train/val) 0.01519/0.01206. Took 0.27 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.68/0.30, Loss(train/val) 0.01390/0.00323. Took 0.27 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.76/0.40, Loss(train/val) 0.01626/0.00554. Took 0.28 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.71/0.32, Loss(train/val) 0.01486/0.00338. Took 0.28 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.67/0.29, Loss(train/val) 0.01268/0.00288. Took 0.27 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.69/0.48, Loss(train/val) 0.01280/0.00649. Took 0.27 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.71/0.46, Loss(train/val) 0.01357/0.00613. Took 0.29 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.64/0.43, Loss(train/val) 0.01162/0.00527. Took 0.28 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.66/0.53, Loss(train/val) 0.01187/0.00744. Took 0.25 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.66/0.48, Loss(train/val) 0.01193/0.00654. Took 0.26 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.63/0.45, Loss(train/val) 0.01079/0.00574. Took 0.26 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.64/0.51, Loss(train/val) 0.01124/0.00691. Took 0.27 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.62/0.42, Loss(train/val) 0.01064/0.00516. Took 0.26 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.58/0.42, Loss(train/val) 0.00968/0.00519. Took 0.26 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.62/0.47, Loss(train/val) 0.01054/0.00603. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.61/0.47, Loss(train/val) 0.01032/0.00599. Took 0.27 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.60/0.46, Loss(train/val) 0.01023/0.00588. Took 0.26 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.63/0.53, Loss(train/val) 0.01058/0.00747. Took 0.26 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.60/0.40, Loss(train/val) 0.00980/0.00481. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.56/0.39, Loss(train/val) 0.00852/0.00458. Took 0.26 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.55/0.39, Loss(train/val) 0.00851/0.00459. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.57/0.37, Loss(train/val) 0.00889/0.00425. Took 0.26 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.54/0.31, Loss(train/val) 0.00807/0.00330. Took 0.26 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Acc_RMSE(train/val): 0.52/0.40, Loss(train/val) 0.00797/0.00496. Took 0.26 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.56/0.35, Loss(train/val) 0.00838/0.00397. Took 0.26 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.52/0.35, Loss(train/val) 0.00788/0.00374. Took 0.26 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.55/0.32, Loss(train/val) 0.00868/0.00341. Took 0.26 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.52/0.32, Loss(train/val) 0.00769/0.00375. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.49/0.34, Loss(train/val) 0.00702/0.00386. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.49/0.39, Loss(train/val) 0.00725/0.00507. Took 0.25 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.50/0.37, Loss(train/val) 0.00719/0.00436. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.47/0.40, Loss(train/val) 0.00655/0.00503. Took 0.25 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.47/0.39, Loss(train/val) 0.00700/0.00466. Took 0.26 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.47/0.46, Loss(train/val) 0.00677/0.00601. Took 0.25 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.50/0.41, Loss(train/val) 0.00818/0.00506. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.48/0.32, Loss(train/val) 0.00707/0.00343. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.44/0.41, Loss(train/val) 0.00620/0.00526. Took 0.25 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.50/0.24, Loss(train/val) 0.00752/0.00213. Took 0.25 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.52/0.28, Loss(train/val) 0.00766/0.00276. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.54/0.48, Loss(train/val) 0.00849/0.00670. Took 0.26 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.63/0.31, Loss(train/val) 0.01085/0.00326. Took 0.25 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.56/0.59, Loss(train/val) 0.00863/0.01033. Took 0.27 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.58/0.69, Loss(train/val) 0.00935/0.01264. Took 0.26 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.59/0.33, Loss(train/val) 0.01090/0.00385. Took 0.27 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.56/0.45, Loss(train/val) 0.00895/0.00618. Took 0.26 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_18\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.60/0.82, Loss(train/val) 0.09221/0.02368. Took 0.30 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.12/0.59, Loss(train/val) 0.03744/0.01142. Took 0.26 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.82/0.94, Loss(train/val) 0.02030/0.02132. Took 0.29 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.01/0.32, Loss(train/val) 0.02715/0.00355. Took 0.26 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.84/0.42, Loss(train/val) 0.01791/0.00558. Took 0.30 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.74/0.31, Loss(train/val) 0.01492/0.00319. Took 0.27 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.73/0.27, Loss(train/val) 0.01416/0.00267. Took 0.26 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.69/0.28, Loss(train/val) 0.01255/0.00293. Took 0.25 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.65/0.30, Loss(train/val) 0.01143/0.00320. Took 0.25 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.69/0.31, Loss(train/val) 0.01223/0.00339. Took 0.26 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.67/0.29, Loss(train/val) 0.01160/0.00301. Took 0.27 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.67/0.28, Loss(train/val) 0.01158/0.00284. Took 0.26 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.69/0.30, Loss(train/val) 0.01200/0.00311. Took 0.27 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.85/0.42, Loss(train/val) 0.01766/0.00566. Took 0.27 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.86/0.38, Loss(train/val) 0.01898/0.00469. Took 0.27 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.69/0.30, Loss(train/val) 0.01315/0.00326. Took 0.27 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.67/0.27, Loss(train/val) 0.01173/0.00270. Took 0.27 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.74/0.37, Loss(train/val) 0.01482/0.00528. Took 0.27 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.53/0.56, Loss(train/val) 0.00858/0.01295. Took 0.27 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.60/0.53, Loss(train/val) 0.01103/0.01241. Took 0.27 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.58/0.52, Loss(train/val) 0.00987/0.01057. Took 0.27 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.57/0.37, Loss(train/val) 0.00949/0.00519. Took 0.27 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.69/0.53, Loss(train/val) 0.01218/0.01064. Took 0.26 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.55/0.38, Loss(train/val) 0.00844/0.00562. Took 0.25 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.69/0.67, Loss(train/val) 0.01344/0.01962. Took 0.25 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.57/0.47, Loss(train/val) 0.00982/0.00941. Took 0.25 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.73/0.58, Loss(train/val) 0.01513/0.01247. Took 0.25 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.67/0.39, Loss(train/val) 0.01216/0.00562. Took 0.25 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.58/0.48, Loss(train/val) 0.01012/0.00870. Took 0.25 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.73/0.56, Loss(train/val) 0.01540/0.01243. Took 0.26 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.71/0.49, Loss(train/val) 0.01467/0.00974. Took 0.26 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.71/0.49, Loss(train/val) 0.01390/0.01031. Took 0.25 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.70/0.45, Loss(train/val) 0.01314/0.00788. Took 0.25 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.86/0.70, Loss(train/val) 0.01901/0.01673. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.88/0.57, Loss(train/val) 0.01639/0.01222. Took 0.26 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.97/0.52, Loss(train/val) 0.02542/0.00885. Took 0.26 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.50/0.32, Loss(train/val) 0.00730/0.00389. Took 0.26 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.68/0.32, Loss(train/val) 0.01298/0.00397. Took 0.25 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.64/0.37, Loss(train/val) 0.01211/0.00507. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.70/0.30, Loss(train/val) 0.01416/0.00338. Took 0.25 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.64/0.46, Loss(train/val) 0.01182/0.00592. Took 0.26 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.79/0.49, Loss(train/val) 0.01691/0.00680. Took 0.25 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.66/0.60, Loss(train/val) 0.01294/0.00918. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.72/0.42, Loss(train/val) 0.01406/0.00541. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.55/0.46, Loss(train/val) 0.00925/0.00580. Took 0.26 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.60/0.43, Loss(train/val) 0.00998/0.00523. Took 0.25 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.54/0.43, Loss(train/val) 0.00894/0.00533. Took 0.26 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.54/0.43, Loss(train/val) 0.00852/0.00535. Took 0.25 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.53/0.50, Loss(train/val) 0.00852/0.00666. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.59/0.27, Loss(train/val) 0.00972/0.00281. Took 0.25 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.49/0.43, Loss(train/val) 0.00708/0.00512. Took 0.27 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.57/0.32, Loss(train/val) 0.00893/0.00328. Took 0.26 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.53/0.47, Loss(train/val) 0.00806/0.00605. Took 0.25 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.59/0.31, Loss(train/val) 0.00954/0.00318. Took 0.26 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.53/0.40, Loss(train/val) 0.00817/0.00469. Took 0.24 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.53/0.29, Loss(train/val) 0.00824/0.00304. Took 0.26 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.47/0.46, Loss(train/val) 0.00679/0.00596. Took 0.25 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.56/0.35, Loss(train/val) 0.00889/0.00383. Took 0.26 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.52/0.42, Loss(train/val) 0.00743/0.00529. Took 0.26 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.52/0.34, Loss(train/val) 0.00783/0.00381. Took 0.24 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.47/0.43, Loss(train/val) 0.00682/0.00543. Took 0.26 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.47/0.39, Loss(train/val) 0.00686/0.00479. Took 0.23 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.47/0.49, Loss(train/val) 0.00660/0.00675. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.49/0.31, Loss(train/val) 0.00713/0.00340. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.44/0.60, Loss(train/val) 0.00610/0.00955. Took 0.25 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_19\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.69/0.53, Loss(train/val) 0.11410/0.00917. Took 0.25 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.15/0.62, Loss(train/val) 0.04048/0.01277. Took 0.26 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Acc_RMSE(train/val): 1.13/0.55, Loss(train/val) 0.03805/0.00977. Took 0.25 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 1.08/0.31, Loss(train/val) 0.03428/0.00358. Took 0.25 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.98/0.56, Loss(train/val) 0.02745/0.00952. Took 0.26 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.88/0.34, Loss(train/val) 0.02055/0.00430. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.71/0.59, Loss(train/val) 0.01360/0.00954. Took 0.25 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.86/0.33, Loss(train/val) 0.01925/0.00378. Took 0.25 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.60/0.43, Loss(train/val) 0.01038/0.00546. Took 0.25 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.74/0.42, Loss(train/val) 0.01386/0.00522. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.78/0.37, Loss(train/val) 0.01583/0.00409. Took 0.25 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.65/0.39, Loss(train/val) 0.01194/0.00492. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.67/0.34, Loss(train/val) 0.01210/0.00387. Took 0.23 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.64/0.34, Loss(train/val) 0.01157/0.00371. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.65/0.34, Loss(train/val) 0.01144/0.00382. Took 0.25 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.61/0.42, Loss(train/val) 0.01054/0.00560. Took 0.26 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.56/0.34, Loss(train/val) 0.00954/0.00446. Took 0.26 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.56/0.39, Loss(train/val) 0.00933/0.00605. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.58/0.40, Loss(train/val) 0.00991/0.00670. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.56/0.39, Loss(train/val) 0.00904/0.00546. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.56/0.36, Loss(train/val) 0.00887/0.00414. Took 0.25 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.63/0.38, Loss(train/val) 0.01073/0.00440. Took 0.25 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.72/0.26, Loss(train/val) 0.01401/0.00240. Took 0.25 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.71/0.31, Loss(train/val) 0.01364/0.00366. Took 0.25 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.56/0.70, Loss(train/val) 0.01017/0.02002. Took 0.25 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.53/0.51, Loss(train/val) 0.00898/0.01182. Took 0.25 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.54/0.37, Loss(train/val) 0.00887/0.00578. Took 0.25 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.56/0.31, Loss(train/val) 0.00874/0.00359. Took 0.25 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.62/0.37, Loss(train/val) 0.01007/0.00487. Took 0.26 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.47/0.52, Loss(train/val) 0.00712/0.01133. Took 0.26 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.53/0.60, Loss(train/val) 0.00860/0.01475. Took 0.25 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.56/0.28, Loss(train/val) 0.00886/0.00284. Took 0.26 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.60/0.36, Loss(train/val) 0.00948/0.00461. Took 0.25 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.48/0.45, Loss(train/val) 0.00665/0.00722. Took 0.26 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.68/0.32, Loss(train/val) 0.01221/0.00343. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.61/0.34, Loss(train/val) 0.01021/0.00447. Took 0.25 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.63/0.80, Loss(train/val) 0.01075/0.02494. Took 0.26 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.59/1.01, Loss(train/val) 0.01144/0.04192. Took 0.25 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.65/0.63, Loss(train/val) 0.01210/0.01639. Took 0.26 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.66/0.36, Loss(train/val) 0.01182/0.00484. Took 0.25 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.62/0.72, Loss(train/val) 0.01033/0.02100. Took 0.26 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.65/0.73, Loss(train/val) 0.01161/0.02400. Took 0.26 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.62/0.66, Loss(train/val) 0.01147/0.01889. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.65/0.93, Loss(train/val) 0.01169/0.03715. Took 0.24 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.57/0.65, Loss(train/val) 0.01085/0.01701. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.65/0.48, Loss(train/val) 0.01342/0.00852. Took 0.25 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.65/0.48, Loss(train/val) 0.01272/0.00840. Took 0.25 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.73/0.50, Loss(train/val) 0.01405/0.00889. Took 0.26 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.76/0.51, Loss(train/val) 0.01541/0.01026. Took 0.26 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.76/0.48, Loss(train/val) 0.01572/0.00910. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.76/0.46, Loss(train/val) 0.01579/0.00831. Took 0.24 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.83/0.36, Loss(train/val) 0.01902/0.00475. Took 0.24 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.71/0.48, Loss(train/val) 0.01391/0.00773. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.99/0.54, Loss(train/val) 0.02937/0.01031. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.57/0.46, Loss(train/val) 0.01045/0.00789. Took 0.26 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.90/0.38, Loss(train/val) 0.01684/0.00418. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.88/0.33, Loss(train/val) 0.02128/0.00387. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.70/0.67, Loss(train/val) 0.01543/0.01235. Took 0.26 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.87/0.38, Loss(train/val) 0.02065/0.00488. Took 0.26 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.59/0.49, Loss(train/val) 0.01082/0.00621. Took 0.25 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.64/0.33, Loss(train/val) 0.01171/0.00360. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.53/0.41, Loss(train/val) 0.00895/0.00477. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.56/0.35, Loss(train/val) 0.00923/0.00397. Took 0.26 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.50/0.44, Loss(train/val) 0.00832/0.00529. Took 0.25 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.55/0.40, Loss(train/val) 0.00897/0.00472. Took 0.25 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_20\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.59/0.57, Loss(train/val) 0.09204/0.01071. Took 0.25 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.10/0.65, Loss(train/val) 0.03661/0.01378. Took 0.25 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.07/0.42, Loss(train/val) 0.03389/0.00561. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.86/0.74, Loss(train/val) 0.02214/0.01418. Took 0.25 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.90/0.35, Loss(train/val) 0.02186/0.00444. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.82/0.33, Loss(train/val) 0.01782/0.00355. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.72/0.42, Loss(train/val) 0.01393/0.00514. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.76/0.32, Loss(train/val) 0.01528/0.00394. Took 0.25 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.68/0.30, Loss(train/val) 0.01202/0.00317. Took 0.25 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.73/0.31, Loss(train/val) 0.01395/0.00358. Took 0.25 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.68/0.30, Loss(train/val) 0.01247/0.00328. Took 0.25 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.70/0.31, Loss(train/val) 0.01281/0.00348. Took 0.25 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.72/0.31, Loss(train/val) 0.01312/0.00354. Took 0.25 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.70/0.30, Loss(train/val) 0.01276/0.00307. Took 0.25 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.78/0.35, Loss(train/val) 0.01476/0.00413. Took 0.26 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.76/0.37, Loss(train/val) 0.01423/0.00501. Took 0.25 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.60/0.46, Loss(train/val) 0.01058/0.00765. Took 0.26 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.67/0.49, Loss(train/val) 0.01272/0.00896. Took 0.25 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.77/0.51, Loss(train/val) 0.01475/0.00905. Took 0.25 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.74/0.46, Loss(train/val) 0.01336/0.00728. Took 0.25 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.70/0.53, Loss(train/val) 0.01240/0.00970. Took 0.25 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.70/0.43, Loss(train/val) 0.01270/0.00714. Took 0.26 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.70/0.54, Loss(train/val) 0.01324/0.01148. Took 0.25 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.83/0.41, Loss(train/val) 0.01924/0.00571. Took 0.25 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.62/0.61, Loss(train/val) 0.01204/0.01276. Took 0.26 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.89/0.46, Loss(train/val) 0.02135/0.00772. Took 0.25 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.75/0.33, Loss(train/val) 0.01657/0.00332. Took 0.26 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.81/0.49, Loss(train/val) 0.01822/0.00636. Took 0.25 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Acc_RMSE(train/val): 0.73/0.48, Loss(train/val) 0.01492/0.00646. Took 0.25 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.67/0.38, Loss(train/val) 0.01253/0.00439. Took 0.25 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.68/0.50, Loss(train/val) 0.01260/0.00678. Took 0.25 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.67/0.44, Loss(train/val) 0.01226/0.00543. Took 0.26 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.63/0.41, Loss(train/val) 0.01093/0.00481. Took 0.25 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.61/0.38, Loss(train/val) 0.01039/0.00450. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.62/0.38, Loss(train/val) 0.01052/0.00440. Took 0.24 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.60/0.36, Loss(train/val) 0.00987/0.00393. Took 0.25 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.61/0.41, Loss(train/val) 0.01026/0.00487. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.64/0.34, Loss(train/val) 0.01079/0.00374. Took 0.25 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00919/0.00392. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00914/0.00364. Took 0.26 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.58/0.36, Loss(train/val) 0.00913/0.00410. Took 0.25 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.57/0.35, Loss(train/val) 0.00907/0.00396. Took 0.24 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.63/0.37, Loss(train/val) 0.01031/0.00434. Took 0.26 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.54/0.33, Loss(train/val) 0.00845/0.00358. Took 0.26 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.57/0.34, Loss(train/val) 0.00895/0.00383. Took 0.26 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.56/0.30, Loss(train/val) 0.00882/0.00318. Took 0.26 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.52/0.31, Loss(train/val) 0.00782/0.00341. Took 0.23 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.58/0.28, Loss(train/val) 0.00888/0.00271. Took 0.26 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.61/0.28, Loss(train/val) 0.00975/0.00277. Took 0.26 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.53/0.28, Loss(train/val) 0.00802/0.00285. Took 0.26 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.53/0.31, Loss(train/val) 0.00817/0.00386. Took 0.26 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.52/0.29, Loss(train/val) 0.00743/0.00322. Took 0.25 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.55/0.34, Loss(train/val) 0.00829/0.00420. Took 0.25 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.50/0.33, Loss(train/val) 0.00774/0.00403. Took 0.25 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.50/0.35, Loss(train/val) 0.00747/0.00389. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.50/0.35, Loss(train/val) 0.00780/0.00391. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.47/0.29, Loss(train/val) 0.00733/0.00281. Took 0.25 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.54/0.26, Loss(train/val) 0.00812/0.00249. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.63/0.27, Loss(train/val) 0.01039/0.00247. Took 0.26 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.55/0.48, Loss(train/val) 0.00897/0.00656. Took 0.25 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.64/0.31, Loss(train/val) 0.01083/0.00328. Took 0.26 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.52/0.42, Loss(train/val) 0.00751/0.00537. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.52/0.43, Loss(train/val) 0.00788/0.00562. Took 0.25 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.51/0.48, Loss(train/val) 0.00745/0.00678. Took 0.26 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.52/0.48, Loss(train/val) 0.00820/0.00678. Took 0.26 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_21\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.63/0.65, Loss(train/val) 0.08691/0.01388. Took 0.26 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.08/0.62, Loss(train/val) 0.03518/0.01249. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.91/0.64, Loss(train/val) 0.02352/0.01150. Took 0.25 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.93/0.38, Loss(train/val) 0.02301/0.00480. Took 0.25 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.74/0.31, Loss(train/val) 0.01475/0.00315. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.67/0.30, Loss(train/val) 0.01234/0.00326. Took 0.25 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.75/0.40, Loss(train/val) 0.01442/0.00543. Took 0.30 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.74/0.27, Loss(train/val) 0.01425/0.00254. Took 0.23 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.77/0.35, Loss(train/val) 0.01519/0.00424. Took 0.25 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.75/0.34, Loss(train/val) 0.01402/0.00386. Took 0.26 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.74/0.34, Loss(train/val) 0.01441/0.00420. Took 0.25 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.65/0.37, Loss(train/val) 0.01124/0.00503. Took 0.26 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.61/0.36, Loss(train/val) 0.01022/0.00494. Took 0.25 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.56/0.35, Loss(train/val) 0.00913/0.00472. Took 0.26 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.61/0.43, Loss(train/val) 0.01038/0.00794. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.53/0.44, Loss(train/val) 0.00848/0.00822. Took 0.26 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.64/0.53, Loss(train/val) 0.01153/0.01093. Took 0.26 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.50/0.40, Loss(train/val) 0.00806/0.00651. Took 0.26 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.81/0.40, Loss(train/val) 0.01681/0.00623. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.47/0.35, Loss(train/val) 0.00705/0.00495. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.66/0.48, Loss(train/val) 0.01151/0.00801. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.50/0.33, Loss(train/val) 0.00726/0.00411. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.61/0.66, Loss(train/val) 0.01069/0.01673. Took 0.25 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.54/0.39, Loss(train/val) 0.00909/0.00565. Took 0.25 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.73/0.60, Loss(train/val) 0.01429/0.01363. Took 0.25 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.52/0.36, Loss(train/val) 0.00788/0.00460. Took 0.25 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.70/0.78, Loss(train/val) 0.01369/0.02377. Took 0.25 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.67/0.35, Loss(train/val) 0.01231/0.00433. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.76/0.78, Loss(train/val) 0.01592/0.02500. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.61/0.37, Loss(train/val) 0.01133/0.00521. Took 0.25 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.63/0.68, Loss(train/val) 0.01171/0.01784. Took 0.24 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.69/0.40, Loss(train/val) 0.01433/0.00560. Took 0.25 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.78/0.25, Loss(train/val) 0.01433/0.00224. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.82/0.31, Loss(train/val) 0.01837/0.00339. Took 0.25 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.73/0.43, Loss(train/val) 0.01470/0.00511. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.78/0.53, Loss(train/val) 0.01683/0.00806. Took 0.26 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.70/0.51, Loss(train/val) 0.01443/0.00728. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.69/0.46, Loss(train/val) 0.01298/0.00572. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.65/0.48, Loss(train/val) 0.01180/0.00644. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.58/0.48, Loss(train/val) 0.01014/0.00619. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.59/0.35, Loss(train/val) 0.00993/0.00384. Took 0.26 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.53/0.44, Loss(train/val) 0.00843/0.00546. Took 0.25 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.56/0.38, Loss(train/val) 0.00922/0.00417. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.55/0.30, Loss(train/val) 0.00865/0.00288. Took 0.26 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.52/0.38, Loss(train/val) 0.00820/0.00421. Took 0.24 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.59/0.26, Loss(train/val) 0.00974/0.00240. Took 0.25 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.55/0.31, Loss(train/val) 0.00850/0.00306. Took 0.25 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.51/0.34, Loss(train/val) 0.00798/0.00347. Took 0.24 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.55/0.28, Loss(train/val) 0.00882/0.00267. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.51/0.29, Loss(train/val) 0.00763/0.00276. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.56/0.30, Loss(train/val) 0.00879/0.00336. Took 0.25 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.52/0.28, Loss(train/val) 0.00756/0.00259. Took 0.25 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.52/0.37, Loss(train/val) 0.00863/0.00406. Took 0.26 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.51/0.29, Loss(train/val) 0.00767/0.00299. Took 0.26 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Acc_RMSE(train/val): 0.51/0.33, Loss(train/val) 0.00776/0.00348. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.53/0.26, Loss(train/val) 0.00796/0.00250. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.53/0.27, Loss(train/val) 0.00791/0.00269. Took 0.26 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.46/0.34, Loss(train/val) 0.00630/0.00376. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.49/0.29, Loss(train/val) 0.00737/0.00323. Took 0.24 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.46/0.41, Loss(train/val) 0.00654/0.00512. Took 0.26 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.50/0.42, Loss(train/val) 0.00740/0.00521. Took 0.26 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.47/0.40, Loss(train/val) 0.00702/0.00490. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.44/0.38, Loss(train/val) 0.00636/0.00458. Took 0.26 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.45/0.43, Loss(train/val) 0.00654/0.00547. Took 0.25 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.47/0.47, Loss(train/val) 0.00722/0.00643. Took 0.24 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_22\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.46/0.70, Loss(train/val) 0.07127/0.01636. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.08/0.54, Loss(train/val) 0.03444/0.00925. Took 0.24 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.87/0.72, Loss(train/val) 0.02128/0.01288. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.82/0.33, Loss(train/val) 0.01760/0.00414. Took 0.26 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.79/0.40, Loss(train/val) 0.01599/0.00524. Took 0.25 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.80/0.27, Loss(train/val) 0.01739/0.00260. Took 0.26 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.63/0.36, Loss(train/val) 0.01116/0.00431. Took 0.25 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.68/0.40, Loss(train/val) 0.01225/0.00566. Took 0.24 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.70/0.36, Loss(train/val) 0.01282/0.00481. Took 0.24 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.66/0.40, Loss(train/val) 0.01181/0.00605. Took 0.23 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.70/0.42, Loss(train/val) 0.01256/0.00618. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.69/0.37, Loss(train/val) 0.01222/0.00494. Took 0.24 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.62/0.36, Loss(train/val) 0.01025/0.00485. Took 0.24 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.65/0.44, Loss(train/val) 0.01098/0.00754. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.60/0.34, Loss(train/val) 0.00999/0.00445. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.70/0.52, Loss(train/val) 0.01276/0.00999. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.57/0.32, Loss(train/val) 0.00921/0.00385. Took 0.25 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.71/0.58, Loss(train/val) 0.01341/0.01198. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.70/0.40, Loss(train/val) 0.01247/0.00525. Took 0.25 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.69/0.48, Loss(train/val) 0.01214/0.00849. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.72/0.58, Loss(train/val) 0.01473/0.01191. Took 0.24 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.69/0.52, Loss(train/val) 0.01376/0.00944. Took 0.25 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.68/0.54, Loss(train/val) 0.01319/0.01003. Took 0.24 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.72/0.31, Loss(train/val) 0.01479/0.00343. Took 0.25 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.79/0.34, Loss(train/val) 0.01734/0.00355. Took 0.25 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.77/0.45, Loss(train/val) 0.01639/0.00575. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.64/0.45, Loss(train/val) 0.01195/0.00581. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.67/0.45, Loss(train/val) 0.01244/0.00565. Took 0.25 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.63/0.41, Loss(train/val) 0.01121/0.00483. Took 0.24 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.63/0.45, Loss(train/val) 0.01124/0.00573. Took 0.26 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.62/0.34, Loss(train/val) 0.01112/0.00362. Took 0.25 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.59/0.38, Loss(train/val) 0.00985/0.00418. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.66/0.43, Loss(train/val) 0.01162/0.00519. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.63/0.31, Loss(train/val) 0.01068/0.00316. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.64/0.32, Loss(train/val) 0.01070/0.00363. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.62/0.38, Loss(train/val) 0.01023/0.00581. Took 0.24 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.57/0.32, Loss(train/val) 0.00919/0.00381. Took 0.24 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.55/0.42, Loss(train/val) 0.00900/0.00498. Took 0.25 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.62/0.46, Loss(train/val) 0.01060/0.00592. Took 0.25 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.62/0.42, Loss(train/val) 0.01052/0.00507. Took 0.25 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.61/0.46, Loss(train/val) 0.01041/0.00587. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.62/0.40, Loss(train/val) 0.01043/0.00466. Took 0.24 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.56/0.39, Loss(train/val) 0.00872/0.00460. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.55/0.41, Loss(train/val) 0.00867/0.00490. Took 0.25 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.56/0.42, Loss(train/val) 0.00876/0.00518. Took 0.26 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.55/0.36, Loss(train/val) 0.00855/0.00401. Took 0.26 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.52/0.37, Loss(train/val) 0.00774/0.00431. Took 0.25 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.55/0.37, Loss(train/val) 0.00809/0.00436. Took 0.25 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.50/0.36, Loss(train/val) 0.00711/0.00415. Took 0.28 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.49/0.36, Loss(train/val) 0.00708/0.00432. Took 0.26 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.47/0.42, Loss(train/val) 0.00637/0.00555. Took 0.27 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.48/0.38, Loss(train/val) 0.00658/0.00462. Took 0.27 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.46/0.34, Loss(train/val) 0.00646/0.00386. Took 0.26 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.44/0.33, Loss(train/val) 0.00589/0.00366. Took 0.26 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.44/0.39, Loss(train/val) 0.00615/0.00485. Took 0.24 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.45/0.31, Loss(train/val) 0.00590/0.00321. Took 0.27 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.43/0.37, Loss(train/val) 0.00592/0.00455. Took 0.28 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.43/0.43, Loss(train/val) 0.00547/0.00571. Took 0.29 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.42/0.36, Loss(train/val) 0.00560/0.00409. Took 0.28 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.44/0.32, Loss(train/val) 0.00658/0.00355. Took 0.23 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.43/0.43, Loss(train/val) 0.00566/0.00567. Took 0.24 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.46/0.29, Loss(train/val) 0.00637/0.00312. Took 0.23 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.43/0.43, Loss(train/val) 0.00567/0.00568. Took 0.24 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.47/0.32, Loss(train/val) 0.00639/0.00349. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.45/0.46, Loss(train/val) 0.00641/0.00646. Took 0.23 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_23\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=65, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.73/0.48, Loss(train/val) 0.09843/0.00773. Took 0.24 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.10/0.56, Loss(train/val) 0.03654/0.01023. Took 0.25 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 0.91/0.71, Loss(train/val) 0.02453/0.01481. Took 0.24 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.98/0.33, Loss(train/val) 0.02742/0.00419. Took 0.23 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 0.82/0.45, Loss(train/val) 0.01816/0.00649. Took 0.24 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.84/0.30, Loss(train/val) 0.01935/0.00331. Took 0.24 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.79/0.36, Loss(train/val) 0.01793/0.00394. Took 0.24 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.71/0.31, Loss(train/val) 0.01369/0.00362. Took 0.26 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.68/0.30, Loss(train/val) 0.01244/0.00338. Took 0.25 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.62/0.32, Loss(train/val) 0.01060/0.00377. Took 0.24 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.73/0.37, Loss(train/val) 0.01372/0.00471. Took 0.24 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.69/0.26, Loss(train/val) 0.01264/0.00242. Took 0.23 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.76/0.30, Loss(train/val) 0.01488/0.00306. Took 0.23 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Acc_RMSE(train/val): 0.75/0.29, Loss(train/val) 0.01426/0.00295. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.70/0.35, Loss(train/val) 0.01267/0.00432. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.61/0.32, Loss(train/val) 0.01062/0.00386. Took 0.24 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.59/0.45, Loss(train/val) 0.01022/0.00862. Took 0.24 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.64/0.56, Loss(train/val) 0.01154/0.01368. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.56/0.52, Loss(train/val) 0.00967/0.01122. Took 0.24 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.62/0.54, Loss(train/val) 0.01097/0.01061. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.48/0.41, Loss(train/val) 0.00722/0.00688. Took 0.25 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.71/0.48, Loss(train/val) 0.01291/0.00805. Took 0.24 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.51/0.47, Loss(train/val) 0.00810/0.00911. Took 0.24 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.56/0.65, Loss(train/val) 0.00935/0.01566. Took 0.24 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 0.55/0.58, Loss(train/val) 0.00885/0.01199. Took 0.24 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.67/0.51, Loss(train/val) 0.01170/0.00967. Took 0.24 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.60/0.32, Loss(train/val) 0.00993/0.00356. Took 0.25 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.74/0.49, Loss(train/val) 0.01392/0.00931. Took 0.27 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.66/0.74, Loss(train/val) 0.01072/0.02043. Took 0.25 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.76/0.55, Loss(train/val) 0.01674/0.01448. Took 0.25 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.74/0.48, Loss(train/val) 0.01492/0.01067. Took 0.25 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.60/0.41, Loss(train/val) 0.01003/0.00679. Took 0.26 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.64/0.74, Loss(train/val) 0.01119/0.02267. Took 0.26 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.57/0.70, Loss(train/val) 0.01025/0.01989. Took 0.27 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.60/0.36, Loss(train/val) 0.01068/0.00510. Took 0.27 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.70/0.63, Loss(train/val) 0.01349/0.01558. Took 0.33 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.58/0.55, Loss(train/val) 0.01015/0.01137. Took 0.30 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.59/0.49, Loss(train/val) 0.01045/0.00844. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.60/0.64, Loss(train/val) 0.01098/0.01419. Took 0.24 sec\n",
      "Epoch 39, Acc_RMSE(train/val): 0.60/0.45, Loss(train/val) 0.01099/0.00765. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 1.04/0.82, Loss(train/val) 0.02190/0.02382. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.72/0.32, Loss(train/val) 0.01428/0.00340. Took 0.28 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.58/0.61, Loss(train/val) 0.01055/0.01442. Took 0.24 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.73/0.41, Loss(train/val) 0.01613/0.00659. Took 0.26 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.78/0.31, Loss(train/val) 0.01791/0.00349. Took 0.26 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.84/0.41, Loss(train/val) 0.01919/0.00472. Took 0.26 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.79/0.52, Loss(train/val) 0.01717/0.00716. Took 0.25 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.78/0.61, Loss(train/val) 0.01676/0.00940. Took 0.26 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.73/0.52, Loss(train/val) 0.01450/0.00721. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.63/0.52, Loss(train/val) 0.01128/0.00713. Took 0.24 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.62/0.44, Loss(train/val) 0.01103/0.00538. Took 0.27 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.57/0.44, Loss(train/val) 0.00960/0.00531. Took 0.26 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.57/0.46, Loss(train/val) 0.00935/0.00578. Took 0.26 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.57/0.34, Loss(train/val) 0.00930/0.00352. Took 0.25 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.53/0.30, Loss(train/val) 0.00830/0.00290. Took 0.26 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.55/0.30, Loss(train/val) 0.00852/0.00304. Took 0.25 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.53/0.37, Loss(train/val) 0.00810/0.00414. Took 0.24 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.57/0.33, Loss(train/val) 0.00928/0.00350. Took 0.24 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.56/0.37, Loss(train/val) 0.00899/0.00407. Took 0.27 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.59/0.25, Loss(train/val) 0.00937/0.00236. Took 0.25 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.51/0.33, Loss(train/val) 0.00771/0.00341. Took 0.26 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.56/0.31, Loss(train/val) 0.00872/0.00325. Took 0.24 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.51/0.42, Loss(train/val) 0.00769/0.00534. Took 0.23 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.57/0.35, Loss(train/val) 0.00928/0.00390. Took 0.24 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.52/0.36, Loss(train/val) 0.00781/0.00405. Took 0.26 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "\n",
      " exp_24\n",
      "loseFunc = MSELoss, optim=Adam, x_frames=4, n_layers=2, batch_size=8, hid_dim=64, epoch=200, lr=0.01, l2=0.0001, dropout=0.1, use_bn=False\n",
      "Epoch 0, Acc_RMSE(train/val): 1.61/0.64, Loss(train/val) 0.10465/0.01363. Took 0.28 sec\n",
      "Epoch 1, Acc_RMSE(train/val): 1.15/0.65, Loss(train/val) 0.04000/0.01385. Took 0.27 sec\n",
      "Epoch 2, Acc_RMSE(train/val): 1.10/0.30, Loss(train/val) 0.03574/0.00298. Took 0.27 sec\n",
      "Epoch 3, Acc_RMSE(train/val): 0.98/0.67, Loss(train/val) 0.02699/0.01340. Took 0.27 sec\n",
      "Epoch 4, Acc_RMSE(train/val): 1.05/0.45, Loss(train/val) 0.03107/0.00759. Took 0.27 sec\n",
      "Epoch 5, Acc_RMSE(train/val): 0.72/0.48, Loss(train/val) 0.01427/0.00654. Took 0.26 sec\n",
      "Epoch 6, Acc_RMSE(train/val): 0.74/0.38, Loss(train/val) 0.01504/0.00504. Took 0.26 sec\n",
      "Epoch 7, Acc_RMSE(train/val): 0.84/0.40, Loss(train/val) 0.01863/0.00493. Took 0.25 sec\n",
      "Epoch 8, Acc_RMSE(train/val): 0.81/0.33, Loss(train/val) 0.01810/0.00409. Took 0.26 sec\n",
      "Epoch 9, Acc_RMSE(train/val): 0.65/0.37, Loss(train/val) 0.01128/0.00477. Took 0.25 sec\n",
      "Epoch 10, Acc_RMSE(train/val): 0.59/0.39, Loss(train/val) 0.00973/0.00529. Took 0.26 sec\n",
      "Epoch 11, Acc_RMSE(train/val): 0.71/0.35, Loss(train/val) 0.01340/0.00374. Took 0.27 sec\n",
      "Epoch 12, Acc_RMSE(train/val): 0.72/0.36, Loss(train/val) 0.01482/0.00460. Took 0.26 sec\n",
      "Epoch 13, Acc_RMSE(train/val): 0.59/0.49, Loss(train/val) 0.01009/0.00750. Took 0.24 sec\n",
      "Epoch 14, Acc_RMSE(train/val): 0.67/0.37, Loss(train/val) 0.01179/0.00438. Took 0.24 sec\n",
      "Epoch 15, Acc_RMSE(train/val): 0.69/0.32, Loss(train/val) 0.01272/0.00388. Took 0.25 sec\n",
      "Epoch 16, Acc_RMSE(train/val): 0.60/0.39, Loss(train/val) 0.01026/0.00583. Took 0.25 sec\n",
      "Epoch 17, Acc_RMSE(train/val): 0.59/0.34, Loss(train/val) 0.00974/0.00455. Took 0.24 sec\n",
      "Epoch 18, Acc_RMSE(train/val): 0.57/0.37, Loss(train/val) 0.00932/0.00561. Took 0.25 sec\n",
      "Epoch 19, Acc_RMSE(train/val): 0.53/0.41, Loss(train/val) 0.00818/0.00711. Took 0.24 sec\n",
      "Epoch 20, Acc_RMSE(train/val): 0.51/0.48, Loss(train/val) 0.00816/0.01033. Took 0.26 sec\n",
      "Epoch 21, Acc_RMSE(train/val): 0.52/0.43, Loss(train/val) 0.00799/0.00636. Took 0.26 sec\n",
      "Epoch 22, Acc_RMSE(train/val): 0.83/0.36, Loss(train/val) 0.01725/0.00465. Took 0.24 sec\n",
      "Epoch 23, Acc_RMSE(train/val): 0.97/0.31, Loss(train/val) 0.02336/0.00335. Took 0.28 sec\n",
      "Epoch 24, Acc_RMSE(train/val): 1.03/0.68, Loss(train/val) 0.02483/0.01605. Took 0.27 sec\n",
      "Epoch 25, Acc_RMSE(train/val): 0.72/0.60, Loss(train/val) 0.01490/0.01514. Took 0.25 sec\n",
      "Epoch 26, Acc_RMSE(train/val): 0.74/0.68, Loss(train/val) 0.01584/0.01785. Took 0.24 sec\n",
      "Epoch 27, Acc_RMSE(train/val): 0.75/0.50, Loss(train/val) 0.01518/0.00895. Took 0.24 sec\n",
      "Epoch 28, Acc_RMSE(train/val): 0.68/0.63, Loss(train/val) 0.01279/0.01488. Took 0.26 sec\n",
      "Epoch 29, Acc_RMSE(train/val): 0.78/0.50, Loss(train/val) 0.01674/0.00955. Took 0.25 sec\n",
      "Epoch 30, Acc_RMSE(train/val): 0.74/0.51, Loss(train/val) 0.01615/0.00938. Took 0.23 sec\n",
      "Epoch 31, Acc_RMSE(train/val): 0.87/0.34, Loss(train/val) 0.02137/0.00447. Took 0.24 sec\n",
      "Epoch 32, Acc_RMSE(train/val): 0.83/0.36, Loss(train/val) 0.01905/0.00414. Took 0.24 sec\n",
      "Epoch 33, Acc_RMSE(train/val): 0.85/0.41, Loss(train/val) 0.02020/0.00461. Took 0.24 sec\n",
      "Epoch 34, Acc_RMSE(train/val): 0.79/0.44, Loss(train/val) 0.01749/0.00538. Took 0.25 sec\n",
      "Epoch 35, Acc_RMSE(train/val): 0.77/0.34, Loss(train/val) 0.01647/0.00356. Took 0.27 sec\n",
      "Epoch 36, Acc_RMSE(train/val): 0.91/0.36, Loss(train/val) 0.02406/0.00467. Took 0.27 sec\n",
      "Epoch 37, Acc_RMSE(train/val): 0.61/0.31, Loss(train/val) 0.01058/0.00356. Took 0.24 sec\n",
      "Epoch 38, Acc_RMSE(train/val): 0.54/0.30, Loss(train/val) 0.00864/0.00336. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Acc_RMSE(train/val): 0.68/0.28, Loss(train/val) 0.01267/0.00296. Took 0.24 sec\n",
      "Epoch 40, Acc_RMSE(train/val): 0.73/0.37, Loss(train/val) 0.01399/0.00419. Took 0.24 sec\n",
      "Epoch 41, Acc_RMSE(train/val): 0.72/0.42, Loss(train/val) 0.01492/0.00509. Took 0.26 sec\n",
      "Epoch 42, Acc_RMSE(train/val): 0.65/0.50, Loss(train/val) 0.01244/0.00692. Took 0.25 sec\n",
      "Epoch 43, Acc_RMSE(train/val): 0.66/0.48, Loss(train/val) 0.01256/0.00634. Took 0.23 sec\n",
      "Epoch 44, Acc_RMSE(train/val): 0.62/0.49, Loss(train/val) 0.01110/0.00652. Took 0.26 sec\n",
      "Epoch 45, Acc_RMSE(train/val): 0.61/0.47, Loss(train/val) 0.01064/0.00591. Took 0.24 sec\n",
      "Epoch 46, Acc_RMSE(train/val): 0.57/0.47, Loss(train/val) 0.00962/0.00607. Took 0.26 sec\n",
      "Epoch 47, Acc_RMSE(train/val): 0.59/0.40, Loss(train/val) 0.00985/0.00455. Took 0.26 sec\n",
      "Epoch 48, Acc_RMSE(train/val): 0.54/0.46, Loss(train/val) 0.00858/0.00574. Took 0.25 sec\n",
      "Epoch 49, Acc_RMSE(train/val): 0.56/0.45, Loss(train/val) 0.00912/0.00552. Took 0.25 sec\n",
      "Epoch 50, Acc_RMSE(train/val): 0.53/0.36, Loss(train/val) 0.00846/0.00376. Took 0.26 sec\n",
      "Epoch 51, Acc_RMSE(train/val): 0.50/0.38, Loss(train/val) 0.00754/0.00414. Took 0.26 sec\n",
      "Epoch 52, Acc_RMSE(train/val): 0.51/0.36, Loss(train/val) 0.00785/0.00387. Took 0.24 sec\n",
      "Epoch 53, Acc_RMSE(train/val): 0.53/0.31, Loss(train/val) 0.00789/0.00306. Took 0.24 sec\n",
      "Epoch 54, Acc_RMSE(train/val): 0.46/0.31, Loss(train/val) 0.00681/0.00307. Took 0.25 sec\n",
      "Epoch 55, Acc_RMSE(train/val): 0.49/0.28, Loss(train/val) 0.00710/0.00258. Took 0.24 sec\n",
      "Epoch 56, Acc_RMSE(train/val): 0.47/0.29, Loss(train/val) 0.00689/0.00278. Took 0.26 sec\n",
      "Epoch 57, Acc_RMSE(train/val): 0.48/0.26, Loss(train/val) 0.00687/0.00230. Took 0.25 sec\n",
      "Epoch 58, Acc_RMSE(train/val): 0.48/0.30, Loss(train/val) 0.00674/0.00319. Took 0.25 sec\n",
      "Epoch 59, Acc_RMSE(train/val): 0.47/0.28, Loss(train/val) 0.00648/0.00286. Took 0.26 sec\n",
      "Epoch 60, Acc_RMSE(train/val): 0.48/0.27, Loss(train/val) 0.00674/0.00259. Took 0.25 sec\n",
      "Epoch 61, Acc_RMSE(train/val): 0.46/0.27, Loss(train/val) 0.00640/0.00261. Took 0.25 sec\n",
      "Epoch 62, Acc_RMSE(train/val): 0.46/0.26, Loss(train/val) 0.00636/0.00246. Took 0.25 sec\n",
      "Epoch 63, Acc_RMSE(train/val): 0.46/0.27, Loss(train/val) 0.00634/0.00265. Took 0.25 sec\n",
      "Epoch 64, Acc_RMSE(train/val): 0.44/0.27, Loss(train/val) 0.00589/0.00271. Took 0.26 sec\n",
      "Epoch 65, Acc_RMSE(train/val): 0.45/0.29, Loss(train/val) 0.00611/0.00320. Took 0.25 sec\n",
      "Epoch 66, Acc_RMSE(train/val): 0.42/0.27, Loss(train/val) 0.00567/0.00267. Took 0.24 sec\n",
      "Epoch 67, Acc_RMSE(train/val): 0.45/0.27, Loss(train/val) 0.00604/0.00267. Took 0.24 sec\n",
      "Epoch 68, Acc_RMSE(train/val): 0.44/0.26, Loss(train/val) 0.00580/0.00233. Took 0.24 sec\n",
      "Epoch 69, Acc_RMSE(train/val): 0.44/0.27, Loss(train/val) 0.00593/0.00257. Took 0.25 sec\n",
      "Epoch 70, Acc_RMSE(train/val): 0.44/0.31, Loss(train/val) 0.00608/0.00363. Took 0.25 sec\n",
      "Epoch 71, Acc_RMSE(train/val): 0.48/0.29, Loss(train/val) 0.00641/0.00310. Took 0.24 sec\n",
      "Epoch 72, Acc_RMSE(train/val): 0.43/0.27, Loss(train/val) 0.00574/0.00266. Took 0.25 sec\n",
      "Epoch 73, Acc_RMSE(train/val): 0.43/0.29, Loss(train/val) 0.00569/0.00288. Took 0.24 sec\n",
      "Epoch 74, Acc_RMSE(train/val): 0.43/0.29, Loss(train/val) 0.00581/0.00282. Took 0.24 sec\n",
      "Epoch 75, Acc_RMSE(train/val): 0.42/0.34, Loss(train/val) 0.00537/0.00360. Took 0.24 sec\n",
      "Epoch 76, Acc_RMSE(train/val): 0.44/0.30, Loss(train/val) 0.00616/0.00334. Took 0.24 sec\n",
      "Epoch 77, Acc_RMSE(train/val): 0.46/0.30, Loss(train/val) 0.00609/0.00292. Took 0.24 sec\n",
      "Epoch 78, Acc_RMSE(train/val): 0.51/0.43, Loss(train/val) 0.00783/0.00552. Took 0.24 sec\n",
      "Epoch 79, Acc_RMSE(train/val): 0.51/0.39, Loss(train/val) 0.00780/0.00487. Took 0.24 sec\n",
      "Epoch 80, Acc_RMSE(train/val): 0.46/0.40, Loss(train/val) 0.00671/0.00460. Took 0.23 sec\n",
      "Epoch 81, Acc_RMSE(train/val): 0.54/0.48, Loss(train/val) 0.00795/0.00684. Took 0.24 sec\n",
      "Epoch 82, Acc_RMSE(train/val): 0.46/0.30, Loss(train/val) 0.00659/0.00312. Took 0.25 sec\n",
      "Epoch 83, Acc_RMSE(train/val): 0.44/0.53, Loss(train/val) 0.00610/0.00755. Took 0.24 sec\n",
      "Epoch 84, Acc_RMSE(train/val): 0.47/0.37, Loss(train/val) 0.00683/0.00432. Took 0.24 sec\n",
      "Epoch 85, Acc_RMSE(train/val): 0.43/0.50, Loss(train/val) 0.00597/0.00718. Took 0.24 sec\n",
      "Epoch 86, Acc_RMSE(train/val): 0.43/0.43, Loss(train/val) 0.00570/0.00547. Took 0.25 sec\n",
      "Epoch 87, Acc_RMSE(train/val): 0.46/0.37, Loss(train/val) 0.00688/0.00424. Took 0.26 sec\n",
      "Epoch 88, Acc_RMSE(train/val): 0.42/0.64, Loss(train/val) 0.00546/0.01060. Took 0.25 sec\n",
      "Epoch 89, Acc_RMSE(train/val): 0.44/0.27, Loss(train/val) 0.00592/0.00276. Took 0.25 sec\n",
      "Epoch 90, Acc_RMSE(train/val): 0.46/0.67, Loss(train/val) 0.00620/0.01111. Took 0.30 sec\n",
      "Epoch 91, Acc_RMSE(train/val): 0.47/0.63, Loss(train/val) 0.00616/0.01047. Took 0.25 sec\n",
      "Epoch 92, Acc_RMSE(train/val): 0.46/0.63, Loss(train/val) 0.00620/0.01036. Took 0.24 sec\n",
      "Epoch 93, Acc_RMSE(train/val): 0.42/0.68, Loss(train/val) 0.00521/0.01193. Took 0.25 sec\n",
      "Epoch 94, Acc_RMSE(train/val): 0.44/0.74, Loss(train/val) 0.00570/0.01390. Took 0.25 sec\n",
      "Epoch 95, Acc_RMSE(train/val): 0.40/0.56, Loss(train/val) 0.00501/0.00830. Took 0.24 sec\n",
      "Epoch 96, Acc_RMSE(train/val): 0.42/0.96, Loss(train/val) 0.00554/0.02139. Took 0.24 sec\n",
      "Epoch 97, Acc_RMSE(train/val): 0.51/0.75, Loss(train/val) 0.00782/0.01453. Took 0.25 sec\n",
      "Epoch 98, Acc_RMSE(train/val): 0.40/0.71, Loss(train/val) 0.00495/0.01269. Took 0.26 sec\n",
      "Epoch 99, Acc_RMSE(train/val): 0.43/0.80, Loss(train/val) 0.00547/0.01573. Took 0.30 sec\n",
      "Epoch 100, Acc_RMSE(train/val): 0.43/0.97, Loss(train/val) 0.00565/0.02185. Took 0.28 sec\n",
      "Epoch 101, Acc_RMSE(train/val): 0.43/0.94, Loss(train/val) 0.00564/0.02077. Took 0.25 sec\n",
      "Epoch 102, Acc_RMSE(train/val): 0.44/0.99, Loss(train/val) 0.00574/0.02237. Took 0.25 sec\n",
      "Epoch 103, Acc_RMSE(train/val): 0.45/0.87, Loss(train/val) 0.00614/0.01811. Took 0.25 sec\n",
      "Epoch 104, Acc_RMSE(train/val): 0.46/0.77, Loss(train/val) 0.00574/0.01483. Took 0.25 sec\n",
      "Epoch 105, Acc_RMSE(train/val): 0.50/0.75, Loss(train/val) 0.00662/0.01418. Took 0.26 sec\n",
      "Epoch 106, Acc_RMSE(train/val): 0.47/0.63, Loss(train/val) 0.00611/0.01034. Took 0.26 sec\n",
      "Epoch 107, Acc_RMSE(train/val): 0.53/0.72, Loss(train/val) 0.00733/0.01316. Took 0.24 sec\n",
      "Epoch 108, Acc_RMSE(train/val): 0.50/0.68, Loss(train/val) 0.00677/0.01198. Took 0.27 sec\n",
      "Epoch 109, Acc_RMSE(train/val): 0.53/0.54, Loss(train/val) 0.00773/0.00833. Took 0.25 sec\n",
      "Epoch 110, Acc_RMSE(train/val): 0.50/0.67, Loss(train/val) 0.00732/0.01156. Took 0.27 sec\n",
      "Epoch 111, Acc_RMSE(train/val): 0.49/0.57, Loss(train/val) 0.00674/0.00873. Took 0.27 sec\n",
      "Epoch 112, Acc_RMSE(train/val): 0.52/0.62, Loss(train/val) 0.00732/0.01041. Took 0.26 sec\n",
      "Epoch 113, Acc_RMSE(train/val): 0.50/0.63, Loss(train/val) 0.00661/0.01062. Took 0.26 sec\n",
      "Epoch 114, Acc_RMSE(train/val): 0.51/0.58, Loss(train/val) 0.00747/0.00911. Took 0.27 sec\n",
      "Epoch 115, Acc_RMSE(train/val): 0.51/0.64, Loss(train/val) 0.00731/0.01076. Took 0.24 sec\n",
      "Epoch 116, Acc_RMSE(train/val): 0.53/0.38, Loss(train/val) 0.00769/0.00449. Took 0.25 sec\n",
      "Epoch 117, Acc_RMSE(train/val): 0.50/0.90, Loss(train/val) 0.00741/0.01893. Took 0.25 sec\n",
      "Epoch 118, Acc_RMSE(train/val): 0.48/0.78, Loss(train/val) 0.00657/0.01476. Took 0.26 sec\n",
      "Epoch 119, Acc_RMSE(train/val): 0.51/0.62, Loss(train/val) 0.00673/0.00992. Took 0.24 sec\n",
      "Epoch 120, Acc_RMSE(train/val): 0.53/0.32, Loss(train/val) 0.00745/0.00343. Took 0.24 sec\n",
      "Epoch 121, Acc_RMSE(train/val): 0.56/0.57, Loss(train/val) 0.00902/0.00870. Took 0.24 sec\n",
      "Epoch 122, Acc_RMSE(train/val): 0.64/0.72, Loss(train/val) 0.01156/0.01322. Took 0.25 sec\n",
      "Epoch 123, Acc_RMSE(train/val): 0.52/0.70, Loss(train/val) 0.00775/0.01236. Took 0.25 sec\n",
      "Epoch 124, Acc_RMSE(train/val): 0.51/0.57, Loss(train/val) 0.00748/0.00883. Took 0.25 sec\n",
      "Epoch 125, Acc_RMSE(train/val): 0.47/0.54, Loss(train/val) 0.00629/0.00808. Took 0.25 sec\n",
      "Epoch 126, Acc_RMSE(train/val): 0.49/0.38, Loss(train/val) 0.00675/0.00442. Took 0.25 sec\n",
      "Epoch 127, Acc_RMSE(train/val): 0.59/0.35, Loss(train/val) 0.00918/0.00396. Took 0.26 sec\n",
      "Epoch 128, Acc_RMSE(train/val): 0.59/0.48, Loss(train/val) 0.00936/0.00655. Took 0.27 sec\n",
      "Epoch 129, Acc_RMSE(train/val): 0.57/0.52, Loss(train/val) 0.00859/0.00762. Took 0.25 sec\n",
      "Epoch 130, Acc_RMSE(train/val): 0.53/0.47, Loss(train/val) 0.00788/0.00662. Took 0.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131, Acc_RMSE(train/val): 0.51/0.42, Loss(train/val) 0.00770/0.00591. Took 0.26 sec\n",
      "Epoch 132, Acc_RMSE(train/val): 0.50/0.41, Loss(train/val) 0.00762/0.00557. Took 0.26 sec\n",
      "Epoch 133, Acc_RMSE(train/val): 0.52/0.29, Loss(train/val) 0.00746/0.00311. Took 0.24 sec\n",
      "Epoch 134, Acc_RMSE(train/val): 0.59/0.28, Loss(train/val) 0.00878/0.00271. Took 0.25 sec\n",
      "Epoch 135, Acc_RMSE(train/val): 0.68/0.27, Loss(train/val) 0.01143/0.00253. Took 0.25 sec\n",
      "Epoch 136, Acc_RMSE(train/val): 0.80/0.30, Loss(train/val) 0.01493/0.00302. Took 0.26 sec\n",
      "Epoch 137, Acc_RMSE(train/val): 0.77/0.29, Loss(train/val) 0.01383/0.00280. Took 0.25 sec\n",
      "Epoch 138, Acc_RMSE(train/val): 0.68/0.35, Loss(train/val) 0.01196/0.00476. Took 0.25 sec\n",
      "Epoch 139, Acc_RMSE(train/val): 0.59/0.40, Loss(train/val) 0.00981/0.00596. Took 0.26 sec\n",
      "Epoch 140, Acc_RMSE(train/val): 0.66/0.43, Loss(train/val) 0.01265/0.00701. Took 0.26 sec\n",
      "Epoch 141, Acc_RMSE(train/val): 0.69/0.45, Loss(train/val) 0.01394/0.00817. Took 0.25 sec\n",
      "Epoch 142, Acc_RMSE(train/val): 0.68/0.33, Loss(train/val) 0.01335/0.00398. Took 0.24 sec\n",
      "Epoch 143, Acc_RMSE(train/val): 0.62/0.30, Loss(train/val) 0.01078/0.00329. Took 0.25 sec\n",
      "Epoch 144, Acc_RMSE(train/val): 0.59/0.30, Loss(train/val) 0.00999/0.00330. Took 0.25 sec\n",
      "Epoch 145, Acc_RMSE(train/val): 0.54/0.35, Loss(train/val) 0.00872/0.00452. Took 0.25 sec\n",
      "Epoch 146, Acc_RMSE(train/val): 0.55/0.27, Loss(train/val) 0.00892/0.00275. Took 0.27 sec\n",
      "Epoch 147, Acc_RMSE(train/val): 0.51/0.28, Loss(train/val) 0.00742/0.00295. Took 0.26 sec\n",
      "Epoch 148, Acc_RMSE(train/val): 0.52/0.26, Loss(train/val) 0.00752/0.00253. Took 0.26 sec\n",
      "Epoch 149, Acc_RMSE(train/val): 0.49/0.27, Loss(train/val) 0.00695/0.00264. Took 0.26 sec\n",
      "Epoch 150, Acc_RMSE(train/val): 0.48/0.29, Loss(train/val) 0.00647/0.00320. Took 0.26 sec\n",
      "Epoch 151, Acc_RMSE(train/val): 0.47/0.31, Loss(train/val) 0.00649/0.00361. Took 0.27 sec\n",
      "Epoch 152, Acc_RMSE(train/val): 0.44/0.33, Loss(train/val) 0.00553/0.00420. Took 0.25 sec\n",
      "Epoch 153, Acc_RMSE(train/val): 0.47/0.38, Loss(train/val) 0.00616/0.00544. Took 0.26 sec\n",
      "Epoch 154, Acc_RMSE(train/val): 0.46/0.34, Loss(train/val) 0.00603/0.00423. Took 0.26 sec\n",
      "Epoch 155, Acc_RMSE(train/val): 0.48/0.48, Loss(train/val) 0.00609/0.00883. Took 0.25 sec\n",
      "Epoch 156, Acc_RMSE(train/val): 0.46/0.32, Loss(train/val) 0.00645/0.00355. Took 0.26 sec\n",
      "Epoch 157, Acc_RMSE(train/val): 0.47/0.49, Loss(train/val) 0.00603/0.00903. Took 0.26 sec\n",
      "Epoch 158, Acc_RMSE(train/val): 0.43/0.33, Loss(train/val) 0.00553/0.00404. Took 0.27 sec\n",
      "Epoch 159, Acc_RMSE(train/val): 0.45/0.44, Loss(train/val) 0.00537/0.00761. Took 0.27 sec\n",
      "Epoch 160, Acc_RMSE(train/val): 0.46/0.33, Loss(train/val) 0.00577/0.00397. Took 0.25 sec\n",
      "Epoch 161, Acc_RMSE(train/val): 0.46/0.33, Loss(train/val) 0.00572/0.00409. Took 0.30 sec\n",
      "Epoch 162, Acc_RMSE(train/val): 0.42/0.46, Loss(train/val) 0.00512/0.00834. Took 0.28 sec\n",
      "Epoch 163, Acc_RMSE(train/val): 0.42/0.32, Loss(train/val) 0.00503/0.00394. Took 0.27 sec\n",
      "Epoch 164, Acc_RMSE(train/val): 0.39/0.39, Loss(train/val) 0.00442/0.00574. Took 0.25 sec\n",
      "Epoch 165, Acc_RMSE(train/val): 0.41/0.36, Loss(train/val) 0.00498/0.00500. Took 0.24 sec\n",
      "Epoch 166, Acc_RMSE(train/val): 0.40/0.34, Loss(train/val) 0.00460/0.00448. Took 0.25 sec\n",
      "Epoch 167, Acc_RMSE(train/val): 0.40/0.42, Loss(train/val) 0.00465/0.00701. Took 0.24 sec\n",
      "Epoch 168, Acc_RMSE(train/val): 0.41/0.36, Loss(train/val) 0.00469/0.00494. Took 0.26 sec\n",
      "Epoch 169, Acc_RMSE(train/val): 0.45/0.32, Loss(train/val) 0.00602/0.00368. Took 0.26 sec\n",
      "Epoch 170, Acc_RMSE(train/val): 0.61/0.32, Loss(train/val) 0.00983/0.00338. Took 0.25 sec\n",
      "Epoch 171, Acc_RMSE(train/val): 0.47/0.69, Loss(train/val) 0.00725/0.01823. Took 0.26 sec\n",
      "Epoch 172, Acc_RMSE(train/val): 0.44/0.44, Loss(train/val) 0.00659/0.00752. Took 0.24 sec\n",
      "Epoch 173, Acc_RMSE(train/val): 0.46/0.36, Loss(train/val) 0.00602/0.00477. Took 0.27 sec\n",
      "Epoch 174, Acc_RMSE(train/val): 0.42/0.43, Loss(train/val) 0.00546/0.00697. Took 0.24 sec\n",
      "Epoch 175, Acc_RMSE(train/val): 0.40/0.31, Loss(train/val) 0.00539/0.00326. Took 0.26 sec\n",
      "Epoch 176, Acc_RMSE(train/val): 0.44/0.46, Loss(train/val) 0.00625/0.00826. Took 0.27 sec\n",
      "Epoch 177, Acc_RMSE(train/val): 0.48/0.35, Loss(train/val) 0.00699/0.00383. Took 0.27 sec\n",
      "Epoch 178, Acc_RMSE(train/val): 0.43/0.33, Loss(train/val) 0.00589/0.00416. Took 0.28 sec\n",
      "Epoch 179, Acc_RMSE(train/val): 0.43/0.32, Loss(train/val) 0.00548/0.00344. Took 0.27 sec\n",
      "Epoch 180, Acc_RMSE(train/val): 0.59/0.37, Loss(train/val) 0.00956/0.00489. Took 0.28 sec\n",
      "Epoch 181, Acc_RMSE(train/val): 0.52/0.32, Loss(train/val) 0.00815/0.00328. Took 0.26 sec\n",
      "Epoch 182, Acc_RMSE(train/val): 0.53/0.56, Loss(train/val) 0.00732/0.01182. Took 0.27 sec\n",
      "Epoch 183, Acc_RMSE(train/val): 0.52/0.29, Loss(train/val) 0.00761/0.00278. Took 0.24 sec\n",
      "Epoch 184, Acc_RMSE(train/val): 0.49/0.30, Loss(train/val) 0.00660/0.00310. Took 0.27 sec\n",
      "Epoch 185, Acc_RMSE(train/val): 0.53/0.27, Loss(train/val) 0.00668/0.00268. Took 0.26 sec\n",
      "Epoch 186, Acc_RMSE(train/val): 0.53/0.41, Loss(train/val) 0.00697/0.00583. Took 0.27 sec\n",
      "Epoch 187, Acc_RMSE(train/val): 0.53/0.46, Loss(train/val) 0.00643/0.00735. Took 0.25 sec\n",
      "Epoch 188, Acc_RMSE(train/val): 0.51/0.30, Loss(train/val) 0.00637/0.00308. Took 0.26 sec\n",
      "Epoch 189, Acc_RMSE(train/val): 0.48/0.30, Loss(train/val) 0.00607/0.00319. Took 0.25 sec\n",
      "Epoch 190, Acc_RMSE(train/val): 0.47/0.33, Loss(train/val) 0.00585/0.00379. Took 0.25 sec\n",
      "Epoch 191, Acc_RMSE(train/val): 0.43/0.33, Loss(train/val) 0.00525/0.00387. Took 0.25 sec\n",
      "Epoch 192, Acc_RMSE(train/val): 0.42/0.33, Loss(train/val) 0.00513/0.00380. Took 0.25 sec\n",
      "Epoch 193, Acc_RMSE(train/val): 0.44/0.34, Loss(train/val) 0.00586/0.00379. Took 0.26 sec\n",
      "Epoch 194, Acc_RMSE(train/val): 0.41/0.35, Loss(train/val) 0.00523/0.00386. Took 0.25 sec\n",
      "Epoch 195, Acc_RMSE(train/val): 0.39/0.31, Loss(train/val) 0.00471/0.00327. Took 0.25 sec\n",
      "Epoch 196, Acc_RMSE(train/val): 0.40/0.31, Loss(train/val) 0.00480/0.00325. Took 0.26 sec\n",
      "Epoch 197, Acc_RMSE(train/val): 0.42/0.40, Loss(train/val) 0.00531/0.00478. Took 0.26 sec\n",
      "Epoch 198, Acc_RMSE(train/val): 0.43/0.46, Loss(train/val) 0.00605/0.00631. Took 0.24 sec\n",
      "Epoch 199, Acc_RMSE(train/val): 0.41/0.29, Loss(train/val) 0.00515/0.00320. Took 0.26 sec\n",
      "start\n",
      "end\n",
      "start\n",
      "end\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print('##### Start #####')\n",
    "\n",
    "num = 0 #초기화\n",
    "\n",
    "for var1 in list_var1:\n",
    "    for var2 in list_var2:\n",
    "        for var3 in list_var3:\n",
    "            for var4 in list_var4:\n",
    "                for var5 in list_var5:\n",
    "                    for var6 in list_var6:\n",
    "                        for var7 in list_var7:\n",
    "                            for var8 in list_var8:\n",
    "                                for var9 in list_var9:\n",
    "                                    for var10 in list_var10:\n",
    "                                        for var11 in list_var11:\n",
    "                                            ts = time.time()\n",
    "                                            num += 1\n",
    "                                            setattr(args, name_var1, var1)\n",
    "                                            setattr(args, name_var2, var2)\n",
    "                                            setattr(args, name_var3, var3)\n",
    "                                            setattr(args, name_var4, var4)\n",
    "                                            setattr(args, name_var5, var5)\n",
    "                                            setattr(args, name_var6, var6)\n",
    "                                            setattr(args, name_var7, var7)\n",
    "                                            setattr(args, name_var8, var8)\n",
    "                                            setattr(args, name_var9, var9)\n",
    "                                            setattr(args, name_var10, var10)\n",
    "                                            setattr(args, name_var11, var11)\n",
    "                                            print('\\n exp_{}'.format(num))\n",
    "                                            print('loseFunc = {}, optim={}, x_frames={}, n_layers={}, batch_size={}, hid_dim={}, epoch={}, lr={}, l2={}, dropout={}, use_bn={}'\n",
    "                                                  .format(args.loss,args.optim,args.x_frames,args.n_layers,args.batch_size,args.hid_dim,args.epoch,args.lr,args.l2,args.dropout,args.use_bn))     \n",
    "\n",
    "                                            result = experiment(partition, deepcopy(args))\n",
    "\n",
    "                                    #         print('train_acc_RMSE = {:2.2f}%, val_acc_RMSE = {:2.2f}%, test_RMSE = {:2.2f}%, test_R2 = {:2.2f}%'\n",
    "                                    #               .format(result['train_acc_RMSE'],result['val_acc_RMSE'],result['test_RMSE'],result['test_R2']))\n",
    "\n",
    "                                            vis.text('loseFunc = {}, optim={}, x_frames={}, n_layers={}, batch_size={}, hid_dim={}, epoch={}, lr={}, l2={}, dropout={}, use_bn={}'\n",
    "                                                     .format(args.loss,args.optim,args.x_frames,args.n_layers,args.batch_size,args.hid_dim,args.epoch,args.lr,args.l2,args.dropout,args.use_bn),\n",
    "                                                     opts=dict(title='exp_{}_text'.format(num)))\n",
    "                                            # 만든 모델의 test 데이터 예측 시각화\n",
    "\n",
    "                                            predict = torch.Tensor(result['test_pred']).view(-1,1)\n",
    "                                            truth = torch.Tensor(result['test_true']).view(-1,1)\n",
    "                                            axis = torch.Tensor(range(len(result['test_pred']))).view(-1,1)\n",
    "\n",
    "                                            Y_axis = torch.cat((predict, truth), -1)\n",
    "                                            X_axis = torch.cat((axis, axis), -1)\n",
    "\n",
    "                                            vis.line(Y = Y_axis, X = X_axis, opts=dict(title='Result_exp_{}_RMSE[{:2.3f}]_R2[{:2.3f}]'.format(num,result['test_RMSE'],result['test_R2']),\n",
    "                                                                                       legend=['predict','true'],\n",
    "                                                                                        showlegend=True,\n",
    "                                                                                       layoutopts = {'plotly': {'legend': {'x':0, 'y':0}}}))\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsungpark/Desktop/Real_Last/DS_NG_TN/Last\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jinsungpark/Desktop/Real_Last/DS_NG_TN/Last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm119epoch.pt             modell_result_train119.csv\r\n",
      "lstm126epoch.pt             \u001b[34mtrash\u001b[m\u001b[m/\r\n",
      "modell_result_test119.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jinsungpark/Desktop/Real_Last/DS_NG_TN/Last'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testall = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2013-01-01', '2016-07-31')\n",
    "testset = RiverDataset(args.UpData, args.DownData, args.x_frames, args.y_frames, '2016-08-01', '2017-05-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n",
      "start\n",
      "end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_3874232b7ff272'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberis = 168\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "modell = LSTM_edit()\n",
    "# modell.load_state_dict(torch.load('lstm[{}].pt'.format(numberis)))\n",
    "modell.load_state_dict(torch.load('lstm{}epoch.pt'.format(numberis)))\n",
    "RMSE_1, R2_1, Pred_1, True_1 = test_edit(modell)\n",
    "RMSE_1_all, R2_1_all, Pred_1_all, True_1_all = test_edit_all(modell)\n",
    "\n",
    "test_data = pd.DataFrame()\n",
    "test_data['test_pred'] = Pred_1\n",
    "test_data['test_true'] = True_1\n",
    "test_data['test_RMSE'] = RMSE_1\n",
    "test_data['test_R2'] = R2_1\n",
    "\n",
    "test_data_all = pd.DataFrame()\n",
    "test_data_all['test_pred'] = Pred_1_all\n",
    "test_data_all['test_true'] = True_1_all\n",
    "test_data_all['test_RMSE'] = RMSE_1_all\n",
    "test_data_all['test_R2'] = R2_1_all\n",
    "\n",
    "\n",
    "test_data.to_csv('modell_result_test{}.csv'.format(numberis))\n",
    "test_data_all.to_csv('modell_result_train{}.csv'.format(numberis))\n",
    "\n",
    "predict = torch.Tensor(test_data['test_pred']).view(-1,1)\n",
    "truth = torch.Tensor(test_data['test_true']).view(-1,1)\n",
    "axis = torch.Tensor(range(len(test_data['test_pred']))).view(-1,1)\n",
    "\n",
    "Y_axis = torch.cat((predict, truth), -1)\n",
    "X_axis = torch.cat((axis, axis), -1)\n",
    "\n",
    "vis.line(Y = Y_axis, X = X_axis, opts=dict(title='Result_exp_{}_RMSE[{:2.3f}]_R2[{:2.3f}]'\n",
    "                                           .format(numberis,test_data['test_RMSE'][0],test_data['test_R2'][0]),\n",
    "                                           legend=['predict','true'],\n",
    "                                           showlegend=True,\n",
    "                                           layoutopts = {'plotly': {'legend': {'x':0, 'y':0}}}))\n",
    "\n",
    "\n",
    "predict = torch.Tensor(test_data_all['test_pred']).view(-1,1)\n",
    "truth = torch.Tensor(test_data_all['test_true']).view(-1,1)\n",
    "axis = torch.Tensor(range(len(test_data_all['test_pred']))).view(-1,1)\n",
    "\n",
    "Y_axis = torch.cat((predict, truth), -1)\n",
    "X_axis = torch.cat((axis, axis), -1)\n",
    "\n",
    "vis.line(Y = Y_axis, X = X_axis, opts=dict(title='Result_all_exp_{}_RMSE[{:2.3f}]_R2[{:2.3f}]'\n",
    "                                           .format(numberis,test_data_all['test_RMSE'][0],test_data_all['test_R2'][0]),\n",
    "                                           legend=['predict','true'],\n",
    "                                           showlegend=True,\n",
    "                                           layoutopts = {'plotly': {'legend': {'x':0, 'y':0}}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 666\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "\n",
    "# for i in range(1,23):\n",
    "#     numberis = i\n",
    "#     modell = LSTM_edit()\n",
    "#     modell.load_state_dict(torch.load('lstm[{}].pt'.format(numberis)))\n",
    "#     RMSE_1, R2_1, Pred_1, True_1 = test_edit(modell)\n",
    "#     RMSE_1_all, R2_1_all, Pred_1_all, True_1_all = test_edit_all(modell)\n",
    "\n",
    "#     test_data = {}\n",
    "#     test_data['test_pred'] = Pred_1\n",
    "#     test_data['test_true'] = True_1\n",
    "#     test_data['test_RMSE'] = RMSE_1\n",
    "#     test_data['test_R2'] = R2_1\n",
    "\n",
    "#     test_data_all = {}\n",
    "#     test_data_all['test_pred'] = Pred_1_all\n",
    "#     test_data_all['test_true'] = True_1_all\n",
    "#     test_data_all['test_RMSE'] = RMSE_1_all\n",
    "#     test_data_all['test_R2'] = R2_1_all\n",
    "\n",
    "\n",
    "\n",
    "#     # test_data.to_csv('modell_result_[{}]_all.csv'.format(numberis))\n",
    "\n",
    "#     predict = torch.Tensor(test_data['test_pred']).view(-1,1)\n",
    "#     truth = torch.Tensor(test_data['test_true']).view(-1,1)\n",
    "#     axis = torch.Tensor(range(len(test_data['test_pred']))).view(-1,1)\n",
    "\n",
    "#     Y_axis = torch.cat((predict, truth), -1)\n",
    "#     X_axis = torch.cat((axis, axis), -1)\n",
    "\n",
    "#     vis.line(Y = Y_axis, X = X_axis, opts=dict(title='Result_exp_{}_RMSE[{:2.3f}]_R2[{:2.3f}]'.format(numberis,test_data['test_RMSE'],test_data['test_R2']),\n",
    "#                                                legend=['predict','true'],\n",
    "#                                                showlegend=True,\n",
    "#                                                layoutopts = {'plotly': {'legend': {'x':0, 'y':0}}}))\n",
    "\n",
    "\n",
    "#     predict = torch.Tensor(test_data_all['test_pred']).view(-1,1)\n",
    "#     truth = torch.Tensor(test_data_all['test_true']).view(-1,1)\n",
    "#     axis = torch.Tensor(range(len(test_data_all['test_pred']))).view(-1,1)\n",
    "\n",
    "#     Y_axis = torch.cat((predict, truth), -1)\n",
    "#     X_axis = torch.cat((axis, axis), -1)\n",
    "\n",
    "#     vis.line(Y = Y_axis, X = X_axis, opts=dict(title='Result_all_exp_{}_RMSE[{:2.3f}]_R2[{:2.3f}]'\n",
    "#                                                .format(numberis,test_data_all['test_RMSE'],test_data_all['test_R2']),\n",
    "#                                                legend=['predict','true'],\n",
    "#                                                showlegend=True,\n",
    "#                                                layoutopts = {'plotly': {'legend': {'x':0, 'y':0}}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
